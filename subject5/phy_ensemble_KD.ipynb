{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "phy_ensemble_KD_50_subs_tr_dt,_sub_466(sub 5).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fe88e128d1d2407abcd219f6032a51e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2f212dfc068448c96a146b00bd9b916",
              "IPY_MODEL_e94c8f12923542948396617a5184c401",
              "IPY_MODEL_1250c1ce608f494f9ef390fe5e0b0cff"
            ],
            "layout": "IPY_MODEL_609554ad2b4543a69954af797f0a23ba"
          }
        },
        "d2f212dfc068448c96a146b00bd9b916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c484503f6efb4dcaa1096f09830d5426",
            "placeholder": "​",
            "style": "IPY_MODEL_e02186324a2c48469330702c941053d7",
            "value": "100%"
          }
        },
        "e94c8f12923542948396617a5184c401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8accca5d9c964e5182f5845a56150d9f",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e366296f9dc041669d1d0b2920d9833c",
            "value": 100
          }
        },
        "1250c1ce608f494f9ef390fe5e0b0cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f48653bf9a1a466badd900013cf7e667",
            "placeholder": "​",
            "style": "IPY_MODEL_9e14c8a833ce479192b28b1f71463519",
            "value": " 100/100 [01:01&lt;00:00,  1.39it/s]"
          }
        },
        "609554ad2b4543a69954af797f0a23ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c484503f6efb4dcaa1096f09830d5426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e02186324a2c48469330702c941053d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8accca5d9c964e5182f5845a56150d9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e366296f9dc041669d1d0b2920d9833c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f48653bf9a1a466badd900013cf7e667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e14c8a833ce479192b28b1f71463519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83ec2bc9b6db40febf1d764d7129da76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1e8b54f7d194b49817e6135a897b3a9",
              "IPY_MODEL_924a502e17874b3c970d71afa7faa826",
              "IPY_MODEL_242e6cd46a4447a8bb38f80ecdd8e7e3"
            ],
            "layout": "IPY_MODEL_bf3af936981e486c88149eccb0103e54"
          }
        },
        "f1e8b54f7d194b49817e6135a897b3a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbf153f63ac04c348b2ebbbbb65b8a86",
            "placeholder": "​",
            "style": "IPY_MODEL_54be49a263cc47228c9cf546d8d74d91",
            "value": "100%"
          }
        },
        "924a502e17874b3c970d71afa7faa826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e532d5e5346482b96d17e04f59f5dff",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c95c5647aafd44b6bf19feb789a4e462",
            "value": 2
          }
        },
        "242e6cd46a4447a8bb38f80ecdd8e7e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f39f80d11f7f457083a5829a45164151",
            "placeholder": "​",
            "style": "IPY_MODEL_8e5ad55e01af4a4da58b22303750000a",
            "value": " 2/2 [00:02&lt;00:00,  1.38s/it]"
          }
        },
        "bf3af936981e486c88149eccb0103e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbf153f63ac04c348b2ebbbbb65b8a86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54be49a263cc47228c9cf546d8d74d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e532d5e5346482b96d17e04f59f5dff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c95c5647aafd44b6bf19feb789a4e462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f39f80d11f7f457083a5829a45164151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e5ad55e01af4a4da58b22303750000a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QwaMPYsKrEy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.pipeline import Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "metadata": {
        "id": "-i-2uxtqK05H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "0eV1jVn8K07r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#%cd /gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GmbGXPSKJQN",
        "outputId": "90430021-084b-41fc-b77a-50413b4432db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/gdrive/My Drive\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1LT5EcaJt-C",
        "outputId": "9588cd6b-c88d-4a51-ad3d-dc1fa21aa879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Colab Notebooks'   NPZ_files   physionet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rblAU_LuK7Uu",
        "outputId": "9970ac84-1001-494d-f1ba-dce93cdea593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mne\n",
            "  Downloading mne-1.0.3-py3-none-any.whl (7.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5 MB 14.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mne) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.21.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mne) (2.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mne) (21.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.4.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.7/dist-packages (from mne) (1.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mne) (4.64.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mne) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mne) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mne) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mne) (1.15.0)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import pyeeg\n",
        "from tensorflow import keras "
      ],
      "metadata": {
        "id": "AdC_kWUFK7cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import glob\n",
        "import math\n",
        "import ntpath\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#import edfreader\n",
        "#import models\n",
        "import mne\n",
        "#import pyeeg\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "from mne.datasets.sleep_physionet._utils import _fetch_one, _data_path, AGE_SLEEP_RECORDS, _check_subjects\n",
        "from datetime import datetime\n",
        "from mne import Epochs, pick_types, find_events\n",
        "from mne.io import concatenate_raws, read_raw_edf\n",
        "from mne.time_frequency import psd_welch\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.svm import SVC\n",
        "import joblib\n",
        "\n",
        "from sklearn.metrics import make_scorer, f1_score, accuracy_score, classification_report, log_loss\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "#from xgboost import XGBClassifier\n",
        "#import xgboost"
      ],
      "metadata": {
        "id": "jJ3LG4-jLE9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VBS = True  # constant boolean to enable/disbale verbose\n",
        "EPOCH_SEC_SIZE = 30  # Epoch duration selection\n",
        "seed = 42  # seed value for the random seeds\n",
        "batch_size = 64\n",
        "number_of_files = 100 #100 npz files, 50 subjects, each suject has 2 nights, so 2 files per subject (50*2)=100\n",
        "\n",
        "# values to label the stages\n",
        "UNKNOWN = -1\n",
        "W = 0\n",
        "N1 = 1\n",
        "N2 = 2\n",
        "N3 = 3\n",
        "REM = 4\n",
        "\n",
        "# making string dictionary for the label values\n",
        "label_dict = {\n",
        "    \"UNKNOWN\"  : UNKNOWN,\n",
        "    \"W\"        : W,\n",
        "    \"N1\"       : N1,\n",
        "    \"N2\"       : N2,\n",
        "    \"N3\"       : N3,\n",
        "    \"REM\"      : REM\n",
        "}\n",
        "\n",
        "# converting from label values to strings \n",
        "class_dict = {\n",
        "    -1: \"UNKNOWN\",\n",
        "    0 : \"W\",\n",
        "    1 : \"N1\",\n",
        "    2 : \"N2\",\n",
        "    3 : \"N3\",\n",
        "    4 : \"REM\"\n",
        "}\n",
        "\n",
        "# annotation dictionary to convert from string to label values\n",
        "annot2label = {\n",
        "    \"Sleep stage ?\": -1,\n",
        "    \"Movement time\": -1,\n",
        "    \"Sleep stage W\": 0,\n",
        "    \"Sleep stage 1\": 1,\n",
        "    \"Sleep stage 2\": 2,\n",
        "    \"Sleep stage 3\": 3,\n",
        "    \"Sleep stage 4\": 3,\n",
        "    \"Sleep stage R\": 4\n",
        "}\n",
        "#project_path = os.path.abspath(os.getcwd())  # finding the current project path in windows"
      ],
      "metadata": {
        "id": "xSNwSfF1LMz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# localized fetch_data function by using mne library\n",
        "# https://github.com/mne-tools/mne-python/blob/maint/0.20/mne/datasets/sleep_physionet/age.py#L18-L111\n",
        "data_path = _data_path\n",
        "BASE_URL = 'https://physionet.org/physiobank/database/sleep-edfx/sleep-cassette/'\n",
        "def fetch_data(subjects, recording=[1, 2], path=None, force_update=False,\n",
        "               update_path=None, base_url=BASE_URL,\n",
        "               verbose=None):  # noqa: D301\n",
        "    records = np.loadtxt(AGE_SLEEP_RECORDS,\n",
        "                         skiprows=1,\n",
        "                         delimiter=',',\n",
        "                         usecols=(0, 1, 2, 6, 7),\n",
        "                         dtype={'names': ('subject', 'record', 'type', 'sha',\n",
        "                                          'fname'),\n",
        "                                'formats': ('<i2', 'i1', '<S9', 'S40', '<S22')}\n",
        "                         )\n",
        "    psg_records = records[np.where(records['type'] == b'PSG')]\n",
        "    hyp_records = records[np.where(records['type'] == b'Hypnogram')]\n",
        "\n",
        "    path = data_path(path=path, update_path=update_path)\n",
        "    params = [path, force_update, base_url]\n",
        "    fnames = []\n",
        "    for subject in subjects:\n",
        "        for idx in np.where(psg_records['subject'] == subject)[0]:\n",
        "            if psg_records['record'][idx] in recording:\n",
        "                psg_fname = _fetch_one(psg_records['fname'][idx].decode(),\n",
        "                                       psg_records['sha'][idx].decode(),\n",
        "                                       *params)\n",
        "                hyp_fname = _fetch_one(hyp_records['fname'][idx].decode(),\n",
        "                                       hyp_records['sha'][idx].decode(),\n",
        "                                       *params)\n",
        "                fnames.append([psg_fname, hyp_fname])\n",
        "\n",
        "    return fnames"
      ],
      "metadata": {
        "id": "Rmn8q60zLPBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "npz_files = sorted(glob.glob(\"/content/gdrive/My Drive/NPZ_files/***.npz\"))"
      ],
      "metadata": {
        "id": "bO5b-P6v_QJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((0, 3000, 1))\n",
        "y = []\n",
        "for fn in tqdm(npz_files[:number_of_files]):\n",
        "    samples = np.load(fn)\n",
        "    X_data = samples['x']\n",
        "    X = np.concatenate((X, X_data), axis=0)\n",
        "    y.extend(samples['y'])\n",
        "y = np.array(y)\n",
        "\n",
        "#sorted(glob.glob(\"/gdrive/My Drive/NPZ_files/***.npz\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fe88e128d1d2407abcd219f6032a51e4",
            "d2f212dfc068448c96a146b00bd9b916",
            "e94c8f12923542948396617a5184c401",
            "1250c1ce608f494f9ef390fe5e0b0cff",
            "609554ad2b4543a69954af797f0a23ba",
            "c484503f6efb4dcaa1096f09830d5426",
            "e02186324a2c48469330702c941053d7",
            "8accca5d9c964e5182f5845a56150d9f",
            "e366296f9dc041669d1d0b2920d9833c",
            "f48653bf9a1a466badd900013cf7e667",
            "9e14c8a833ce479192b28b1f71463519"
          ]
        },
        "id": "qxqp19i7LPF0",
        "outputId": "a7e83654-7003-47e1-897f-808d4ef00b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe88e128d1d2407abcd219f6032a51e4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "npz_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJQhA9x-LWKZ",
        "outputId": "3f628a3d-9d37-4292-93f2-51ccf550ef7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/NPZ_files/SC4001E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4002E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4011E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4012E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4021E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4022E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4031E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4032E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4041E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4042E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4051E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4052E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4061E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4062E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4071E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4072E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4081E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4082E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4091E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4092E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4101E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4102E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4111E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4112E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4121E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4122E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4141E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4142E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4151E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4152E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4161E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4162E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4171E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4172E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4181E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4182E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4191E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4192E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4201E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4202E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4211E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4212E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4221E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4222E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4231E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4232E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4241E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4242E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4251E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4252E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4261F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4262F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4271F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4272F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4281G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4282G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4291G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4292G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4301E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4302E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4311E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4312E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4321E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4322E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4331F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4332F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4341F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4342F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4351F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4352F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4371F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4372F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4381F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4382F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4401E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4402E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4411E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4412E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4421E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4422E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4431E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4432E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4441E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4442E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4451F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4452F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4461F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4462F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4471F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4472F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4481F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4482F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4491G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4492G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4501E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4502E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4511E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4512E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4531E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4532E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4541F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4542F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4551F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4552F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4561F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4562F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4571F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4572F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4581G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4582G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4591G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4592G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4601E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4602E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4611E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4612E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4621E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4622E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4631E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4632E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4641E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4642E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4651E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4652E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4661E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4662E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4671G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4672G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4701E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4702E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4711E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4712E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4721E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4722E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4731E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4732E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4741E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4742E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4751E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4752E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4761E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4762E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4771G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4772G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4801G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4802G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4811G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4812G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4821G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4822G0.npz']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(npz_files[:number_of_files])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpGBuj1zLWNT",
        "outputId": "363b5d21-4ca0-4022-d65a-20bcb438803a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "npz_files[:number_of_files]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjLD1Bm5LWQF",
        "outputId": "e3a0ca3d-e55b-4e8d-fc18-c0d040619fab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/NPZ_files/SC4001E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4002E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4011E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4012E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4021E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4022E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4031E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4032E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4041E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4042E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4051E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4052E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4061E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4062E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4071E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4072E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4081E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4082E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4091E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4092E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4101E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4102E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4111E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4112E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4121E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4122E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4141E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4142E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4151E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4152E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4161E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4162E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4171E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4172E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4181E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4182E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4191E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4192E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4201E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4202E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4211E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4212E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4221E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4222E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4231E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4232E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4241E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4242E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4251E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4252E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4261F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4262F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4271F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4272F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4281G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4282G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4291G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4292G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4301E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4302E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4311E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4312E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4321E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4322E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4331F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4332F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4341F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4342F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4351F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4352F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4371F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4372F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4381F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4382F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4401E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4402E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4411E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4412E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4421E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4422E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4431E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4432E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4441E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4442E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4451F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4452F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4461F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4462F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4471F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4472F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4481F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4482F0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4491G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4492G0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4501E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4502E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4511E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4512E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4531E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4532E0.npz']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "npz_files[124:126]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z__RQOgvLWTH",
        "outputId": "7bd99869-3922-45b4-87cd-e1c996179a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/NPZ_files/SC4661E0.npz',\n",
              " '/content/gdrive/My Drive/NPZ_files/SC4662E0.npz']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izABuIkjLlK3",
        "outputId": "17047909-3cc7-4ea5-f350-10317c08ec5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 8.11135578e+00],\n",
              "        [ 1.74886456e+01],\n",
              "        [ 2.12395611e+01],\n",
              "        ...,\n",
              "        [-1.03619051e+01],\n",
              "        [-1.11120882e+01],\n",
              "        [-2.10989022e+00]],\n",
              "\n",
              "       [[-1.07369967e+01],\n",
              "        [-1.13934069e+01],\n",
              "        [-4.45421267e+00],\n",
              "        ...,\n",
              "        [ 5.88424911e+01],\n",
              "        [ 4.83399277e+01],\n",
              "        [ 5.36849823e+01]],\n",
              "\n",
              "       [[ 6.13743591e+01],\n",
              "        [ 3.86813202e+01],\n",
              "        [ 4.95589752e+01],\n",
              "        ...,\n",
              "        [ 3.36175842e+01],\n",
              "        [ 3.43677673e+01],\n",
              "        [ 3.18358974e+01]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 3.47106218e+00],\n",
              "        [-5.03052510e-02],\n",
              "        [ 2.56556773e+00],\n",
              "        ...,\n",
              "        [ 9.55799758e-01],\n",
              "        [-1.86129427e+00],\n",
              "        [ 3.37045169e+00]],\n",
              "\n",
              "       [[ 2.26373625e+00],\n",
              "        [ 3.52136761e-01],\n",
              "        [ 2.86739922e+00],\n",
              "        ...,\n",
              "        [ 2.54041519e+01],\n",
              "        [ 2.02730160e+01],\n",
              "        [ 1.82608051e+01]],\n",
              "\n",
              "       [[ 1.96693535e+01],\n",
              "        [ 1.65504265e+01],\n",
              "        [ 1.54437122e+01],\n",
              "        ...,\n",
              "        [ 1.83614159e+01],\n",
              "        [ 2.97304020e+01],\n",
              "        [ 1.76571426e+01]]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTpchoaJLlPd",
        "outputId": "dc54510f-f296-4225-d0f7-79fe36380d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "JF6uRM_iLlSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if VBS:\n",
        "    print(\"Shape of the input data: {}\".format(X.shape))\n",
        "    print(\"Shape of the sleep stages: {}\".format(y.shape))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUbmOwSjLlVS",
        "outputId": "5f5f7637-5c1c-49cb-b2fc-2178614333b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the input data: (116718, 3000, 1)\n",
            "Shape of the sleep stages: (116718,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers, losses, activations, models\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import GlobalMaxPool1D, GlobalAveragePooling1D, concatenate, SpatialDropout1D, TimeDistributed, Bidirectional, LSTM\n",
        "from tensorflow.keras.layers import Input, Conv1D, Dense, Dropout, MaxPool1D, Activation\n",
        "from tensorflow.keras.layers import Reshape, LSTM, TimeDistributed, Bidirectional, BatchNormalization, Flatten, RepeatVector\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#from keras_contrib.layers import CRF\n",
        "\n",
        "from scipy.signal import butter, lfilter\n"
      ],
      "metadata": {
        "id": "2S625LlcLlYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#n_classes=5\n",
        "def model_b(n_classes=5, use_sub_layer=False, use_rnn=True, verbose=False):\n",
        "    inputLayer = Input(shape=(3000, 1), name='inLayer')\n",
        "    convFine = Conv1D(filters=64, kernel_size=int(Fs/2), strides=int(Fs/16), padding='same', activation='relu', name='fConv1')(inputLayer)\n",
        "    convFine = MaxPool1D(pool_size=8, strides=8, name='fMaxP1')(convFine)\n",
        "    convFine = Dropout(rate=0.5, name='fDrop1')(convFine)\n",
        "    convFine = Conv1D(filters=128, kernel_size=8, padding='same', activation='relu', name='fConv2')(convFine)\n",
        "    convFine = Conv1D(filters=128, kernel_size=8, padding='same', activation='relu', name='fConv3')(convFine)\n",
        "    convFine = Conv1D(filters=128, kernel_size=8, padding='same', activation='relu', name='fConv4')(convFine)\n",
        "    convFine = MaxPool1D(pool_size=4, strides=4, name='fMaxP2')(convFine)\n",
        "    fineShape = convFine.get_shape()\n",
        "    convFine = Flatten(name='fFlat1')(convFine)\n",
        "    \n",
        "    # network to learn coarse features\n",
        "    convCoarse = Conv1D(filters=32, kernel_size=Fs*4, strides=int(Fs/2), padding='same', activation='relu', name='cConv1')(inputLayer)\n",
        "    convCoarse = MaxPool1D(pool_size=4, strides=4, name='cMaxP1')(convCoarse)\n",
        "    convCoarse = Dropout(rate=0.5, name='cDrop1')(convCoarse)\n",
        "    convCoarse = Conv1D(filters=128, kernel_size=6, padding='same', activation='relu', name='cConv2')(convCoarse)\n",
        "    convCoarse = Conv1D(filters=128, kernel_size=6, padding='same', activation='relu', name='cConv3')(convCoarse)\n",
        "    convCoarse = Conv1D(filters=128, kernel_size=6, padding='same', activation='relu', name='cConv4')(convCoarse)\n",
        "    convCoarse = MaxPool1D(pool_size=2, strides=2, name='cMaxP2')(convCoarse)\n",
        "    coarseShape = convCoarse.get_shape()\n",
        "    convCoarse = Flatten(name='cFlat1')(convCoarse)\n",
        "    \n",
        "    # concatenate coarse and fine cnns\n",
        "    mergeLayer = concatenate([convFine, convCoarse], name='merge_1')\n",
        "    outLayer = Dropout(rate=0.5, name='mDrop1')(mergeLayer)\n",
        "    \n",
        "    outLayer = Reshape((1, outLayer.get_shape()[1]), name='reshape1')(outLayer)\n",
        "    outLayer = LSTM(64, return_sequences=True)(outLayer)\n",
        "    outLayer = LSTM(64, return_sequences=False)(outLayer)\n",
        "\n",
        "    # Classify\n",
        "    outLayer = Dense(n_classes, activation='softmax', name='outLayer')(outLayer)\n",
        "    model = Model(inputLayer, outLayer)\n",
        "    optimizer = Adam(lr=1e-4)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
        "    #model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    if verbose:\n",
        "        model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "bAe0cmpJL3VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def butter_bandpass(lowcut, highpass, fs, order=4):\n",
        "    nyq = 0.5 * fs\n",
        "    #       low = lowcut / nyq\n",
        "    high = highpass / nyq\n",
        "    b, a = butter(order, high, btype='highpass')\n",
        "    return b, a"
      ],
      "metadata": {
        "id": "_oylVDLVL3X8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def butter_bandpass_filter(data, highpass, fs, order=4):\n",
        "    b, a = butter_bandpass(0, highpass, fs, order=order)\n",
        "    y = lfilter(b, a, data)\n",
        "    return y"
      ],
      "metadata": {
        "id": "pgmWHwIOL3at"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#npz_files = sorted(glob.glob(os.path.join(output_path, \"*.npz\")))\n",
        "X_sub_466 = np.zeros((0, 3000, 1))\n",
        "y_sub_466 = []\n",
        "for fn in tqdm(npz_files[124:126]): #extracting data from the npz files corresponding to both tge recording 1, 2 of the 73rd subject (no 53rd subject)\n",
        "    samples = np.load(fn)\n",
        "    X_data = samples['x']\n",
        "    X_sub_466 = np.concatenate((X_sub_466, X_data), axis=0)\n",
        "    y_sub_466.extend(samples['y'])\n",
        "y_sub_466 = np.array(y_sub_466)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "83ec2bc9b6db40febf1d764d7129da76",
            "f1e8b54f7d194b49817e6135a897b3a9",
            "924a502e17874b3c970d71afa7faa826",
            "242e6cd46a4447a8bb38f80ecdd8e7e3",
            "bf3af936981e486c88149eccb0103e54",
            "bbf153f63ac04c348b2ebbbbb65b8a86",
            "54be49a263cc47228c9cf546d8d74d91",
            "9e532d5e5346482b96d17e04f59f5dff",
            "c95c5647aafd44b6bf19feb789a4e462",
            "f39f80d11f7f457083a5829a45164151",
            "8e5ad55e01af4a4da58b22303750000a"
          ]
        },
        "id": "VsiRp4zhL3dc",
        "outputId": "2a4033fc-cea3-4754-e600-44d549ec5aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83ec2bc9b6db40febf1d764d7129da76"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_sub_466"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Znukt-l1L3gQ",
        "outputId": "9d2f65df-5153-4db8-89ef-723923310dbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 19.33431053],\n",
              "        [-37.49255371],\n",
              "        [ -7.04297924],\n",
              "        ...,\n",
              "        [-16.205616  ],\n",
              "        [ -6.21001244],\n",
              "        [-35.36385727]],\n",
              "\n",
              "       [[-20.64810753],\n",
              "        [-39.15848541],\n",
              "        [-16.205616  ],\n",
              "        ...,\n",
              "        [ 17.39072037],\n",
              "        [ -8.06105042],\n",
              "        [ -9.17167282]],\n",
              "\n",
              "       [[-13.98437119],\n",
              "        [  0.63882786],\n",
              "        [  0.17606838],\n",
              "        ...,\n",
              "        [ 16.37265015],\n",
              "        [-12.13333321],\n",
              "        [  9.52380943]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 20.94554329],\n",
              "        [ 20.19609261],\n",
              "        [ 14.70012188],\n",
              "        ...,\n",
              "        [ 21.11208725],\n",
              "        [ 11.20268631],\n",
              "        [  5.87326002]],\n",
              "\n",
              "       [[  8.70451736],\n",
              "        [ 10.36996365],\n",
              "        [  9.37069607],\n",
              "        ...,\n",
              "        [-48.00390625],\n",
              "        [-43.0908432 ],\n",
              "        [-35.26324844]],\n",
              "\n",
              "       [[ -5.7015872 ],\n",
              "        [-21.44004822],\n",
              "        [  4.04126978],\n",
              "        ...,\n",
              "        [  3.37509155],\n",
              "        [ 19.03028107],\n",
              "        [ 35.51819229]]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_sub_466"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0M5eAMwMD3m",
        "outputId": "46afb3fc-26f0-44d7-beee-eb948cb2613c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(y_sub_466).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBvoprc6bpNe",
        "outputId": "aab6d0de-95e2-4f4a-cba2-4b677b9358a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2096\n",
              "2     836\n",
              "1     610\n",
              "4     360\n",
              "3     118\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if VBS:\n",
        "    print(\"Shape of the subject(466) data: {}\".format(X_sub_466.shape))\n",
        "    print(\"Shape of the corresponding sleep stage: {}\".format(y_sub_466.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGsddVuvMD6d",
        "outputId": "1f8c5e6f-d072-4724-e61e-f37e3b508e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the subject(466) data: (4020, 3000, 1)\n",
            "Shape of the corresponding sleep stage: (4020,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp_x = np.array([butter_bandpass_filter(sample, highpass=40.0, fs=100, order=4) for sample in X])\n",
        "\n",
        "if VBS:\n",
        "    print(pp_x.shape)"
      ],
      "metadata": {
        "id": "MHyiIqkyMD9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5664ac4-00b0-4da7-daf7-a9f0c5fb1e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(116718, 3000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SGh9u0dMEBr",
        "outputId": "fb08a061-1366-4439-a1c3-caa5307413dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(116718,)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnC-jbBaML0d",
        "outputId": "67dd6c20-7cf7-4b01-b15b-41f8405e3baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ3o82GJML3L",
        "outputId": "e8a255dd-32d0-4197-b2cc-23811fb4c1b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 3.91319654e-02],\n",
              "        [ 8.43712310e-02],\n",
              "        [ 1.02466935e-01],\n",
              "        ...,\n",
              "        [-4.99893880e-02],\n",
              "        [-5.36085289e-02],\n",
              "        [-1.01788349e-02]],\n",
              "\n",
              "       [[-5.17989585e-02],\n",
              "        [-5.49657067e-02],\n",
              "        [-2.14886513e-02],\n",
              "        ...,\n",
              "        [ 2.83876381e-01],\n",
              "        [ 2.33208409e-01],\n",
              "        [ 2.58994788e-01]],\n",
              "\n",
              "       [[ 2.96090982e-01],\n",
              "        [ 1.86611970e-01],\n",
              "        [ 2.39089513e-01],\n",
              "        ...,\n",
              "        [ 1.62182769e-01],\n",
              "        [ 1.65801910e-01],\n",
              "        [ 1.53587300e-01]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 1.67455958e-02],\n",
              "        [-2.42689804e-04],\n",
              "        [ 1.23771796e-02],\n",
              "        ...,\n",
              "        [ 4.61110622e-03],\n",
              "        [-8.97952265e-03],\n",
              "        [ 1.62602162e-02]],\n",
              "\n",
              "       [[ 1.09210409e-02],\n",
              "        [ 1.69882864e-03],\n",
              "        [ 1.38333184e-02],\n",
              "        ...,\n",
              "        [ 1.22558352e-01],\n",
              "        [ 9.78039900e-02],\n",
              "        [ 8.80963939e-02]],\n",
              "\n",
              "       [[ 9.48917148e-02],\n",
              "        [ 7.98449401e-02],\n",
              "        [ 7.45057705e-02],\n",
              "        ...,\n",
              "        [ 8.85817747e-02],\n",
              "        [ 1.43429667e-01],\n",
              "        [ 8.51841188e-02]]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp_x_rshp=pp_x.reshape(116718, 3000)"
      ],
      "metadata": {
        "id": "601PbRzwML6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp_x_rshp_df=pd.DataFrame(pp_x_rshp)"
      ],
      "metadata": {
        "id": "earR0NgrML_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp_x_rshp_df['sleep_stage']=y"
      ],
      "metadata": {
        "id": "jk9qTP59MMDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp_x_rshp_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "tydflxnKMMHf",
        "outputId": "e3b1c31f-de49-4dce-e0d8-bb65bb9b2970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0         1         2         3         4         5         6  \\\n",
              "0       0.039132  0.084371  0.102467  0.033251  0.045465  0.026465  0.008369   \n",
              "1      -0.051799 -0.054966 -0.021489 -0.001131 -0.016512 -0.114229 -0.056775   \n",
              "2       0.296091  0.186612  0.239090  0.259900  0.302877  0.316901  0.272567   \n",
              "3       0.134134  0.116491  0.116491  0.070347  0.066728  0.037322  0.030989   \n",
              "4       0.333640  0.359878  0.381141  0.386117  0.373450  0.372998  0.360783   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "116713  0.117219  0.233710  0.088582  0.195365  0.141488  0.136634  0.103629   \n",
              "116714 -0.087611 -0.076447 -0.056061 -0.058488 -0.075962 -0.053149 -0.065769   \n",
              "116715  0.016746 -0.000243  0.012377  0.020629  0.014319 -0.042956 -0.085669   \n",
              "116716  0.010921  0.001699  0.013833 -0.000243  0.008494 -0.000243  0.002670   \n",
              "116717  0.094892  0.079845  0.074506  0.070623  0.077903  0.084213  0.082757   \n",
              "\n",
              "               7         8         9  ...      2991      2992      2993  \\\n",
              "0       0.001131 -0.006560  0.009274  ... -0.034156  0.001583 -0.057228   \n",
              "1      -0.085728 -0.113324 -0.078490  ...  0.264876  0.197922  0.267138   \n",
              "2       0.281614  0.220541  0.265328  ...  0.164445  0.146349  0.176207   \n",
              "3       0.039584  0.023751  0.020131  ... -0.087086 -0.040942  0.009726   \n",
              "4       0.367117  0.359878  0.382046  ... -0.121920 -0.060847  0.000679   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "116713  0.213810  0.167699  0.141488  ... -0.108482 -0.110424 -0.112365   \n",
              "116714 -0.104114 -0.086155 -0.121102  ...  0.034219  0.093921  0.097319   \n",
              "116715 -0.076447 -0.066740 -0.060915  ...  0.031792  0.027909  0.014804   \n",
              "116716 -0.001699 -0.003640  0.011406  ...  0.126927  0.115763  0.124014   \n",
              "116717  0.076447  0.084213  0.090523  ...  0.198278  0.121588  0.224488   \n",
              "\n",
              "            2994      2995      2996      2997      2998      2999  \\\n",
              "0      -0.041394 -0.023751  0.002488 -0.049989 -0.053609 -0.010179   \n",
              "1       0.264876  0.312377  0.251304  0.283876  0.233208  0.258995   \n",
              "2       0.176659  0.149516  0.163540  0.162183  0.165802  0.153587   \n",
              "3       0.035060  0.129610  0.045465  0.126896  0.205612  0.274829   \n",
              "4       0.060394  0.045465  0.084371  0.057680  0.122372  0.207422   \n",
              "...          ...       ...       ...       ...       ...       ...   \n",
              "116713 -0.064798 -0.171096 -0.115278 -0.044898 -0.099746 -0.122073   \n",
              "116714  0.070623  0.069167  0.040529  0.058488  0.046839  0.049266   \n",
              "116715  0.017231  0.020143  0.001213  0.004611 -0.008980  0.016260   \n",
              "116716  0.130810  0.130810  0.124014  0.122558  0.097804  0.088096   \n",
              "116717  0.146342  0.061886  0.129354  0.088582  0.143430  0.085184   \n",
              "\n",
              "        sleep_stage  \n",
              "0                 0  \n",
              "1                 0  \n",
              "2                 0  \n",
              "3                 0  \n",
              "4                 0  \n",
              "...             ...  \n",
              "116713            0  \n",
              "116714            0  \n",
              "116715            0  \n",
              "116716            0  \n",
              "116717            0  \n",
              "\n",
              "[116718 rows x 3001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0aa1e02b-a88b-4dd0-b6f3-d5d455434d5e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>2991</th>\n",
              "      <th>2992</th>\n",
              "      <th>2993</th>\n",
              "      <th>2994</th>\n",
              "      <th>2995</th>\n",
              "      <th>2996</th>\n",
              "      <th>2997</th>\n",
              "      <th>2998</th>\n",
              "      <th>2999</th>\n",
              "      <th>sleep_stage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.039132</td>\n",
              "      <td>0.084371</td>\n",
              "      <td>0.102467</td>\n",
              "      <td>0.033251</td>\n",
              "      <td>0.045465</td>\n",
              "      <td>0.026465</td>\n",
              "      <td>0.008369</td>\n",
              "      <td>0.001131</td>\n",
              "      <td>-0.006560</td>\n",
              "      <td>0.009274</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.034156</td>\n",
              "      <td>0.001583</td>\n",
              "      <td>-0.057228</td>\n",
              "      <td>-0.041394</td>\n",
              "      <td>-0.023751</td>\n",
              "      <td>0.002488</td>\n",
              "      <td>-0.049989</td>\n",
              "      <td>-0.053609</td>\n",
              "      <td>-0.010179</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.051799</td>\n",
              "      <td>-0.054966</td>\n",
              "      <td>-0.021489</td>\n",
              "      <td>-0.001131</td>\n",
              "      <td>-0.016512</td>\n",
              "      <td>-0.114229</td>\n",
              "      <td>-0.056775</td>\n",
              "      <td>-0.085728</td>\n",
              "      <td>-0.113324</td>\n",
              "      <td>-0.078490</td>\n",
              "      <td>...</td>\n",
              "      <td>0.264876</td>\n",
              "      <td>0.197922</td>\n",
              "      <td>0.267138</td>\n",
              "      <td>0.264876</td>\n",
              "      <td>0.312377</td>\n",
              "      <td>0.251304</td>\n",
              "      <td>0.283876</td>\n",
              "      <td>0.233208</td>\n",
              "      <td>0.258995</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.296091</td>\n",
              "      <td>0.186612</td>\n",
              "      <td>0.239090</td>\n",
              "      <td>0.259900</td>\n",
              "      <td>0.302877</td>\n",
              "      <td>0.316901</td>\n",
              "      <td>0.272567</td>\n",
              "      <td>0.281614</td>\n",
              "      <td>0.220541</td>\n",
              "      <td>0.265328</td>\n",
              "      <td>...</td>\n",
              "      <td>0.164445</td>\n",
              "      <td>0.146349</td>\n",
              "      <td>0.176207</td>\n",
              "      <td>0.176659</td>\n",
              "      <td>0.149516</td>\n",
              "      <td>0.163540</td>\n",
              "      <td>0.162183</td>\n",
              "      <td>0.165802</td>\n",
              "      <td>0.153587</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.134134</td>\n",
              "      <td>0.116491</td>\n",
              "      <td>0.116491</td>\n",
              "      <td>0.070347</td>\n",
              "      <td>0.066728</td>\n",
              "      <td>0.037322</td>\n",
              "      <td>0.030989</td>\n",
              "      <td>0.039584</td>\n",
              "      <td>0.023751</td>\n",
              "      <td>0.020131</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.087086</td>\n",
              "      <td>-0.040942</td>\n",
              "      <td>0.009726</td>\n",
              "      <td>0.035060</td>\n",
              "      <td>0.129610</td>\n",
              "      <td>0.045465</td>\n",
              "      <td>0.126896</td>\n",
              "      <td>0.205612</td>\n",
              "      <td>0.274829</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.333640</td>\n",
              "      <td>0.359878</td>\n",
              "      <td>0.381141</td>\n",
              "      <td>0.386117</td>\n",
              "      <td>0.373450</td>\n",
              "      <td>0.372998</td>\n",
              "      <td>0.360783</td>\n",
              "      <td>0.367117</td>\n",
              "      <td>0.359878</td>\n",
              "      <td>0.382046</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.121920</td>\n",
              "      <td>-0.060847</td>\n",
              "      <td>0.000679</td>\n",
              "      <td>0.060394</td>\n",
              "      <td>0.045465</td>\n",
              "      <td>0.084371</td>\n",
              "      <td>0.057680</td>\n",
              "      <td>0.122372</td>\n",
              "      <td>0.207422</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116713</th>\n",
              "      <td>0.117219</td>\n",
              "      <td>0.233710</td>\n",
              "      <td>0.088582</td>\n",
              "      <td>0.195365</td>\n",
              "      <td>0.141488</td>\n",
              "      <td>0.136634</td>\n",
              "      <td>0.103629</td>\n",
              "      <td>0.213810</td>\n",
              "      <td>0.167699</td>\n",
              "      <td>0.141488</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108482</td>\n",
              "      <td>-0.110424</td>\n",
              "      <td>-0.112365</td>\n",
              "      <td>-0.064798</td>\n",
              "      <td>-0.171096</td>\n",
              "      <td>-0.115278</td>\n",
              "      <td>-0.044898</td>\n",
              "      <td>-0.099746</td>\n",
              "      <td>-0.122073</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116714</th>\n",
              "      <td>-0.087611</td>\n",
              "      <td>-0.076447</td>\n",
              "      <td>-0.056061</td>\n",
              "      <td>-0.058488</td>\n",
              "      <td>-0.075962</td>\n",
              "      <td>-0.053149</td>\n",
              "      <td>-0.065769</td>\n",
              "      <td>-0.104114</td>\n",
              "      <td>-0.086155</td>\n",
              "      <td>-0.121102</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034219</td>\n",
              "      <td>0.093921</td>\n",
              "      <td>0.097319</td>\n",
              "      <td>0.070623</td>\n",
              "      <td>0.069167</td>\n",
              "      <td>0.040529</td>\n",
              "      <td>0.058488</td>\n",
              "      <td>0.046839</td>\n",
              "      <td>0.049266</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116715</th>\n",
              "      <td>0.016746</td>\n",
              "      <td>-0.000243</td>\n",
              "      <td>0.012377</td>\n",
              "      <td>0.020629</td>\n",
              "      <td>0.014319</td>\n",
              "      <td>-0.042956</td>\n",
              "      <td>-0.085669</td>\n",
              "      <td>-0.076447</td>\n",
              "      <td>-0.066740</td>\n",
              "      <td>-0.060915</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031792</td>\n",
              "      <td>0.027909</td>\n",
              "      <td>0.014804</td>\n",
              "      <td>0.017231</td>\n",
              "      <td>0.020143</td>\n",
              "      <td>0.001213</td>\n",
              "      <td>0.004611</td>\n",
              "      <td>-0.008980</td>\n",
              "      <td>0.016260</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116716</th>\n",
              "      <td>0.010921</td>\n",
              "      <td>0.001699</td>\n",
              "      <td>0.013833</td>\n",
              "      <td>-0.000243</td>\n",
              "      <td>0.008494</td>\n",
              "      <td>-0.000243</td>\n",
              "      <td>0.002670</td>\n",
              "      <td>-0.001699</td>\n",
              "      <td>-0.003640</td>\n",
              "      <td>0.011406</td>\n",
              "      <td>...</td>\n",
              "      <td>0.126927</td>\n",
              "      <td>0.115763</td>\n",
              "      <td>0.124014</td>\n",
              "      <td>0.130810</td>\n",
              "      <td>0.130810</td>\n",
              "      <td>0.124014</td>\n",
              "      <td>0.122558</td>\n",
              "      <td>0.097804</td>\n",
              "      <td>0.088096</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116717</th>\n",
              "      <td>0.094892</td>\n",
              "      <td>0.079845</td>\n",
              "      <td>0.074506</td>\n",
              "      <td>0.070623</td>\n",
              "      <td>0.077903</td>\n",
              "      <td>0.084213</td>\n",
              "      <td>0.082757</td>\n",
              "      <td>0.076447</td>\n",
              "      <td>0.084213</td>\n",
              "      <td>0.090523</td>\n",
              "      <td>...</td>\n",
              "      <td>0.198278</td>\n",
              "      <td>0.121588</td>\n",
              "      <td>0.224488</td>\n",
              "      <td>0.146342</td>\n",
              "      <td>0.061886</td>\n",
              "      <td>0.129354</td>\n",
              "      <td>0.088582</td>\n",
              "      <td>0.143430</td>\n",
              "      <td>0.085184</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>116718 rows × 3001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0aa1e02b-a88b-4dd0-b6f3-d5d455434d5e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0aa1e02b-a88b-4dd0-b6f3-d5d455434d5e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0aa1e02b-a88b-4dd0-b6f3-d5d455434d5e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp_x_rshp_df.to_csv(r'/content/gdrive/My Drive/physionet/ensemble/50_subs/original_50_subs_dt_original_y_x_not_bootstraped.csv', header=False, index=False)"
      ],
      "metadata": {
        "id": "9oTQlShrNsxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_transfer_set=pp_x_rshp_df.sample(frac=1,replace=True, random_state=248)"
      ],
      "metadata": {
        "id": "ltvTyp83McpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_transfer_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "DtypxWE_Mctw",
        "outputId": "952d0eca-f6ab-445b-f69e-8d058fb0d7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0         1         2         3         4         5         6  \\\n",
              "2302    0.068014  0.082915  0.077628  0.074744  0.060804  0.063688  0.050710   \n",
              "31195   0.104729  0.054513 -0.020131 -0.064918 -0.122825 -0.127801 -0.107443   \n",
              "82207   0.002281 -0.031309 -0.007672 -0.020527 -0.003110 -0.011404  0.006013   \n",
              "2198   -0.025235 -0.037732 -0.033406 -0.031964 -0.034848 -0.041097 -0.031484   \n",
              "107738  0.097914 -0.100520 -0.044574 -0.079540 -0.071235 -0.029713 -0.041951   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "20894   0.032558  0.033944  0.046413  0.056111  0.060267  0.066271  0.077816   \n",
              "78249   0.068695  0.059483  0.051071  0.044662  0.037051  0.041057  0.040656   \n",
              "57039   0.013392  0.030717  0.029805  0.016127  0.026613  0.024334  0.019775   \n",
              "34319  -0.057457 -0.065629 -0.101198 -0.114176 -0.141093 -0.184354 -0.222807   \n",
              "17826  -0.065742 -0.082698 -0.086365 -0.053368 -0.023122 -0.024038 -0.046494   \n",
              "\n",
              "               7         8         9  ...      2991      2992      2993  \\\n",
              "2302    0.029561  0.010815  0.008412  ... -0.010334 -0.016102 -0.034368   \n",
              "31195  -0.086633 -0.051799 -0.033251  ... -0.123729 -0.120563 -0.129158   \n",
              "82207  -0.029236 -0.025089 -0.042091  ...  0.088122  0.057850  0.027992   \n",
              "2198   -0.025716 -0.019948 -0.030522  ... -0.015141 -0.013699 -0.018025   \n",
              "107738  0.000445 -0.031024  0.172217  ...  0.167409  0.220732  0.191011   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "20894   0.058882  0.078278  0.051493  ...  0.024707  0.025631  0.015933   \n",
              "78249   0.046264  0.039054  0.045063  ...  0.035850  0.031444  0.026637   \n",
              "57039   0.038012  0.027069  0.031629  ...  0.013392  0.018863  0.034820   \n",
              "34319  -0.230017 -0.242514 -0.231459  ... -0.085817 -0.068993 -0.058899   \n",
              "17826  -0.133109 -0.211476 -0.300383  ... -0.135401 -0.128985 -0.091864   \n",
              "\n",
              "            2994      2995      2996      2997      2998      2999  \\\n",
              "2302   -0.055998 -0.074263 -0.071860 -0.077147 -0.084838 -0.090125   \n",
              "31195  -0.149968 -0.173945 -0.187064 -0.171231 -0.149516 -0.121467   \n",
              "82207   0.038359  0.040847  0.053703  0.072779  0.055362  0.029651   \n",
              "2198   -0.020909 -0.021390 -0.002644 -0.020428 -0.025235 -0.024754   \n",
              "107738  0.119767  0.165661  0.270996  0.200190  0.246520  0.166535   \n",
              "...          ...       ...       ...       ...       ...       ...   \n",
              "20894   0.044565 -0.000231  0.018242 -0.028402  0.021475  0.028402   \n",
              "78249   0.023433  0.027839  0.023833  0.018626  0.005007  0.007010   \n",
              "57039   0.034364  0.042115  0.045306  0.041659  0.032996  0.024334   \n",
              "34319  -0.043999 -0.058419 -0.065629 -0.070916 -0.068513 -0.090143   \n",
              "17826  -0.071700 -0.102404 -0.157398 -0.150524 -0.087281 -0.042828   \n",
              "\n",
              "        sleep_stage  \n",
              "2302              4  \n",
              "31195             3  \n",
              "82207             1  \n",
              "2198              2  \n",
              "107738            0  \n",
              "...             ...  \n",
              "20894             2  \n",
              "78249             4  \n",
              "57039             4  \n",
              "34319             2  \n",
              "17826             2  \n",
              "\n",
              "[116718 rows x 3001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e4f73c6-3964-43c0-b747-ec84c5552312\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>2991</th>\n",
              "      <th>2992</th>\n",
              "      <th>2993</th>\n",
              "      <th>2994</th>\n",
              "      <th>2995</th>\n",
              "      <th>2996</th>\n",
              "      <th>2997</th>\n",
              "      <th>2998</th>\n",
              "      <th>2999</th>\n",
              "      <th>sleep_stage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2302</th>\n",
              "      <td>0.068014</td>\n",
              "      <td>0.082915</td>\n",
              "      <td>0.077628</td>\n",
              "      <td>0.074744</td>\n",
              "      <td>0.060804</td>\n",
              "      <td>0.063688</td>\n",
              "      <td>0.050710</td>\n",
              "      <td>0.029561</td>\n",
              "      <td>0.010815</td>\n",
              "      <td>0.008412</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.010334</td>\n",
              "      <td>-0.016102</td>\n",
              "      <td>-0.034368</td>\n",
              "      <td>-0.055998</td>\n",
              "      <td>-0.074263</td>\n",
              "      <td>-0.071860</td>\n",
              "      <td>-0.077147</td>\n",
              "      <td>-0.084838</td>\n",
              "      <td>-0.090125</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31195</th>\n",
              "      <td>0.104729</td>\n",
              "      <td>0.054513</td>\n",
              "      <td>-0.020131</td>\n",
              "      <td>-0.064918</td>\n",
              "      <td>-0.122825</td>\n",
              "      <td>-0.127801</td>\n",
              "      <td>-0.107443</td>\n",
              "      <td>-0.086633</td>\n",
              "      <td>-0.051799</td>\n",
              "      <td>-0.033251</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.123729</td>\n",
              "      <td>-0.120563</td>\n",
              "      <td>-0.129158</td>\n",
              "      <td>-0.149968</td>\n",
              "      <td>-0.173945</td>\n",
              "      <td>-0.187064</td>\n",
              "      <td>-0.171231</td>\n",
              "      <td>-0.149516</td>\n",
              "      <td>-0.121467</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82207</th>\n",
              "      <td>0.002281</td>\n",
              "      <td>-0.031309</td>\n",
              "      <td>-0.007672</td>\n",
              "      <td>-0.020527</td>\n",
              "      <td>-0.003110</td>\n",
              "      <td>-0.011404</td>\n",
              "      <td>0.006013</td>\n",
              "      <td>-0.029236</td>\n",
              "      <td>-0.025089</td>\n",
              "      <td>-0.042091</td>\n",
              "      <td>...</td>\n",
              "      <td>0.088122</td>\n",
              "      <td>0.057850</td>\n",
              "      <td>0.027992</td>\n",
              "      <td>0.038359</td>\n",
              "      <td>0.040847</td>\n",
              "      <td>0.053703</td>\n",
              "      <td>0.072779</td>\n",
              "      <td>0.055362</td>\n",
              "      <td>0.029651</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2198</th>\n",
              "      <td>-0.025235</td>\n",
              "      <td>-0.037732</td>\n",
              "      <td>-0.033406</td>\n",
              "      <td>-0.031964</td>\n",
              "      <td>-0.034848</td>\n",
              "      <td>-0.041097</td>\n",
              "      <td>-0.031484</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>-0.019948</td>\n",
              "      <td>-0.030522</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.015141</td>\n",
              "      <td>-0.013699</td>\n",
              "      <td>-0.018025</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.021390</td>\n",
              "      <td>-0.002644</td>\n",
              "      <td>-0.020428</td>\n",
              "      <td>-0.025235</td>\n",
              "      <td>-0.024754</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107738</th>\n",
              "      <td>0.097914</td>\n",
              "      <td>-0.100520</td>\n",
              "      <td>-0.044574</td>\n",
              "      <td>-0.079540</td>\n",
              "      <td>-0.071235</td>\n",
              "      <td>-0.029713</td>\n",
              "      <td>-0.041951</td>\n",
              "      <td>0.000445</td>\n",
              "      <td>-0.031024</td>\n",
              "      <td>0.172217</td>\n",
              "      <td>...</td>\n",
              "      <td>0.167409</td>\n",
              "      <td>0.220732</td>\n",
              "      <td>0.191011</td>\n",
              "      <td>0.119767</td>\n",
              "      <td>0.165661</td>\n",
              "      <td>0.270996</td>\n",
              "      <td>0.200190</td>\n",
              "      <td>0.246520</td>\n",
              "      <td>0.166535</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20894</th>\n",
              "      <td>0.032558</td>\n",
              "      <td>0.033944</td>\n",
              "      <td>0.046413</td>\n",
              "      <td>0.056111</td>\n",
              "      <td>0.060267</td>\n",
              "      <td>0.066271</td>\n",
              "      <td>0.077816</td>\n",
              "      <td>0.058882</td>\n",
              "      <td>0.078278</td>\n",
              "      <td>0.051493</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024707</td>\n",
              "      <td>0.025631</td>\n",
              "      <td>0.015933</td>\n",
              "      <td>0.044565</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>0.018242</td>\n",
              "      <td>-0.028402</td>\n",
              "      <td>0.021475</td>\n",
              "      <td>0.028402</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78249</th>\n",
              "      <td>0.068695</td>\n",
              "      <td>0.059483</td>\n",
              "      <td>0.051071</td>\n",
              "      <td>0.044662</td>\n",
              "      <td>0.037051</td>\n",
              "      <td>0.041057</td>\n",
              "      <td>0.040656</td>\n",
              "      <td>0.046264</td>\n",
              "      <td>0.039054</td>\n",
              "      <td>0.045063</td>\n",
              "      <td>...</td>\n",
              "      <td>0.035850</td>\n",
              "      <td>0.031444</td>\n",
              "      <td>0.026637</td>\n",
              "      <td>0.023433</td>\n",
              "      <td>0.027839</td>\n",
              "      <td>0.023833</td>\n",
              "      <td>0.018626</td>\n",
              "      <td>0.005007</td>\n",
              "      <td>0.007010</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57039</th>\n",
              "      <td>0.013392</td>\n",
              "      <td>0.030717</td>\n",
              "      <td>0.029805</td>\n",
              "      <td>0.016127</td>\n",
              "      <td>0.026613</td>\n",
              "      <td>0.024334</td>\n",
              "      <td>0.019775</td>\n",
              "      <td>0.038012</td>\n",
              "      <td>0.027069</td>\n",
              "      <td>0.031629</td>\n",
              "      <td>...</td>\n",
              "      <td>0.013392</td>\n",
              "      <td>0.018863</td>\n",
              "      <td>0.034820</td>\n",
              "      <td>0.034364</td>\n",
              "      <td>0.042115</td>\n",
              "      <td>0.045306</td>\n",
              "      <td>0.041659</td>\n",
              "      <td>0.032996</td>\n",
              "      <td>0.024334</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34319</th>\n",
              "      <td>-0.057457</td>\n",
              "      <td>-0.065629</td>\n",
              "      <td>-0.101198</td>\n",
              "      <td>-0.114176</td>\n",
              "      <td>-0.141093</td>\n",
              "      <td>-0.184354</td>\n",
              "      <td>-0.222807</td>\n",
              "      <td>-0.230017</td>\n",
              "      <td>-0.242514</td>\n",
              "      <td>-0.231459</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.085817</td>\n",
              "      <td>-0.068993</td>\n",
              "      <td>-0.058899</td>\n",
              "      <td>-0.043999</td>\n",
              "      <td>-0.058419</td>\n",
              "      <td>-0.065629</td>\n",
              "      <td>-0.070916</td>\n",
              "      <td>-0.068513</td>\n",
              "      <td>-0.090143</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17826</th>\n",
              "      <td>-0.065742</td>\n",
              "      <td>-0.082698</td>\n",
              "      <td>-0.086365</td>\n",
              "      <td>-0.053368</td>\n",
              "      <td>-0.023122</td>\n",
              "      <td>-0.024038</td>\n",
              "      <td>-0.046494</td>\n",
              "      <td>-0.133109</td>\n",
              "      <td>-0.211476</td>\n",
              "      <td>-0.300383</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.135401</td>\n",
              "      <td>-0.128985</td>\n",
              "      <td>-0.091864</td>\n",
              "      <td>-0.071700</td>\n",
              "      <td>-0.102404</td>\n",
              "      <td>-0.157398</td>\n",
              "      <td>-0.150524</td>\n",
              "      <td>-0.087281</td>\n",
              "      <td>-0.042828</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>116718 rows × 3001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e4f73c6-3964-43c0-b747-ec84c5552312')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e4f73c6-3964-43c0-b747-ec84c5552312 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e4f73c6-3964-43c0-b747-ec84c5552312');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#could save this to drive only after deleting transfer_set_50_subs.csv from drive (have a backup of this on pc/hard disc)"
      ],
      "metadata": {
        "id": "RpRGuPlSKksU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_transfer_set.to_csv(r'/gdrive/My Drive/physionet/ensemble/50_subs/original_bootstrapped_50_subs_transfer_set.csv', header=False, index=False) #original_50_subs_transfer_set.csv"
      ],
      "metadata": {
        "id": "nhnwvwqQzOMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_dt_transfer=dt_transfer_set.drop('sleep_stage',axis=1)\n",
        "y_dt_transfer=dt_transfer_set['sleep_stage']"
      ],
      "metadata": {
        "id": "1bmah1OTMcw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_dt_transfer_=np_utils.to_categorical(y_dt_transfer)"
      ],
      "metadata": {
        "id": "tIzkDIywNDxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_dt_transfer_rshp=np.array(x_dt_transfer).reshape(116718,3000,1)"
      ],
      "metadata": {
        "id": "GR3hhuxNND0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp_X_sub_466 = np.array([butter_bandpass_filter(sample, highpass=40.0, fs=100, order=4) for sample in X_sub_466])\n",
        "\n",
        "if VBS:\n",
        "    print(pp_X_sub_466.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFj97k-KND2y",
        "outputId": "7942d38d-1e9a-43c1-c289-2caf9fea1542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4020, 3000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp_X_sub_466"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncGgtqZ4cz8T",
        "outputId": "e231538b-91f7-4456-9ab1-48a0c60d3f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.09327535],\n",
              "        [-0.18087695],\n",
              "        [-0.03397775],\n",
              "        ...,\n",
              "        [-0.07818146],\n",
              "        [-0.02995923],\n",
              "        [-0.17060739]],\n",
              "\n",
              "       [[-0.09961356],\n",
              "        [-0.18891398],\n",
              "        [-0.07818146],\n",
              "        ...,\n",
              "        [ 0.08389881],\n",
              "        [-0.03888928],\n",
              "        [-0.0442473 ]],\n",
              "\n",
              "       [[-0.06746541],\n",
              "        [ 0.00308192],\n",
              "        [ 0.00084941],\n",
              "        ...,\n",
              "        [ 0.07898729],\n",
              "        [-0.05853537],\n",
              "        [ 0.04594613]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.10104849],\n",
              "        [ 0.09743289],\n",
              "        [ 0.07091844],\n",
              "        ...,\n",
              "        [ 0.10185196],\n",
              "        [ 0.05404561],\n",
              "        [ 0.02833462]],\n",
              "\n",
              "       [[ 0.04199358],\n",
              "        [ 0.05002827],\n",
              "        [ 0.04520746],\n",
              "        ...,\n",
              "        [-0.23158733],\n",
              "        [-0.20788502],\n",
              "        [-0.17012202]],\n",
              "\n",
              "       [[-0.02750641],\n",
              "        [-0.10343415],\n",
              "        [ 0.01949647],\n",
              "        ...,\n",
              "        [ 0.0162826 ],\n",
              "        [ 0.09180861],\n",
              "        [ 0.17135196]]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_sub_466_=np_utils.to_categorical(y_sub_466)"
      ],
      "metadata": {
        "id": "_kAlaiwMcz_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_sub_466_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AIBDHY-c0EA",
        "outputId": "94b239bd-ec95-4fc5-c794-61986bf36fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp_X_sub_466_rshp=pp_X_sub_466.reshape(4020, 3000)"
      ],
      "metadata": {
        "id": "agj5E2RnHbwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp_X_sub_466_rshp_df=pd.DataFrame(pp_X_sub_466_rshp)"
      ],
      "metadata": {
        "id": "UNtb-Ft3HbzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp_X_sub_466_rshp_df['sleep_stage']=y_sub_466"
      ],
      "metadata": {
        "id": "VkTQsh6rHb13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp_X_sub_466_rshp_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "BD7C6WWrIAf8",
        "outputId": "0785b533-7760-4af2-e925-861b57c54ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "0     0.093275 -0.180877 -0.033978  0.000849 -0.034871 -0.049605 -0.036210   \n",
              "1    -0.099614 -0.188914 -0.078181 -0.035764 -0.118813 -0.025941 -0.074609   \n",
              "2    -0.067465  0.003082  0.000849  0.005761 -0.160784 -0.325097 -0.310363   \n",
              "3    -0.097381  0.036123 -0.029513 -0.051838 -0.020136 -0.023262 -0.087558   \n",
              "4     0.097740  0.166948  0.161144  0.273662  0.258035  0.262946  0.345103   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "4015  0.230809  0.187421  0.236835  0.135598  0.129973  0.151265  0.097433   \n",
              "4016 -0.020677 -0.017061 -0.017463  0.024719 -0.007821 -0.023891 -0.026301   \n",
              "4017  0.101048  0.097433  0.070918  0.067705  0.068106  0.066098  0.061277   \n",
              "4018  0.041994  0.050028  0.045207  0.037575  0.066499  0.019496  0.060072   \n",
              "4019 -0.027506 -0.103434  0.019496 -0.038755 -0.018267 -0.058038  0.054849   \n",
              "\n",
              "             7         8         9  ...      2991      2992      2993  \\\n",
              "0    -0.154533 -0.082646  0.106670  ...  0.001296  0.001742  0.090150   \n",
              "1    -0.088898 -0.105418 -0.028173  ... -0.037996 -0.084432 -0.098721   \n",
              "2    -0.283126 -0.271070 -0.086665  ...  0.029426  0.097294  0.066932   \n",
              "3    -0.021029 -0.051391 -0.043801  ...  0.053983  0.078541  0.112921   \n",
              "4     0.166055  0.241068  0.243747  ...  0.100419  0.173199  0.189273   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "4015  0.127563  0.107476  0.072124  ...  0.020300 -0.054423 -0.009428   \n",
              "4016 -0.016258 -0.013847 -0.081339  ...  0.084577  0.071320  0.060473   \n",
              "4017  0.016684  0.004231  0.036771  ...  0.105066  0.109083  0.071722   \n",
              "4018  0.114707  0.084577  0.024317  ... -0.035943 -0.031925 -0.035943   \n",
              "4019  0.088595  0.134392  0.119528  ...  0.056456 -0.028712  0.137606   \n",
              "\n",
              "          2994      2995      2996      2997      2998      2999  sleep_stage  \n",
              "0    -0.022815 -0.059428 -0.107651 -0.078181 -0.029959 -0.170607            0  \n",
              "1    -0.040675 -0.061214 -0.095595  0.083899 -0.038889 -0.044247            0  \n",
              "2     0.064699  0.052197  0.115600  0.078987 -0.058535  0.045946            0  \n",
              "3     0.079880  0.052197  0.054876  0.053537  0.051751  0.147302            0  \n",
              "4     0.225440  0.186148  0.169627  0.196417  0.158018  0.100419            0  \n",
              "...        ...       ...       ...       ...       ...       ...          ...  \n",
              "4015 -0.007821  0.029942 -0.009428  0.004231 -0.012241 -0.016660            0  \n",
              "4016  0.012265  0.026728  0.033959  0.073731  0.068106  0.109083            0  \n",
              "4017  0.070115  0.105468  0.068508  0.101852  0.054046  0.028335            0  \n",
              "4018 -0.096605 -0.197842 -0.185790 -0.231587 -0.207885 -0.170122            0  \n",
              "4019  0.027933  0.157693  0.079355  0.016283  0.091809  0.171352            0  \n",
              "\n",
              "[4020 rows x 3001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b8879bb-731e-4765-bf79-6bfe9bb0c28b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>2991</th>\n",
              "      <th>2992</th>\n",
              "      <th>2993</th>\n",
              "      <th>2994</th>\n",
              "      <th>2995</th>\n",
              "      <th>2996</th>\n",
              "      <th>2997</th>\n",
              "      <th>2998</th>\n",
              "      <th>2999</th>\n",
              "      <th>sleep_stage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.093275</td>\n",
              "      <td>-0.180877</td>\n",
              "      <td>-0.033978</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>-0.034871</td>\n",
              "      <td>-0.049605</td>\n",
              "      <td>-0.036210</td>\n",
              "      <td>-0.154533</td>\n",
              "      <td>-0.082646</td>\n",
              "      <td>0.106670</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001296</td>\n",
              "      <td>0.001742</td>\n",
              "      <td>0.090150</td>\n",
              "      <td>-0.022815</td>\n",
              "      <td>-0.059428</td>\n",
              "      <td>-0.107651</td>\n",
              "      <td>-0.078181</td>\n",
              "      <td>-0.029959</td>\n",
              "      <td>-0.170607</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.099614</td>\n",
              "      <td>-0.188914</td>\n",
              "      <td>-0.078181</td>\n",
              "      <td>-0.035764</td>\n",
              "      <td>-0.118813</td>\n",
              "      <td>-0.025941</td>\n",
              "      <td>-0.074609</td>\n",
              "      <td>-0.088898</td>\n",
              "      <td>-0.105418</td>\n",
              "      <td>-0.028173</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.037996</td>\n",
              "      <td>-0.084432</td>\n",
              "      <td>-0.098721</td>\n",
              "      <td>-0.040675</td>\n",
              "      <td>-0.061214</td>\n",
              "      <td>-0.095595</td>\n",
              "      <td>0.083899</td>\n",
              "      <td>-0.038889</td>\n",
              "      <td>-0.044247</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.067465</td>\n",
              "      <td>0.003082</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>-0.160784</td>\n",
              "      <td>-0.325097</td>\n",
              "      <td>-0.310363</td>\n",
              "      <td>-0.283126</td>\n",
              "      <td>-0.271070</td>\n",
              "      <td>-0.086665</td>\n",
              "      <td>...</td>\n",
              "      <td>0.029426</td>\n",
              "      <td>0.097294</td>\n",
              "      <td>0.066932</td>\n",
              "      <td>0.064699</td>\n",
              "      <td>0.052197</td>\n",
              "      <td>0.115600</td>\n",
              "      <td>0.078987</td>\n",
              "      <td>-0.058535</td>\n",
              "      <td>0.045946</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.097381</td>\n",
              "      <td>0.036123</td>\n",
              "      <td>-0.029513</td>\n",
              "      <td>-0.051838</td>\n",
              "      <td>-0.020136</td>\n",
              "      <td>-0.023262</td>\n",
              "      <td>-0.087558</td>\n",
              "      <td>-0.021029</td>\n",
              "      <td>-0.051391</td>\n",
              "      <td>-0.043801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.053983</td>\n",
              "      <td>0.078541</td>\n",
              "      <td>0.112921</td>\n",
              "      <td>0.079880</td>\n",
              "      <td>0.052197</td>\n",
              "      <td>0.054876</td>\n",
              "      <td>0.053537</td>\n",
              "      <td>0.051751</td>\n",
              "      <td>0.147302</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.097740</td>\n",
              "      <td>0.166948</td>\n",
              "      <td>0.161144</td>\n",
              "      <td>0.273662</td>\n",
              "      <td>0.258035</td>\n",
              "      <td>0.262946</td>\n",
              "      <td>0.345103</td>\n",
              "      <td>0.166055</td>\n",
              "      <td>0.241068</td>\n",
              "      <td>0.243747</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100419</td>\n",
              "      <td>0.173199</td>\n",
              "      <td>0.189273</td>\n",
              "      <td>0.225440</td>\n",
              "      <td>0.186148</td>\n",
              "      <td>0.169627</td>\n",
              "      <td>0.196417</td>\n",
              "      <td>0.158018</td>\n",
              "      <td>0.100419</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4015</th>\n",
              "      <td>0.230809</td>\n",
              "      <td>0.187421</td>\n",
              "      <td>0.236835</td>\n",
              "      <td>0.135598</td>\n",
              "      <td>0.129973</td>\n",
              "      <td>0.151265</td>\n",
              "      <td>0.097433</td>\n",
              "      <td>0.127563</td>\n",
              "      <td>0.107476</td>\n",
              "      <td>0.072124</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020300</td>\n",
              "      <td>-0.054423</td>\n",
              "      <td>-0.009428</td>\n",
              "      <td>-0.007821</td>\n",
              "      <td>0.029942</td>\n",
              "      <td>-0.009428</td>\n",
              "      <td>0.004231</td>\n",
              "      <td>-0.012241</td>\n",
              "      <td>-0.016660</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4016</th>\n",
              "      <td>-0.020677</td>\n",
              "      <td>-0.017061</td>\n",
              "      <td>-0.017463</td>\n",
              "      <td>0.024719</td>\n",
              "      <td>-0.007821</td>\n",
              "      <td>-0.023891</td>\n",
              "      <td>-0.026301</td>\n",
              "      <td>-0.016258</td>\n",
              "      <td>-0.013847</td>\n",
              "      <td>-0.081339</td>\n",
              "      <td>...</td>\n",
              "      <td>0.084577</td>\n",
              "      <td>0.071320</td>\n",
              "      <td>0.060473</td>\n",
              "      <td>0.012265</td>\n",
              "      <td>0.026728</td>\n",
              "      <td>0.033959</td>\n",
              "      <td>0.073731</td>\n",
              "      <td>0.068106</td>\n",
              "      <td>0.109083</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4017</th>\n",
              "      <td>0.101048</td>\n",
              "      <td>0.097433</td>\n",
              "      <td>0.070918</td>\n",
              "      <td>0.067705</td>\n",
              "      <td>0.068106</td>\n",
              "      <td>0.066098</td>\n",
              "      <td>0.061277</td>\n",
              "      <td>0.016684</td>\n",
              "      <td>0.004231</td>\n",
              "      <td>0.036771</td>\n",
              "      <td>...</td>\n",
              "      <td>0.105066</td>\n",
              "      <td>0.109083</td>\n",
              "      <td>0.071722</td>\n",
              "      <td>0.070115</td>\n",
              "      <td>0.105468</td>\n",
              "      <td>0.068508</td>\n",
              "      <td>0.101852</td>\n",
              "      <td>0.054046</td>\n",
              "      <td>0.028335</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4018</th>\n",
              "      <td>0.041994</td>\n",
              "      <td>0.050028</td>\n",
              "      <td>0.045207</td>\n",
              "      <td>0.037575</td>\n",
              "      <td>0.066499</td>\n",
              "      <td>0.019496</td>\n",
              "      <td>0.060072</td>\n",
              "      <td>0.114707</td>\n",
              "      <td>0.084577</td>\n",
              "      <td>0.024317</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.035943</td>\n",
              "      <td>-0.031925</td>\n",
              "      <td>-0.035943</td>\n",
              "      <td>-0.096605</td>\n",
              "      <td>-0.197842</td>\n",
              "      <td>-0.185790</td>\n",
              "      <td>-0.231587</td>\n",
              "      <td>-0.207885</td>\n",
              "      <td>-0.170122</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4019</th>\n",
              "      <td>-0.027506</td>\n",
              "      <td>-0.103434</td>\n",
              "      <td>0.019496</td>\n",
              "      <td>-0.038755</td>\n",
              "      <td>-0.018267</td>\n",
              "      <td>-0.058038</td>\n",
              "      <td>0.054849</td>\n",
              "      <td>0.088595</td>\n",
              "      <td>0.134392</td>\n",
              "      <td>0.119528</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056456</td>\n",
              "      <td>-0.028712</td>\n",
              "      <td>0.137606</td>\n",
              "      <td>0.027933</td>\n",
              "      <td>0.157693</td>\n",
              "      <td>0.079355</td>\n",
              "      <td>0.016283</td>\n",
              "      <td>0.091809</td>\n",
              "      <td>0.171352</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4020 rows × 3001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b8879bb-731e-4765-bf79-6bfe9bb0c28b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b8879bb-731e-4765-bf79-6bfe9bb0c28b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b8879bb-731e-4765-bf79-6bfe9bb0c28b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp_X_sub_466_rshp_df.to_csv(r'/content/gdrive/My Drive/physionet/ensemble/50_subs/subject_466_dataset.csv', header=False, index=False)"
      ],
      "metadata": {
        "id": "Ng6zQ4JhIAit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp_X_sub_466_rshp_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "s3t3jXvZIAl3",
        "outputId": "84dcda46-927b-4e51-cca1-e1d42b4279aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "0     0.093275 -0.180877 -0.033978  0.000849 -0.034871 -0.049605 -0.036210   \n",
              "1    -0.099614 -0.188914 -0.078181 -0.035764 -0.118813 -0.025941 -0.074609   \n",
              "2    -0.067465  0.003082  0.000849  0.005761 -0.160784 -0.325097 -0.310363   \n",
              "3    -0.097381  0.036123 -0.029513 -0.051838 -0.020136 -0.023262 -0.087558   \n",
              "4     0.097740  0.166948  0.161144  0.273662  0.258035  0.262946  0.345103   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "4015  0.230809  0.187421  0.236835  0.135598  0.129973  0.151265  0.097433   \n",
              "4016 -0.020677 -0.017061 -0.017463  0.024719 -0.007821 -0.023891 -0.026301   \n",
              "4017  0.101048  0.097433  0.070918  0.067705  0.068106  0.066098  0.061277   \n",
              "4018  0.041994  0.050028  0.045207  0.037575  0.066499  0.019496  0.060072   \n",
              "4019 -0.027506 -0.103434  0.019496 -0.038755 -0.018267 -0.058038  0.054849   \n",
              "\n",
              "             7         8         9  ...      2991      2992      2993  \\\n",
              "0    -0.154533 -0.082646  0.106670  ...  0.001296  0.001742  0.090150   \n",
              "1    -0.088898 -0.105418 -0.028173  ... -0.037996 -0.084432 -0.098721   \n",
              "2    -0.283126 -0.271070 -0.086665  ...  0.029426  0.097294  0.066932   \n",
              "3    -0.021029 -0.051391 -0.043801  ...  0.053983  0.078541  0.112921   \n",
              "4     0.166055  0.241068  0.243747  ...  0.100419  0.173199  0.189273   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "4015  0.127563  0.107476  0.072124  ...  0.020300 -0.054423 -0.009428   \n",
              "4016 -0.016258 -0.013847 -0.081339  ...  0.084577  0.071320  0.060473   \n",
              "4017  0.016684  0.004231  0.036771  ...  0.105066  0.109083  0.071722   \n",
              "4018  0.114707  0.084577  0.024317  ... -0.035943 -0.031925 -0.035943   \n",
              "4019  0.088595  0.134392  0.119528  ...  0.056456 -0.028712  0.137606   \n",
              "\n",
              "          2994      2995      2996      2997      2998      2999  sleep_stage  \n",
              "0    -0.022815 -0.059428 -0.107651 -0.078181 -0.029959 -0.170607            0  \n",
              "1    -0.040675 -0.061214 -0.095595  0.083899 -0.038889 -0.044247            0  \n",
              "2     0.064699  0.052197  0.115600  0.078987 -0.058535  0.045946            0  \n",
              "3     0.079880  0.052197  0.054876  0.053537  0.051751  0.147302            0  \n",
              "4     0.225440  0.186148  0.169627  0.196417  0.158018  0.100419            0  \n",
              "...        ...       ...       ...       ...       ...       ...          ...  \n",
              "4015 -0.007821  0.029942 -0.009428  0.004231 -0.012241 -0.016660            0  \n",
              "4016  0.012265  0.026728  0.033959  0.073731  0.068106  0.109083            0  \n",
              "4017  0.070115  0.105468  0.068508  0.101852  0.054046  0.028335            0  \n",
              "4018 -0.096605 -0.197842 -0.185790 -0.231587 -0.207885 -0.170122            0  \n",
              "4019  0.027933  0.157693  0.079355  0.016283  0.091809  0.171352            0  \n",
              "\n",
              "[4020 rows x 3001 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5092d22-7a67-4a83-82e3-1eeea0f6c5e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>2991</th>\n",
              "      <th>2992</th>\n",
              "      <th>2993</th>\n",
              "      <th>2994</th>\n",
              "      <th>2995</th>\n",
              "      <th>2996</th>\n",
              "      <th>2997</th>\n",
              "      <th>2998</th>\n",
              "      <th>2999</th>\n",
              "      <th>sleep_stage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.093275</td>\n",
              "      <td>-0.180877</td>\n",
              "      <td>-0.033978</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>-0.034871</td>\n",
              "      <td>-0.049605</td>\n",
              "      <td>-0.036210</td>\n",
              "      <td>-0.154533</td>\n",
              "      <td>-0.082646</td>\n",
              "      <td>0.106670</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001296</td>\n",
              "      <td>0.001742</td>\n",
              "      <td>0.090150</td>\n",
              "      <td>-0.022815</td>\n",
              "      <td>-0.059428</td>\n",
              "      <td>-0.107651</td>\n",
              "      <td>-0.078181</td>\n",
              "      <td>-0.029959</td>\n",
              "      <td>-0.170607</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.099614</td>\n",
              "      <td>-0.188914</td>\n",
              "      <td>-0.078181</td>\n",
              "      <td>-0.035764</td>\n",
              "      <td>-0.118813</td>\n",
              "      <td>-0.025941</td>\n",
              "      <td>-0.074609</td>\n",
              "      <td>-0.088898</td>\n",
              "      <td>-0.105418</td>\n",
              "      <td>-0.028173</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.037996</td>\n",
              "      <td>-0.084432</td>\n",
              "      <td>-0.098721</td>\n",
              "      <td>-0.040675</td>\n",
              "      <td>-0.061214</td>\n",
              "      <td>-0.095595</td>\n",
              "      <td>0.083899</td>\n",
              "      <td>-0.038889</td>\n",
              "      <td>-0.044247</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.067465</td>\n",
              "      <td>0.003082</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>-0.160784</td>\n",
              "      <td>-0.325097</td>\n",
              "      <td>-0.310363</td>\n",
              "      <td>-0.283126</td>\n",
              "      <td>-0.271070</td>\n",
              "      <td>-0.086665</td>\n",
              "      <td>...</td>\n",
              "      <td>0.029426</td>\n",
              "      <td>0.097294</td>\n",
              "      <td>0.066932</td>\n",
              "      <td>0.064699</td>\n",
              "      <td>0.052197</td>\n",
              "      <td>0.115600</td>\n",
              "      <td>0.078987</td>\n",
              "      <td>-0.058535</td>\n",
              "      <td>0.045946</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.097381</td>\n",
              "      <td>0.036123</td>\n",
              "      <td>-0.029513</td>\n",
              "      <td>-0.051838</td>\n",
              "      <td>-0.020136</td>\n",
              "      <td>-0.023262</td>\n",
              "      <td>-0.087558</td>\n",
              "      <td>-0.021029</td>\n",
              "      <td>-0.051391</td>\n",
              "      <td>-0.043801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.053983</td>\n",
              "      <td>0.078541</td>\n",
              "      <td>0.112921</td>\n",
              "      <td>0.079880</td>\n",
              "      <td>0.052197</td>\n",
              "      <td>0.054876</td>\n",
              "      <td>0.053537</td>\n",
              "      <td>0.051751</td>\n",
              "      <td>0.147302</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.097740</td>\n",
              "      <td>0.166948</td>\n",
              "      <td>0.161144</td>\n",
              "      <td>0.273662</td>\n",
              "      <td>0.258035</td>\n",
              "      <td>0.262946</td>\n",
              "      <td>0.345103</td>\n",
              "      <td>0.166055</td>\n",
              "      <td>0.241068</td>\n",
              "      <td>0.243747</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100419</td>\n",
              "      <td>0.173199</td>\n",
              "      <td>0.189273</td>\n",
              "      <td>0.225440</td>\n",
              "      <td>0.186148</td>\n",
              "      <td>0.169627</td>\n",
              "      <td>0.196417</td>\n",
              "      <td>0.158018</td>\n",
              "      <td>0.100419</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4015</th>\n",
              "      <td>0.230809</td>\n",
              "      <td>0.187421</td>\n",
              "      <td>0.236835</td>\n",
              "      <td>0.135598</td>\n",
              "      <td>0.129973</td>\n",
              "      <td>0.151265</td>\n",
              "      <td>0.097433</td>\n",
              "      <td>0.127563</td>\n",
              "      <td>0.107476</td>\n",
              "      <td>0.072124</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020300</td>\n",
              "      <td>-0.054423</td>\n",
              "      <td>-0.009428</td>\n",
              "      <td>-0.007821</td>\n",
              "      <td>0.029942</td>\n",
              "      <td>-0.009428</td>\n",
              "      <td>0.004231</td>\n",
              "      <td>-0.012241</td>\n",
              "      <td>-0.016660</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4016</th>\n",
              "      <td>-0.020677</td>\n",
              "      <td>-0.017061</td>\n",
              "      <td>-0.017463</td>\n",
              "      <td>0.024719</td>\n",
              "      <td>-0.007821</td>\n",
              "      <td>-0.023891</td>\n",
              "      <td>-0.026301</td>\n",
              "      <td>-0.016258</td>\n",
              "      <td>-0.013847</td>\n",
              "      <td>-0.081339</td>\n",
              "      <td>...</td>\n",
              "      <td>0.084577</td>\n",
              "      <td>0.071320</td>\n",
              "      <td>0.060473</td>\n",
              "      <td>0.012265</td>\n",
              "      <td>0.026728</td>\n",
              "      <td>0.033959</td>\n",
              "      <td>0.073731</td>\n",
              "      <td>0.068106</td>\n",
              "      <td>0.109083</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4017</th>\n",
              "      <td>0.101048</td>\n",
              "      <td>0.097433</td>\n",
              "      <td>0.070918</td>\n",
              "      <td>0.067705</td>\n",
              "      <td>0.068106</td>\n",
              "      <td>0.066098</td>\n",
              "      <td>0.061277</td>\n",
              "      <td>0.016684</td>\n",
              "      <td>0.004231</td>\n",
              "      <td>0.036771</td>\n",
              "      <td>...</td>\n",
              "      <td>0.105066</td>\n",
              "      <td>0.109083</td>\n",
              "      <td>0.071722</td>\n",
              "      <td>0.070115</td>\n",
              "      <td>0.105468</td>\n",
              "      <td>0.068508</td>\n",
              "      <td>0.101852</td>\n",
              "      <td>0.054046</td>\n",
              "      <td>0.028335</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4018</th>\n",
              "      <td>0.041994</td>\n",
              "      <td>0.050028</td>\n",
              "      <td>0.045207</td>\n",
              "      <td>0.037575</td>\n",
              "      <td>0.066499</td>\n",
              "      <td>0.019496</td>\n",
              "      <td>0.060072</td>\n",
              "      <td>0.114707</td>\n",
              "      <td>0.084577</td>\n",
              "      <td>0.024317</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.035943</td>\n",
              "      <td>-0.031925</td>\n",
              "      <td>-0.035943</td>\n",
              "      <td>-0.096605</td>\n",
              "      <td>-0.197842</td>\n",
              "      <td>-0.185790</td>\n",
              "      <td>-0.231587</td>\n",
              "      <td>-0.207885</td>\n",
              "      <td>-0.170122</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4019</th>\n",
              "      <td>-0.027506</td>\n",
              "      <td>-0.103434</td>\n",
              "      <td>0.019496</td>\n",
              "      <td>-0.038755</td>\n",
              "      <td>-0.018267</td>\n",
              "      <td>-0.058038</td>\n",
              "      <td>0.054849</td>\n",
              "      <td>0.088595</td>\n",
              "      <td>0.134392</td>\n",
              "      <td>0.119528</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056456</td>\n",
              "      <td>-0.028712</td>\n",
              "      <td>0.137606</td>\n",
              "      <td>0.027933</td>\n",
              "      <td>0.157693</td>\n",
              "      <td>0.079355</td>\n",
              "      <td>0.016283</td>\n",
              "      <td>0.091809</td>\n",
              "      <td>0.171352</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4020 rows × 3001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5092d22-7a67-4a83-82e3-1eeea0f6c5e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5092d22-7a67-4a83-82e3-1eeea0f6c5e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5092d22-7a67-4a83-82e3-1eeea0f6c5e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(999)\n",
        "\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(999)\n",
        "\n",
        "import random\n",
        "#random.seed(999)"
      ],
      "metadata": {
        "id": "cTa5UK_WOzj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "metadata": {
        "id": "hCOUBtpWOzl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6d20950-882e-4eb7-b649-894af7b1a5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-ilshgyii\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-ilshgyii\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.8.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101077 sha256=6d0a9bc212823d475a0b79ffa466e369e157daa4a432357831731037d4708a13\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f7k7sfo4/wheels/bb/1f/f2/b57495012683b6b20bbae94a3915ec79753111452d79886abc\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers, losses, activations, models\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import GlobalMaxPool1D, GlobalAveragePooling1D, concatenate, SpatialDropout1D, TimeDistributed, Bidirectional, LSTM\n",
        "from tensorflow.keras.layers import Input, Conv1D, Dense, Dropout, MaxPool1D, Activation\n",
        "from tensorflow.keras.layers import Reshape, LSTM, TimeDistributed, Bidirectional, BatchNormalization, Flatten, RepeatVector\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#from keras_contrib.layers import CRF\n",
        "\n",
        "from scipy.signal import butter, lfilter\n"
      ],
      "metadata": {
        "id": "3kadsNLOgIRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Fs = 100"
      ],
      "metadata": {
        "id": "IEepNLUAOzrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_shuf1=model_b(verbose=VBS)\n",
        "loaded_model_shuf2=model_b(verbose=VBS)\n",
        "loaded_model_shuf3=model_b(verbose=VBS)"
      ],
      "metadata": {
        "id": "emkAGe5zPOFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28416c4e-b44f-464e-efe6-22ffdc6e796f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inLayer (InputLayer)           [(None, 3000, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " fConv1 (Conv1D)                (None, 500, 64)      3264        ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " cConv1 (Conv1D)                (None, 60, 32)       12832       ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " fMaxP1 (MaxPooling1D)          (None, 62, 64)       0           ['fConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP1 (MaxPooling1D)          (None, 15, 32)       0           ['cConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " fDrop1 (Dropout)               (None, 62, 64)       0           ['fMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " cDrop1 (Dropout)               (None, 15, 32)       0           ['cMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv2 (Conv1D)                (None, 62, 128)      65664       ['fDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv2 (Conv1D)                (None, 15, 128)      24704       ['cDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv3 (Conv1D)                (None, 62, 128)      131200      ['fConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv3 (Conv1D)                (None, 15, 128)      98432       ['cConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv4 (Conv1D)                (None, 62, 128)      131200      ['fConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv4 (Conv1D)                (None, 15, 128)      98432       ['cConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " fMaxP2 (MaxPooling1D)          (None, 15, 128)      0           ['fConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP2 (MaxPooling1D)          (None, 7, 128)       0           ['cConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " fFlat1 (Flatten)               (None, 1920)         0           ['fMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " cFlat1 (Flatten)               (None, 896)          0           ['cMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " merge_1 (Concatenate)          (None, 2816)         0           ['fFlat1[0][0]',                 \n",
            "                                                                  'cFlat1[0][0]']                 \n",
            "                                                                                                  \n",
            " mDrop1 (Dropout)               (None, 2816)         0           ['merge_1[0][0]']                \n",
            "                                                                                                  \n",
            " reshape1 (Reshape)             (None, 1, 2816)      0           ['mDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 1, 64)        737536      ['reshape1[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 64)           33024       ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " outLayer (Dense)               (None, 5)            325         ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,336,613\n",
            "Trainable params: 1,336,613\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inLayer (InputLayer)           [(None, 3000, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " fConv1 (Conv1D)                (None, 500, 64)      3264        ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " cConv1 (Conv1D)                (None, 60, 32)       12832       ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " fMaxP1 (MaxPooling1D)          (None, 62, 64)       0           ['fConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP1 (MaxPooling1D)          (None, 15, 32)       0           ['cConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " fDrop1 (Dropout)               (None, 62, 64)       0           ['fMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " cDrop1 (Dropout)               (None, 15, 32)       0           ['cMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv2 (Conv1D)                (None, 62, 128)      65664       ['fDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv2 (Conv1D)                (None, 15, 128)      24704       ['cDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv3 (Conv1D)                (None, 62, 128)      131200      ['fConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv3 (Conv1D)                (None, 15, 128)      98432       ['cConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv4 (Conv1D)                (None, 62, 128)      131200      ['fConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv4 (Conv1D)                (None, 15, 128)      98432       ['cConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " fMaxP2 (MaxPooling1D)          (None, 15, 128)      0           ['fConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP2 (MaxPooling1D)          (None, 7, 128)       0           ['cConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " fFlat1 (Flatten)               (None, 1920)         0           ['fMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " cFlat1 (Flatten)               (None, 896)          0           ['cMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " merge_1 (Concatenate)          (None, 2816)         0           ['fFlat1[0][0]',                 \n",
            "                                                                  'cFlat1[0][0]']                 \n",
            "                                                                                                  \n",
            " mDrop1 (Dropout)               (None, 2816)         0           ['merge_1[0][0]']                \n",
            "                                                                                                  \n",
            " reshape1 (Reshape)             (None, 1, 2816)      0           ['mDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 1, 64)        737536      ['reshape1[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, 64)           33024       ['lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " outLayer (Dense)               (None, 5)            325         ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,336,613\n",
            "Trainable params: 1,336,613\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inLayer (InputLayer)           [(None, 3000, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " fConv1 (Conv1D)                (None, 500, 64)      3264        ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " cConv1 (Conv1D)                (None, 60, 32)       12832       ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " fMaxP1 (MaxPooling1D)          (None, 62, 64)       0           ['fConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP1 (MaxPooling1D)          (None, 15, 32)       0           ['cConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " fDrop1 (Dropout)               (None, 62, 64)       0           ['fMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " cDrop1 (Dropout)               (None, 15, 32)       0           ['cMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv2 (Conv1D)                (None, 62, 128)      65664       ['fDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv2 (Conv1D)                (None, 15, 128)      24704       ['cDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv3 (Conv1D)                (None, 62, 128)      131200      ['fConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv3 (Conv1D)                (None, 15, 128)      98432       ['cConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv4 (Conv1D)                (None, 62, 128)      131200      ['fConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv4 (Conv1D)                (None, 15, 128)      98432       ['cConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " fMaxP2 (MaxPooling1D)          (None, 15, 128)      0           ['fConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP2 (MaxPooling1D)          (None, 7, 128)       0           ['cConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " fFlat1 (Flatten)               (None, 1920)         0           ['fMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " cFlat1 (Flatten)               (None, 896)          0           ['cMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " merge_1 (Concatenate)          (None, 2816)         0           ['fFlat1[0][0]',                 \n",
            "                                                                  'cFlat1[0][0]']                 \n",
            "                                                                                                  \n",
            " mDrop1 (Dropout)               (None, 2816)         0           ['merge_1[0][0]']                \n",
            "                                                                                                  \n",
            " reshape1 (Reshape)             (None, 1, 2816)      0           ['mDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  (None, 1, 64)        737536      ['reshape1[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)                  (None, 64)           33024       ['lstm_4[0][0]']                 \n",
            "                                                                                                  \n",
            " outLayer (Dense)               (None, 5)            325         ['lstm_5[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,336,613\n",
            "Trainable params: 1,336,613\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dt_shuf1\n",
        "checkpoint_path_load_model_30_epochs_shuf1 = \"/gdrive/My Drive/physionet/dt_shuf1_phy/sub_482_75th_sub_with_50_sub_tr_dt/weights-phy_shuf1_30_epochs.ckpt\"\n",
        "checkpoint_load_model_30_epochs_shuf1_dir = os.path.dirname(checkpoint_path_load_model_30_epochs_shuf1)\n",
        "#latest_30_epochs_shuf1_s828=tensorflow.train.latest_checkpoint(checkpoint_load_model_300_epochs_shuf1_s828_dir)\n",
        "print(checkpoint_path_load_model_30_epochs_shuf1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDjXTExmPBY-",
        "outputId": "d1cbecf4-a8f1-4eab-8aa0-75b805c50160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/physionet/dt_shuf1_phy/sub_482_75th_sub_with_50_sub_tr_dt/weights-phy_shuf1_30_epochs.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dt_shuf2\n",
        "checkpoint_path_load_model_30_epochs_shuf2 = \"/gdrive/My Drive/physionet/dt_shuf2_phy/sub_482_75th_sub_with_50_sub_tr_dt/weights-phy_shuf2_30_epochs.ckpt\"\n",
        "checkpoint_load_model_30_epochs_shuf2_dir = os.path.dirname(checkpoint_path_load_model_30_epochs_shuf2)\n",
        "#latest_300_epochs_shuf2_s828=tensorflow.train.latest_checkpoint(checkpoint_load_model_300_epochs_shuf2_s828_dir)\n",
        "print(checkpoint_path_load_model_30_epochs_shuf2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnwbQwuyP47_",
        "outputId": "c0a34f6d-ed2f-4db9-e48c-03462b4e4ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/physionet/dt_shuf2_phy/sub_482_75th_sub_with_50_sub_tr_dt/weights-phy_shuf2_30_epochs.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dt_shuf3\n",
        "checkpoint_path_load_model_30_epochs_shuf3 = \"/gdrive/My Drive/physionet/dt_shuf3_phy/sub_482_75th_sub_with_50_sub_tr_dt/weights-phy_shuf3_30_epochs.ckpt\"\n",
        "checkpoint_load_model_30_epochs_shuf3_dir = os.path.dirname(checkpoint_path_load_model_30_epochs_shuf3)\n",
        "#latest_300_epochs_shuf3_s828=tensorflow.train.latest_checkpoint(checkpoint_load_model_300_epochs_shuf3_s828_dir)\n",
        "print(checkpoint_path_load_model_30_epochs_shuf3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlGygP5UP4-Y",
        "outputId": "a88ef384-431d-4e4b-a5a6-7bcef8637378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/physionet/dt_shuf3_phy/sub_482_75th_sub_with_50_sub_tr_dt/weights-phy_shuf3_30_epochs.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_shuf1.load_weights(checkpoint_path_load_model_30_epochs_shuf1)\n",
        "loaded_model_shuf2.load_weights(checkpoint_path_load_model_30_epochs_shuf2)\n",
        "loaded_model_shuf3.load_weights(checkpoint_path_load_model_30_epochs_shuf3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzhS8srmUk5a",
        "outputId": "06e88ccf-3085-4033-c54a-bdfe5e7673ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f62b00d4810>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(lr=1e-4)"
      ],
      "metadata": {
        "id": "BjwgnUM_jPV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_shuf1.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "loaded_model_shuf2.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "loaded_model_shuf3.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VuHejhNsb3f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa090d1-1b86-4cdd-da5a-8edba994f73a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_shuf1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnO1a1g8VBKb",
        "outputId": "e0086923-f6d6-4faf-9b51-e7863a551cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inLayer (InputLayer)           [(None, 3000, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " fConv1 (Conv1D)                (None, 500, 64)      3264        ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " cConv1 (Conv1D)                (None, 60, 32)       12832       ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " fMaxP1 (MaxPooling1D)          (None, 62, 64)       0           ['fConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP1 (MaxPooling1D)          (None, 15, 32)       0           ['cConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " fDrop1 (Dropout)               (None, 62, 64)       0           ['fMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " cDrop1 (Dropout)               (None, 15, 32)       0           ['cMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv2 (Conv1D)                (None, 62, 128)      65664       ['fDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv2 (Conv1D)                (None, 15, 128)      24704       ['cDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv3 (Conv1D)                (None, 62, 128)      131200      ['fConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv3 (Conv1D)                (None, 15, 128)      98432       ['cConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv4 (Conv1D)                (None, 62, 128)      131200      ['fConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv4 (Conv1D)                (None, 15, 128)      98432       ['cConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " fMaxP2 (MaxPooling1D)          (None, 15, 128)      0           ['fConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP2 (MaxPooling1D)          (None, 7, 128)       0           ['cConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " fFlat1 (Flatten)               (None, 1920)         0           ['fMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " cFlat1 (Flatten)               (None, 896)          0           ['cMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " merge_1 (Concatenate)          (None, 2816)         0           ['fFlat1[0][0]',                 \n",
            "                                                                  'cFlat1[0][0]']                 \n",
            "                                                                                                  \n",
            " mDrop1 (Dropout)               (None, 2816)         0           ['merge_1[0][0]']                \n",
            "                                                                                                  \n",
            " reshape1 (Reshape)             (None, 1, 2816)      0           ['mDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 1, 64)        737536      ['reshape1[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 64)           33024       ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " outLayer (Dense)               (None, 5)            325         ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,336,613\n",
            "Trainable params: 1,336,613\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_shuf2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hSOlh2zVC-B",
        "outputId": "4b38f65c-4086-4e95-ace5-c5c5d58be206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inLayer (InputLayer)           [(None, 3000, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " fConv1 (Conv1D)                (None, 500, 64)      3264        ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " cConv1 (Conv1D)                (None, 60, 32)       12832       ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " fMaxP1 (MaxPooling1D)          (None, 62, 64)       0           ['fConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP1 (MaxPooling1D)          (None, 15, 32)       0           ['cConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " fDrop1 (Dropout)               (None, 62, 64)       0           ['fMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " cDrop1 (Dropout)               (None, 15, 32)       0           ['cMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv2 (Conv1D)                (None, 62, 128)      65664       ['fDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv2 (Conv1D)                (None, 15, 128)      24704       ['cDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv3 (Conv1D)                (None, 62, 128)      131200      ['fConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv3 (Conv1D)                (None, 15, 128)      98432       ['cConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv4 (Conv1D)                (None, 62, 128)      131200      ['fConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv4 (Conv1D)                (None, 15, 128)      98432       ['cConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " fMaxP2 (MaxPooling1D)          (None, 15, 128)      0           ['fConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP2 (MaxPooling1D)          (None, 7, 128)       0           ['cConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " fFlat1 (Flatten)               (None, 1920)         0           ['fMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " cFlat1 (Flatten)               (None, 896)          0           ['cMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " merge_1 (Concatenate)          (None, 2816)         0           ['fFlat1[0][0]',                 \n",
            "                                                                  'cFlat1[0][0]']                 \n",
            "                                                                                                  \n",
            " mDrop1 (Dropout)               (None, 2816)         0           ['merge_1[0][0]']                \n",
            "                                                                                                  \n",
            " reshape1 (Reshape)             (None, 1, 2816)      0           ['mDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 1, 64)        737536      ['reshape1[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, 64)           33024       ['lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " outLayer (Dense)               (None, 5)            325         ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,336,613\n",
            "Trainable params: 1,336,613\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_shuf3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R60Q60DDVFI4",
        "outputId": "8e42c533-ea39-4074-8aaf-6f98e6337f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inLayer (InputLayer)           [(None, 3000, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " fConv1 (Conv1D)                (None, 500, 64)      3264        ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " cConv1 (Conv1D)                (None, 60, 32)       12832       ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " fMaxP1 (MaxPooling1D)          (None, 62, 64)       0           ['fConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP1 (MaxPooling1D)          (None, 15, 32)       0           ['cConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " fDrop1 (Dropout)               (None, 62, 64)       0           ['fMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " cDrop1 (Dropout)               (None, 15, 32)       0           ['cMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv2 (Conv1D)                (None, 62, 128)      65664       ['fDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv2 (Conv1D)                (None, 15, 128)      24704       ['cDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv3 (Conv1D)                (None, 62, 128)      131200      ['fConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv3 (Conv1D)                (None, 15, 128)      98432       ['cConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv4 (Conv1D)                (None, 62, 128)      131200      ['fConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv4 (Conv1D)                (None, 15, 128)      98432       ['cConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " fMaxP2 (MaxPooling1D)          (None, 15, 128)      0           ['fConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP2 (MaxPooling1D)          (None, 7, 128)       0           ['cConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " fFlat1 (Flatten)               (None, 1920)         0           ['fMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " cFlat1 (Flatten)               (None, 896)          0           ['cMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " merge_1 (Concatenate)          (None, 2816)         0           ['fFlat1[0][0]',                 \n",
            "                                                                  'cFlat1[0][0]']                 \n",
            "                                                                                                  \n",
            " mDrop1 (Dropout)               (None, 2816)         0           ['merge_1[0][0]']                \n",
            "                                                                                                  \n",
            " reshape1 (Reshape)             (None, 1, 2816)      0           ['mDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  (None, 1, 64)        737536      ['reshape1[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)                  (None, 64)           33024       ['lstm_4[0][0]']                 \n",
            "                                                                                                  \n",
            " outLayer (Dense)               (None, 5)            325         ['lstm_5[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,336,613\n",
            "Trainable params: 1,336,613\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mode"
      ],
      "metadata": {
        "id": "jBnzGbAXP5BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp_X_sub_466.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEDDoSf9YZTo",
        "outputId": "b8d25140-6516-46b9-8e45-a23b0cafa550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4020, 3000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp_X_sub_466"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-VUZSBWYaiq",
        "outputId": "6bcd4f65-9ad9-486a-fd7b-484d5672d8a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.09327535],\n",
              "        [-0.18087695],\n",
              "        [-0.03397775],\n",
              "        ...,\n",
              "        [-0.07818146],\n",
              "        [-0.02995923],\n",
              "        [-0.17060739]],\n",
              "\n",
              "       [[-0.09961356],\n",
              "        [-0.18891398],\n",
              "        [-0.07818146],\n",
              "        ...,\n",
              "        [ 0.08389881],\n",
              "        [-0.03888928],\n",
              "        [-0.0442473 ]],\n",
              "\n",
              "       [[-0.06746541],\n",
              "        [ 0.00308192],\n",
              "        [ 0.00084941],\n",
              "        ...,\n",
              "        [ 0.07898729],\n",
              "        [-0.05853537],\n",
              "        [ 0.04594613]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.10104849],\n",
              "        [ 0.09743289],\n",
              "        [ 0.07091844],\n",
              "        ...,\n",
              "        [ 0.10185196],\n",
              "        [ 0.05404561],\n",
              "        [ 0.02833462]],\n",
              "\n",
              "       [[ 0.04199358],\n",
              "        [ 0.05002827],\n",
              "        [ 0.04520746],\n",
              "        ...,\n",
              "        [-0.23158733],\n",
              "        [-0.20788502],\n",
              "        [-0.17012202]],\n",
              "\n",
              "       [[-0.02750641],\n",
              "        [-0.10343415],\n",
              "        [ 0.01949647],\n",
              "        ...,\n",
              "        [ 0.0162826 ],\n",
              "        [ 0.09180861],\n",
              "        [ 0.17135196]]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_dt_transfer_rshp.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xr3L5u9P5E_",
        "outputId": "a37bfaf4-ec92-4119-fa7a-9fcd33f011c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(116718, 3000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_dt_transfer_rshp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMov29GuUEEs",
        "outputId": "a90ef2a9-eb3d-4b00-f15a-d8871bc05e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.0680144 ],\n",
              "        [ 0.08291509],\n",
              "        [ 0.07762775],\n",
              "        ...,\n",
              "        [-0.07714708],\n",
              "        [-0.08483776],\n",
              "        [-0.09012509]],\n",
              "\n",
              "       [[ 0.1047289 ],\n",
              "        [ 0.05451331],\n",
              "        [-0.02013147],\n",
              "        ...,\n",
              "        [-0.17123062],\n",
              "        [-0.14951577],\n",
              "        [-0.12146743]],\n",
              "\n",
              "       [[ 0.00228081],\n",
              "        [-0.03130934],\n",
              "        [-0.00767183],\n",
              "        ...,\n",
              "        [ 0.07277867],\n",
              "        [ 0.05536155],\n",
              "        [ 0.02965057]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.01339153],\n",
              "        [ 0.03071675],\n",
              "        [ 0.0298049 ],\n",
              "        ...,\n",
              "        [ 0.041659  ],\n",
              "        [ 0.03299639],\n",
              "        [ 0.02433378]],\n",
              "\n",
              "       [[-0.0574574 ],\n",
              "        [-0.06562874],\n",
              "        [-0.10119811],\n",
              "        ...,\n",
              "        [-0.07091608],\n",
              "        [-0.06851275],\n",
              "        [-0.09014277]],\n",
              "\n",
              "       [[-0.06574184],\n",
              "        [-0.08269832],\n",
              "        [-0.08636458],\n",
              "        ...,\n",
              "        [-0.15052423],\n",
              "        [-0.08728115],\n",
              "        [-0.04282768]]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "#tf.config.run_functions_eagerly(True)\n",
        "#tf.config.experimental_run_functions_eagerly(True)\n",
        "tf.data.experimental.enable_debug_mode()"
      ],
      "metadata": {
        "id": "qtB7dO6Id13x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_shuf1_model = loaded_model_shuf1.evaluate(pp_X_sub_482, y_sub_482_) #checking the model's perforamance on the subject dt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKnNSrWzbgYG",
        "outputId": "1093a33b-db37-4d13-f22f-b6e86ebd8807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96/96 [==============================] - 11s 13ms/step - loss: 0.4133 - accuracy: 0.8678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_shuf2_model = loaded_model_shuf2.evaluate(pp_X_sub_482, y_sub_482_)"
      ],
      "metadata": {
        "id": "oBAmU-LzpU5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_shuf3_model = loaded_model_shuf3.evaluate(pp_X_sub_482, y_sub_482_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDShwSlhpXoE",
        "outputId": "b91bf835-1a4a-4ee3-ed96-1d187afb6f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96/96 [==============================] - 3s 12ms/step - loss: 0.4543 - accuracy: 0.8632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_shuf1_transfer_set_model = loaded_model_shuf1.evaluate(x_dt_transfer_rshp, y_dt_transfer_) #checking the models performance on the transfer set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQxb1hlsZ0HR",
        "outputId": "b33395e9-710b-4d0c-ca3c-9ef64e88dcea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3648/3648 [==============================] - 753s 206ms/step - loss: 0.4014 - accuracy: 0.8454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_shuf2_transfer_set_model = loaded_model_shuf2.evaluate(x_dt_transfer_rshp, y_dt_transfer_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjNiWejnZ0Rw",
        "outputId": "4fab176e-86cb-42b7-83ba-57a8a1f0fab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3648/3648 [==============================] - 749s 205ms/step - loss: 0.4046 - accuracy: 0.8416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_shuf3_transfer_set_model = loaded_best_model_shuf3.evaluate(x_dt_transfer_rshp, y_dt_transfer_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiaFgSYZY7jh",
        "outputId": "53cdd695-97ed-4d0a-f684-fce2ad5b9c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "433/433 [==============================] - 3s 7ms/step - loss: 1.3797 - accuracy: 0.6902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "StHZP2L1ZKCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_sub_466_.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7lWaT0iiWC4",
        "outputId": "7fce8537-7fc2-4b1e-fea4-69782c9428a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4020, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_sub_466_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_xe_0nlA-DE",
        "outputId": "2c6c374e-b27d-4e0d-8423-514fc02c934a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adding 1 to the predictions because argmax maps labels to a number starting from 0 and not 1, will fix this in the kd+personalization experiment"
      ],
      "metadata": {
        "id": "arM52DcDoRsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making predictions on the transfer set and aggregating the predictions"
      ],
      "metadata": {
        "id": "k3dHBHszaqyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_dt_transfer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "xQlQR4XqB1ZR",
        "outputId": "363ba90e-9cd5-4cdb-bf93-bdfc60ab0b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5ee73e94-9a45-490e-bc30-558035277bad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>2960</th>\n",
              "      <th>2961</th>\n",
              "      <th>2962</th>\n",
              "      <th>2963</th>\n",
              "      <th>2964</th>\n",
              "      <th>2965</th>\n",
              "      <th>2966</th>\n",
              "      <th>2967</th>\n",
              "      <th>2968</th>\n",
              "      <th>2969</th>\n",
              "      <th>2970</th>\n",
              "      <th>2971</th>\n",
              "      <th>2972</th>\n",
              "      <th>2973</th>\n",
              "      <th>2974</th>\n",
              "      <th>2975</th>\n",
              "      <th>2976</th>\n",
              "      <th>2977</th>\n",
              "      <th>2978</th>\n",
              "      <th>2979</th>\n",
              "      <th>2980</th>\n",
              "      <th>2981</th>\n",
              "      <th>2982</th>\n",
              "      <th>2983</th>\n",
              "      <th>2984</th>\n",
              "      <th>2985</th>\n",
              "      <th>2986</th>\n",
              "      <th>2987</th>\n",
              "      <th>2988</th>\n",
              "      <th>2989</th>\n",
              "      <th>2990</th>\n",
              "      <th>2991</th>\n",
              "      <th>2992</th>\n",
              "      <th>2993</th>\n",
              "      <th>2994</th>\n",
              "      <th>2995</th>\n",
              "      <th>2996</th>\n",
              "      <th>2997</th>\n",
              "      <th>2998</th>\n",
              "      <th>2999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2302</th>\n",
              "      <td>0.068014</td>\n",
              "      <td>0.082915</td>\n",
              "      <td>0.077628</td>\n",
              "      <td>0.074744</td>\n",
              "      <td>0.060804</td>\n",
              "      <td>0.063688</td>\n",
              "      <td>0.050710</td>\n",
              "      <td>0.029561</td>\n",
              "      <td>0.010815</td>\n",
              "      <td>0.008412</td>\n",
              "      <td>0.016102</td>\n",
              "      <td>0.014660</td>\n",
              "      <td>0.029080</td>\n",
              "      <td>0.012738</td>\n",
              "      <td>0.022351</td>\n",
              "      <td>0.043981</td>\n",
              "      <td>0.045423</td>\n",
              "      <td>0.052633</td>\n",
              "      <td>0.038213</td>\n",
              "      <td>0.029080</td>\n",
              "      <td>0.021870</td>\n",
              "      <td>0.013218</td>\n",
              "      <td>0.004566</td>\n",
              "      <td>0.002644</td>\n",
              "      <td>-0.000721</td>\n",
              "      <td>0.005047</td>\n",
              "      <td>0.007450</td>\n",
              "      <td>0.023793</td>\n",
              "      <td>0.011776</td>\n",
              "      <td>0.007450</td>\n",
              "      <td>0.001682</td>\n",
              "      <td>0.003605</td>\n",
              "      <td>0.011776</td>\n",
              "      <td>0.011296</td>\n",
              "      <td>0.008892</td>\n",
              "      <td>0.029561</td>\n",
              "      <td>0.028119</td>\n",
              "      <td>0.032445</td>\n",
              "      <td>0.031003</td>\n",
              "      <td>0.037732</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.049268</td>\n",
              "      <td>-0.057440</td>\n",
              "      <td>-0.060324</td>\n",
              "      <td>-0.058401</td>\n",
              "      <td>-0.060804</td>\n",
              "      <td>-0.068014</td>\n",
              "      <td>-0.063688</td>\n",
              "      <td>-0.054556</td>\n",
              "      <td>-0.054075</td>\n",
              "      <td>-0.053114</td>\n",
              "      <td>-0.050230</td>\n",
              "      <td>-0.060324</td>\n",
              "      <td>-0.059843</td>\n",
              "      <td>-0.054075</td>\n",
              "      <td>-0.050710</td>\n",
              "      <td>-0.040136</td>\n",
              "      <td>-0.057440</td>\n",
              "      <td>-0.053594</td>\n",
              "      <td>-0.037252</td>\n",
              "      <td>-0.033406</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>-0.005047</td>\n",
              "      <td>0.004086</td>\n",
              "      <td>0.008892</td>\n",
              "      <td>0.010815</td>\n",
              "      <td>0.014660</td>\n",
              "      <td>0.031484</td>\n",
              "      <td>0.020909</td>\n",
              "      <td>0.044942</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>-0.007450</td>\n",
              "      <td>-0.010334</td>\n",
              "      <td>-0.016102</td>\n",
              "      <td>-0.034368</td>\n",
              "      <td>-0.055998</td>\n",
              "      <td>-0.074263</td>\n",
              "      <td>-0.071860</td>\n",
              "      <td>-0.077147</td>\n",
              "      <td>-0.084838</td>\n",
              "      <td>-0.090125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31195</th>\n",
              "      <td>0.104729</td>\n",
              "      <td>0.054513</td>\n",
              "      <td>-0.020131</td>\n",
              "      <td>-0.064918</td>\n",
              "      <td>-0.122825</td>\n",
              "      <td>-0.127801</td>\n",
              "      <td>-0.107443</td>\n",
              "      <td>-0.086633</td>\n",
              "      <td>-0.051799</td>\n",
              "      <td>-0.033251</td>\n",
              "      <td>-0.013346</td>\n",
              "      <td>-0.023751</td>\n",
              "      <td>-0.005203</td>\n",
              "      <td>0.001583</td>\n",
              "      <td>0.003393</td>\n",
              "      <td>0.020584</td>\n",
              "      <td>0.017417</td>\n",
              "      <td>-0.010631</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>-0.006560</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>0.004750</td>\n",
              "      <td>0.039132</td>\n",
              "      <td>0.064466</td>\n",
              "      <td>0.067180</td>\n",
              "      <td>0.054513</td>\n",
              "      <td>0.048180</td>\n",
              "      <td>0.033251</td>\n",
              "      <td>0.040037</td>\n",
              "      <td>0.040037</td>\n",
              "      <td>0.025108</td>\n",
              "      <td>0.005203</td>\n",
              "      <td>0.011988</td>\n",
              "      <td>-0.031894</td>\n",
              "      <td>-0.048180</td>\n",
              "      <td>-0.108348</td>\n",
              "      <td>-0.094776</td>\n",
              "      <td>-0.113324</td>\n",
              "      <td>-0.091157</td>\n",
              "      <td>-0.108800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.058585</td>\n",
              "      <td>0.043203</td>\n",
              "      <td>0.015608</td>\n",
              "      <td>0.062656</td>\n",
              "      <td>0.059942</td>\n",
              "      <td>0.095681</td>\n",
              "      <td>0.097491</td>\n",
              "      <td>0.060394</td>\n",
              "      <td>0.055870</td>\n",
              "      <td>0.040489</td>\n",
              "      <td>0.015608</td>\n",
              "      <td>0.020584</td>\n",
              "      <td>0.036870</td>\n",
              "      <td>0.050894</td>\n",
              "      <td>0.066728</td>\n",
              "      <td>0.090252</td>\n",
              "      <td>0.130515</td>\n",
              "      <td>0.178017</td>\n",
              "      <td>0.179826</td>\n",
              "      <td>0.196565</td>\n",
              "      <td>0.176659</td>\n",
              "      <td>0.162635</td>\n",
              "      <td>0.115586</td>\n",
              "      <td>0.076228</td>\n",
              "      <td>0.041846</td>\n",
              "      <td>0.000679</td>\n",
              "      <td>-0.002941</td>\n",
              "      <td>-0.046823</td>\n",
              "      <td>-0.040037</td>\n",
              "      <td>-0.070347</td>\n",
              "      <td>-0.102467</td>\n",
              "      <td>-0.123729</td>\n",
              "      <td>-0.120563</td>\n",
              "      <td>-0.129158</td>\n",
              "      <td>-0.149968</td>\n",
              "      <td>-0.173945</td>\n",
              "      <td>-0.187064</td>\n",
              "      <td>-0.171231</td>\n",
              "      <td>-0.149516</td>\n",
              "      <td>-0.121467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82207</th>\n",
              "      <td>0.002281</td>\n",
              "      <td>-0.031309</td>\n",
              "      <td>-0.007672</td>\n",
              "      <td>-0.020527</td>\n",
              "      <td>-0.003110</td>\n",
              "      <td>-0.011404</td>\n",
              "      <td>0.006013</td>\n",
              "      <td>-0.029236</td>\n",
              "      <td>-0.025089</td>\n",
              "      <td>-0.042091</td>\n",
              "      <td>-0.021357</td>\n",
              "      <td>-0.010160</td>\n",
              "      <td>-0.032553</td>\n",
              "      <td>-0.015136</td>\n",
              "      <td>-0.024260</td>\n",
              "      <td>-0.035042</td>\n",
              "      <td>-0.059508</td>\n",
              "      <td>-0.047482</td>\n",
              "      <td>-0.049141</td>\n",
              "      <td>-0.018869</td>\n",
              "      <td>-0.009331</td>\n",
              "      <td>-0.001866</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>-0.001037</td>\n",
              "      <td>-0.005598</td>\n",
              "      <td>0.006013</td>\n",
              "      <td>0.027577</td>\n",
              "      <td>0.029651</td>\n",
              "      <td>0.064485</td>\n",
              "      <td>0.063241</td>\n",
              "      <td>0.025504</td>\n",
              "      <td>0.040433</td>\n",
              "      <td>0.035456</td>\n",
              "      <td>0.042506</td>\n",
              "      <td>0.026333</td>\n",
              "      <td>0.035456</td>\n",
              "      <td>0.023430</td>\n",
              "      <td>-0.001451</td>\n",
              "      <td>-0.027162</td>\n",
              "      <td>0.024674</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003110</td>\n",
              "      <td>0.022601</td>\n",
              "      <td>0.001037</td>\n",
              "      <td>0.003525</td>\n",
              "      <td>-0.009745</td>\n",
              "      <td>-0.031724</td>\n",
              "      <td>-0.015136</td>\n",
              "      <td>-0.012233</td>\n",
              "      <td>-0.014722</td>\n",
              "      <td>-0.036286</td>\n",
              "      <td>-0.028406</td>\n",
              "      <td>-0.025918</td>\n",
              "      <td>0.001866</td>\n",
              "      <td>0.019698</td>\n",
              "      <td>0.014722</td>\n",
              "      <td>-0.031309</td>\n",
              "      <td>0.011819</td>\n",
              "      <td>-0.007257</td>\n",
              "      <td>-0.003110</td>\n",
              "      <td>0.018454</td>\n",
              "      <td>0.010575</td>\n",
              "      <td>-0.002696</td>\n",
              "      <td>0.002281</td>\n",
              "      <td>0.011404</td>\n",
              "      <td>0.044580</td>\n",
              "      <td>0.027162</td>\n",
              "      <td>0.057020</td>\n",
              "      <td>0.086464</td>\n",
              "      <td>0.056191</td>\n",
              "      <td>0.036700</td>\n",
              "      <td>0.054532</td>\n",
              "      <td>0.088122</td>\n",
              "      <td>0.057850</td>\n",
              "      <td>0.027992</td>\n",
              "      <td>0.038359</td>\n",
              "      <td>0.040847</td>\n",
              "      <td>0.053703</td>\n",
              "      <td>0.072779</td>\n",
              "      <td>0.055362</td>\n",
              "      <td>0.029651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2198</th>\n",
              "      <td>-0.025235</td>\n",
              "      <td>-0.037732</td>\n",
              "      <td>-0.033406</td>\n",
              "      <td>-0.031964</td>\n",
              "      <td>-0.034848</td>\n",
              "      <td>-0.041097</td>\n",
              "      <td>-0.031484</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>-0.019948</td>\n",
              "      <td>-0.030522</td>\n",
              "      <td>-0.031484</td>\n",
              "      <td>-0.035329</td>\n",
              "      <td>-0.035810</td>\n",
              "      <td>-0.031964</td>\n",
              "      <td>-0.034368</td>\n",
              "      <td>-0.031964</td>\n",
              "      <td>-0.030522</td>\n",
              "      <td>-0.035810</td>\n",
              "      <td>-0.048788</td>\n",
              "      <td>-0.046865</td>\n",
              "      <td>-0.055998</td>\n",
              "      <td>-0.069456</td>\n",
              "      <td>-0.068014</td>\n",
              "      <td>-0.070898</td>\n",
              "      <td>-0.063208</td>\n",
              "      <td>-0.052152</td>\n",
              "      <td>-0.059362</td>\n",
              "      <td>-0.066092</td>\n",
              "      <td>-0.058401</td>\n",
              "      <td>-0.045904</td>\n",
              "      <td>-0.036290</td>\n",
              "      <td>-0.023793</td>\n",
              "      <td>-0.017544</td>\n",
              "      <td>-0.019467</td>\n",
              "      <td>-0.021390</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.014660</td>\n",
              "      <td>-0.023793</td>\n",
              "      <td>-0.024754</td>\n",
              "      <td>-0.026677</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.033887</td>\n",
              "      <td>-0.028119</td>\n",
              "      <td>-0.022351</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.029561</td>\n",
              "      <td>-0.028600</td>\n",
              "      <td>-0.027638</td>\n",
              "      <td>-0.034368</td>\n",
              "      <td>-0.039655</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>-0.023793</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.009854</td>\n",
              "      <td>-0.011296</td>\n",
              "      <td>-0.015141</td>\n",
              "      <td>-0.002163</td>\n",
              "      <td>-0.003124</td>\n",
              "      <td>-0.004086</td>\n",
              "      <td>-0.016102</td>\n",
              "      <td>-0.026196</td>\n",
              "      <td>-0.025235</td>\n",
              "      <td>-0.013699</td>\n",
              "      <td>-0.003605</td>\n",
              "      <td>0.000721</td>\n",
              "      <td>0.014660</td>\n",
              "      <td>0.014180</td>\n",
              "      <td>0.032445</td>\n",
              "      <td>0.021870</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.010334</td>\n",
              "      <td>-0.012738</td>\n",
              "      <td>-0.015141</td>\n",
              "      <td>-0.013699</td>\n",
              "      <td>-0.018025</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.021390</td>\n",
              "      <td>-0.002644</td>\n",
              "      <td>-0.020428</td>\n",
              "      <td>-0.025235</td>\n",
              "      <td>-0.024754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107738</th>\n",
              "      <td>0.097914</td>\n",
              "      <td>-0.100520</td>\n",
              "      <td>-0.044574</td>\n",
              "      <td>-0.079540</td>\n",
              "      <td>-0.071235</td>\n",
              "      <td>-0.029713</td>\n",
              "      <td>-0.041951</td>\n",
              "      <td>0.000445</td>\n",
              "      <td>-0.031024</td>\n",
              "      <td>0.172217</td>\n",
              "      <td>0.081305</td>\n",
              "      <td>-0.077792</td>\n",
              "      <td>0.055954</td>\n",
              "      <td>0.078245</td>\n",
              "      <td>0.012683</td>\n",
              "      <td>0.071252</td>\n",
              "      <td>0.033226</td>\n",
              "      <td>-0.018349</td>\n",
              "      <td>0.053332</td>\n",
              "      <td>0.029292</td>\n",
              "      <td>0.057265</td>\n",
              "      <td>0.113648</td>\n",
              "      <td>0.114960</td>\n",
              "      <td>-0.008733</td>\n",
              "      <td>0.083053</td>\n",
              "      <td>0.309896</td>\n",
              "      <td>-0.039329</td>\n",
              "      <td>0.017054</td>\n",
              "      <td>0.020988</td>\n",
              "      <td>0.075623</td>\n",
              "      <td>0.035849</td>\n",
              "      <td>0.084801</td>\n",
              "      <td>0.085238</td>\n",
              "      <td>0.089172</td>\n",
              "      <td>0.064259</td>\n",
              "      <td>0.090920</td>\n",
              "      <td>0.112337</td>\n",
              "      <td>0.100536</td>\n",
              "      <td>0.103158</td>\n",
              "      <td>0.123701</td>\n",
              "      <td>...</td>\n",
              "      <td>0.202375</td>\n",
              "      <td>0.048524</td>\n",
              "      <td>0.044590</td>\n",
              "      <td>0.061636</td>\n",
              "      <td>0.131569</td>\n",
              "      <td>-0.057686</td>\n",
              "      <td>-0.183127</td>\n",
              "      <td>-0.274039</td>\n",
              "      <td>-0.252622</td>\n",
              "      <td>-0.243444</td>\n",
              "      <td>-0.238636</td>\n",
              "      <td>-0.231206</td>\n",
              "      <td>-0.213723</td>\n",
              "      <td>-0.209789</td>\n",
              "      <td>-0.165644</td>\n",
              "      <td>-0.112758</td>\n",
              "      <td>-0.099208</td>\n",
              "      <td>0.284546</td>\n",
              "      <td>0.265314</td>\n",
              "      <td>0.390318</td>\n",
              "      <td>0.430966</td>\n",
              "      <td>0.370650</td>\n",
              "      <td>0.395563</td>\n",
              "      <td>0.399934</td>\n",
              "      <td>0.405616</td>\n",
              "      <td>0.363657</td>\n",
              "      <td>0.385073</td>\n",
              "      <td>0.365842</td>\n",
              "      <td>0.339617</td>\n",
              "      <td>0.292413</td>\n",
              "      <td>0.264003</td>\n",
              "      <td>0.167409</td>\n",
              "      <td>0.220732</td>\n",
              "      <td>0.191011</td>\n",
              "      <td>0.119767</td>\n",
              "      <td>0.165661</td>\n",
              "      <td>0.270996</td>\n",
              "      <td>0.200190</td>\n",
              "      <td>0.246520</td>\n",
              "      <td>0.166535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20894</th>\n",
              "      <td>0.032558</td>\n",
              "      <td>0.033944</td>\n",
              "      <td>0.046413</td>\n",
              "      <td>0.056111</td>\n",
              "      <td>0.060267</td>\n",
              "      <td>0.066271</td>\n",
              "      <td>0.077816</td>\n",
              "      <td>0.058882</td>\n",
              "      <td>0.078278</td>\n",
              "      <td>0.051493</td>\n",
              "      <td>0.040871</td>\n",
              "      <td>0.061191</td>\n",
              "      <td>0.023322</td>\n",
              "      <td>0.020089</td>\n",
              "      <td>-0.002540</td>\n",
              "      <td>0.032558</td>\n",
              "      <td>0.050569</td>\n",
              "      <td>0.007620</td>\n",
              "      <td>-0.010853</td>\n",
              "      <td>-0.022860</td>\n",
              "      <td>-0.023322</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>0.066271</td>\n",
              "      <td>0.086129</td>\n",
              "      <td>0.061653</td>\n",
              "      <td>0.001616</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>0.001616</td>\n",
              "      <td>0.003925</td>\n",
              "      <td>0.010391</td>\n",
              "      <td>0.000693</td>\n",
              "      <td>0.038562</td>\n",
              "      <td>-0.009467</td>\n",
              "      <td>-0.008544</td>\n",
              "      <td>0.016395</td>\n",
              "      <td>0.021475</td>\n",
              "      <td>0.052416</td>\n",
              "      <td>0.087514</td>\n",
              "      <td>0.063962</td>\n",
              "      <td>0.018242</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.049645</td>\n",
              "      <td>-0.039024</td>\n",
              "      <td>-0.089362</td>\n",
              "      <td>-0.062576</td>\n",
              "      <td>-0.087976</td>\n",
              "      <td>-0.094442</td>\n",
              "      <td>-0.128616</td>\n",
              "      <td>-0.102293</td>\n",
              "      <td>-0.103678</td>\n",
              "      <td>-0.123998</td>\n",
              "      <td>-0.111529</td>\n",
              "      <td>-0.124922</td>\n",
              "      <td>-0.077816</td>\n",
              "      <td>-0.069965</td>\n",
              "      <td>-0.093980</td>\n",
              "      <td>-0.049184</td>\n",
              "      <td>-0.066271</td>\n",
              "      <td>-0.044104</td>\n",
              "      <td>-0.045489</td>\n",
              "      <td>-0.018242</td>\n",
              "      <td>-0.021936</td>\n",
              "      <td>-0.031173</td>\n",
              "      <td>-0.020551</td>\n",
              "      <td>-0.010853</td>\n",
              "      <td>-0.014085</td>\n",
              "      <td>-0.013624</td>\n",
              "      <td>0.019627</td>\n",
              "      <td>0.042718</td>\n",
              "      <td>0.064885</td>\n",
              "      <td>0.028864</td>\n",
              "      <td>0.026093</td>\n",
              "      <td>0.024707</td>\n",
              "      <td>0.025631</td>\n",
              "      <td>0.015933</td>\n",
              "      <td>0.044565</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>0.018242</td>\n",
              "      <td>-0.028402</td>\n",
              "      <td>0.021475</td>\n",
              "      <td>0.028402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78249</th>\n",
              "      <td>0.068695</td>\n",
              "      <td>0.059483</td>\n",
              "      <td>0.051071</td>\n",
              "      <td>0.044662</td>\n",
              "      <td>0.037051</td>\n",
              "      <td>0.041057</td>\n",
              "      <td>0.040656</td>\n",
              "      <td>0.046264</td>\n",
              "      <td>0.039054</td>\n",
              "      <td>0.045063</td>\n",
              "      <td>0.044261</td>\n",
              "      <td>0.039855</td>\n",
              "      <td>0.034648</td>\n",
              "      <td>0.025035</td>\n",
              "      <td>0.025836</td>\n",
              "      <td>0.022631</td>\n",
              "      <td>0.009413</td>\n",
              "      <td>0.004206</td>\n",
              "      <td>0.006209</td>\n",
              "      <td>0.000601</td>\n",
              "      <td>-0.003805</td>\n",
              "      <td>0.001402</td>\n",
              "      <td>-0.005408</td>\n",
              "      <td>-0.004606</td>\n",
              "      <td>-0.005408</td>\n",
              "      <td>-0.008612</td>\n",
              "      <td>-0.013018</td>\n",
              "      <td>-0.010615</td>\n",
              "      <td>-0.006209</td>\n",
              "      <td>0.003405</td>\n",
              "      <td>0.012217</td>\n",
              "      <td>0.010615</td>\n",
              "      <td>0.007010</td>\n",
              "      <td>0.003004</td>\n",
              "      <td>0.011416</td>\n",
              "      <td>0.000601</td>\n",
              "      <td>-0.010214</td>\n",
              "      <td>-0.005808</td>\n",
              "      <td>0.001402</td>\n",
              "      <td>0.010214</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006609</td>\n",
              "      <td>0.011015</td>\n",
              "      <td>0.012217</td>\n",
              "      <td>0.024234</td>\n",
              "      <td>0.022231</td>\n",
              "      <td>0.028640</td>\n",
              "      <td>0.035049</td>\n",
              "      <td>0.030643</td>\n",
              "      <td>0.024634</td>\n",
              "      <td>0.019026</td>\n",
              "      <td>0.021029</td>\n",
              "      <td>0.005808</td>\n",
              "      <td>0.003405</td>\n",
              "      <td>0.015021</td>\n",
              "      <td>0.019828</td>\n",
              "      <td>0.020228</td>\n",
              "      <td>0.011416</td>\n",
              "      <td>0.013819</td>\n",
              "      <td>0.007811</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>0.002203</td>\n",
              "      <td>-0.006209</td>\n",
              "      <td>-0.015421</td>\n",
              "      <td>-0.009413</td>\n",
              "      <td>0.005808</td>\n",
              "      <td>0.025035</td>\n",
              "      <td>0.024634</td>\n",
              "      <td>0.032245</td>\n",
              "      <td>0.033847</td>\n",
              "      <td>0.026236</td>\n",
              "      <td>0.032245</td>\n",
              "      <td>0.035850</td>\n",
              "      <td>0.031444</td>\n",
              "      <td>0.026637</td>\n",
              "      <td>0.023433</td>\n",
              "      <td>0.027839</td>\n",
              "      <td>0.023833</td>\n",
              "      <td>0.018626</td>\n",
              "      <td>0.005007</td>\n",
              "      <td>0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57039</th>\n",
              "      <td>0.013392</td>\n",
              "      <td>0.030717</td>\n",
              "      <td>0.029805</td>\n",
              "      <td>0.016127</td>\n",
              "      <td>0.026613</td>\n",
              "      <td>0.024334</td>\n",
              "      <td>0.019775</td>\n",
              "      <td>0.038012</td>\n",
              "      <td>0.027069</td>\n",
              "      <td>0.031629</td>\n",
              "      <td>0.029805</td>\n",
              "      <td>0.035276</td>\n",
              "      <td>0.038923</td>\n",
              "      <td>0.033908</td>\n",
              "      <td>0.034820</td>\n",
              "      <td>0.031629</td>\n",
              "      <td>0.018407</td>\n",
              "      <td>0.031629</td>\n",
              "      <td>0.036188</td>\n",
              "      <td>0.038468</td>\n",
              "      <td>0.045306</td>\n",
              "      <td>0.058072</td>\n",
              "      <td>0.064455</td>\n",
              "      <td>0.067191</td>\n",
              "      <td>0.048498</td>\n",
              "      <td>0.042115</td>\n",
              "      <td>0.041659</td>\n",
              "      <td>0.054881</td>\n",
              "      <td>0.050778</td>\n",
              "      <td>0.058528</td>\n",
              "      <td>0.058984</td>\n",
              "      <td>0.054881</td>\n",
              "      <td>0.073118</td>\n",
              "      <td>0.056249</td>\n",
              "      <td>0.066735</td>\n",
              "      <td>0.067647</td>\n",
              "      <td>0.053969</td>\n",
              "      <td>0.057616</td>\n",
              "      <td>0.056249</td>\n",
              "      <td>0.059440</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033452</td>\n",
              "      <td>0.029805</td>\n",
              "      <td>0.036188</td>\n",
              "      <td>0.032085</td>\n",
              "      <td>0.028893</td>\n",
              "      <td>0.032540</td>\n",
              "      <td>0.025246</td>\n",
              "      <td>0.030261</td>\n",
              "      <td>0.024790</td>\n",
              "      <td>0.027069</td>\n",
              "      <td>0.006097</td>\n",
              "      <td>0.005641</td>\n",
              "      <td>0.012936</td>\n",
              "      <td>0.021598</td>\n",
              "      <td>0.027981</td>\n",
              "      <td>0.026157</td>\n",
              "      <td>0.019319</td>\n",
              "      <td>0.018407</td>\n",
              "      <td>0.007009</td>\n",
              "      <td>0.001537</td>\n",
              "      <td>-0.003478</td>\n",
              "      <td>-0.006669</td>\n",
              "      <td>0.004729</td>\n",
              "      <td>0.012936</td>\n",
              "      <td>0.015671</td>\n",
              "      <td>0.011568</td>\n",
              "      <td>0.016583</td>\n",
              "      <td>0.016583</td>\n",
              "      <td>0.015671</td>\n",
              "      <td>0.007009</td>\n",
              "      <td>0.004273</td>\n",
              "      <td>0.013392</td>\n",
              "      <td>0.018863</td>\n",
              "      <td>0.034820</td>\n",
              "      <td>0.034364</td>\n",
              "      <td>0.042115</td>\n",
              "      <td>0.045306</td>\n",
              "      <td>0.041659</td>\n",
              "      <td>0.032996</td>\n",
              "      <td>0.024334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34319</th>\n",
              "      <td>-0.057457</td>\n",
              "      <td>-0.065629</td>\n",
              "      <td>-0.101198</td>\n",
              "      <td>-0.114176</td>\n",
              "      <td>-0.141093</td>\n",
              "      <td>-0.184354</td>\n",
              "      <td>-0.222807</td>\n",
              "      <td>-0.230017</td>\n",
              "      <td>-0.242514</td>\n",
              "      <td>-0.231459</td>\n",
              "      <td>-0.214636</td>\n",
              "      <td>-0.201177</td>\n",
              "      <td>-0.194448</td>\n",
              "      <td>-0.182912</td>\n",
              "      <td>-0.164646</td>\n",
              "      <td>-0.146861</td>\n",
              "      <td>-0.135325</td>\n",
              "      <td>-0.129557</td>\n",
              "      <td>-0.120905</td>\n",
              "      <td>-0.129557</td>\n",
              "      <td>-0.148784</td>\n",
              "      <td>-0.165608</td>\n",
              "      <td>-0.181470</td>\n",
              "      <td>-0.172337</td>\n",
              "      <td>-0.145900</td>\n",
              "      <td>-0.143497</td>\n",
              "      <td>-0.133403</td>\n",
              "      <td>-0.126673</td>\n",
              "      <td>-0.128596</td>\n",
              "      <td>-0.130038</td>\n",
              "      <td>-0.112734</td>\n",
              "      <td>-0.101679</td>\n",
              "      <td>-0.106966</td>\n",
              "      <td>-0.084855</td>\n",
              "      <td>-0.062745</td>\n",
              "      <td>-0.063706</td>\n",
              "      <td>-0.049286</td>\n",
              "      <td>-0.065629</td>\n",
              "      <td>-0.060822</td>\n",
              "      <td>-0.057457</td>\n",
              "      <td>...</td>\n",
              "      <td>0.226617</td>\n",
              "      <td>0.219407</td>\n",
              "      <td>0.210755</td>\n",
              "      <td>0.191048</td>\n",
              "      <td>0.169418</td>\n",
              "      <td>0.135290</td>\n",
              "      <td>0.114141</td>\n",
              "      <td>0.103085</td>\n",
              "      <td>0.096356</td>\n",
              "      <td>0.093472</td>\n",
              "      <td>0.091549</td>\n",
              "      <td>0.094433</td>\n",
              "      <td>0.072323</td>\n",
              "      <td>0.042041</td>\n",
              "      <td>0.010797</td>\n",
              "      <td>-0.013236</td>\n",
              "      <td>-0.033424</td>\n",
              "      <td>-0.029579</td>\n",
              "      <td>-0.028617</td>\n",
              "      <td>-0.036789</td>\n",
              "      <td>-0.047363</td>\n",
              "      <td>-0.064187</td>\n",
              "      <td>-0.071877</td>\n",
              "      <td>-0.080049</td>\n",
              "      <td>-0.053131</td>\n",
              "      <td>-0.051689</td>\n",
              "      <td>-0.046402</td>\n",
              "      <td>-0.063225</td>\n",
              "      <td>-0.052170</td>\n",
              "      <td>-0.074281</td>\n",
              "      <td>-0.079087</td>\n",
              "      <td>-0.085817</td>\n",
              "      <td>-0.068993</td>\n",
              "      <td>-0.058899</td>\n",
              "      <td>-0.043999</td>\n",
              "      <td>-0.058419</td>\n",
              "      <td>-0.065629</td>\n",
              "      <td>-0.070916</td>\n",
              "      <td>-0.068513</td>\n",
              "      <td>-0.090143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17826</th>\n",
              "      <td>-0.065742</td>\n",
              "      <td>-0.082698</td>\n",
              "      <td>-0.086365</td>\n",
              "      <td>-0.053368</td>\n",
              "      <td>-0.023122</td>\n",
              "      <td>-0.024038</td>\n",
              "      <td>-0.046494</td>\n",
              "      <td>-0.133109</td>\n",
              "      <td>-0.211476</td>\n",
              "      <td>-0.300383</td>\n",
              "      <td>-0.332463</td>\n",
              "      <td>-0.329713</td>\n",
              "      <td>-0.355835</td>\n",
              "      <td>-0.354919</td>\n",
              "      <td>-0.328338</td>\n",
              "      <td>-0.288467</td>\n",
              "      <td>-0.260970</td>\n",
              "      <td>-0.271053</td>\n",
              "      <td>-0.271969</td>\n",
              "      <td>-0.232099</td>\n",
              "      <td>-0.191311</td>\n",
              "      <td>-0.132193</td>\n",
              "      <td>-0.048785</td>\n",
              "      <td>0.000709</td>\n",
              "      <td>0.043788</td>\n",
              "      <td>0.034164</td>\n",
              "      <td>0.035539</td>\n",
              "      <td>0.087325</td>\n",
              "      <td>0.130403</td>\n",
              "      <td>0.125821</td>\n",
              "      <td>0.083200</td>\n",
              "      <td>0.050204</td>\n",
              "      <td>0.046996</td>\n",
              "      <td>0.060744</td>\n",
              "      <td>0.028664</td>\n",
              "      <td>-0.039620</td>\n",
              "      <td>-0.069866</td>\n",
              "      <td>-0.056118</td>\n",
              "      <td>-0.013039</td>\n",
              "      <td>-0.011206</td>\n",
              "      <td>...</td>\n",
              "      <td>0.150110</td>\n",
              "      <td>0.161108</td>\n",
              "      <td>0.153776</td>\n",
              "      <td>0.141860</td>\n",
              "      <td>0.093282</td>\n",
              "      <td>0.067619</td>\n",
              "      <td>0.056620</td>\n",
              "      <td>0.041038</td>\n",
              "      <td>0.019041</td>\n",
              "      <td>0.071743</td>\n",
              "      <td>0.098782</td>\n",
              "      <td>0.080450</td>\n",
              "      <td>0.012625</td>\n",
              "      <td>0.031414</td>\n",
              "      <td>0.062577</td>\n",
              "      <td>0.058911</td>\n",
              "      <td>-0.007540</td>\n",
              "      <td>-0.025413</td>\n",
              "      <td>0.024998</td>\n",
              "      <td>0.069452</td>\n",
              "      <td>0.037830</td>\n",
              "      <td>-0.017164</td>\n",
              "      <td>-0.020830</td>\n",
              "      <td>-0.029537</td>\n",
              "      <td>-0.040078</td>\n",
              "      <td>-0.102863</td>\n",
              "      <td>-0.134026</td>\n",
              "      <td>-0.169772</td>\n",
              "      <td>-0.123027</td>\n",
              "      <td>-0.103321</td>\n",
              "      <td>-0.111570</td>\n",
              "      <td>-0.135401</td>\n",
              "      <td>-0.128985</td>\n",
              "      <td>-0.091864</td>\n",
              "      <td>-0.071700</td>\n",
              "      <td>-0.102404</td>\n",
              "      <td>-0.157398</td>\n",
              "      <td>-0.150524</td>\n",
              "      <td>-0.087281</td>\n",
              "      <td>-0.042828</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>116718 rows × 3000 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ee73e94-9a45-490e-bc30-558035277bad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ee73e94-9a45-490e-bc30-558035277bad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ee73e94-9a45-490e-bc30-558035277bad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0         1         2     ...      2997      2998      2999\n",
              "2302    0.068014  0.082915  0.077628  ... -0.077147 -0.084838 -0.090125\n",
              "31195   0.104729  0.054513 -0.020131  ... -0.171231 -0.149516 -0.121467\n",
              "82207   0.002281 -0.031309 -0.007672  ...  0.072779  0.055362  0.029651\n",
              "2198   -0.025235 -0.037732 -0.033406  ... -0.020428 -0.025235 -0.024754\n",
              "107738  0.097914 -0.100520 -0.044574  ...  0.200190  0.246520  0.166535\n",
              "...          ...       ...       ...  ...       ...       ...       ...\n",
              "20894   0.032558  0.033944  0.046413  ... -0.028402  0.021475  0.028402\n",
              "78249   0.068695  0.059483  0.051071  ...  0.018626  0.005007  0.007010\n",
              "57039   0.013392  0.030717  0.029805  ...  0.041659  0.032996  0.024334\n",
              "34319  -0.057457 -0.065629 -0.101198  ... -0.070916 -0.068513 -0.090143\n",
              "17826  -0.065742 -0.082698 -0.086365  ... -0.150524 -0.087281 -0.042828\n",
              "\n",
              "[116718 rows x 3000 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(x_dt_transfer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7oaQwK4B4WA",
        "outputId": "742af39d-178d-488b-fdbe-eed31e7cab59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sple in x_dt_transfer:\n",
        "    #sple_rshp=sple.reshape(1,3000,1)\n",
        "    print(type(sple))\n",
        "    print(type(np.array(sple)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NixY86TQB_u0",
        "outputId": "3ad0e153-f2bf-4c4b-8fbc-fba7f6c3ecb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'int'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_shuf1=[]\n",
        "preds_shuf2=[]\n",
        "preds_shuf3=[]\n",
        "\n",
        "m_vote=[]\n",
        "\n",
        "for sple in np.array(x_dt_transfer):\n",
        "    sple_rshp=sple.reshape(1,3000,1)\n",
        "    p1_i=loaded_model_shuf1.predict(sple_rshp)\n",
        "    p1_argmx_i=np.argmax(p1_i,axis=1)\n",
        "    p1_argmx_i_final=(p1_argmx_i)\n",
        "    preds_shuf1.append(p1_argmx_i_final)\n",
        "    p2_i=loaded_model_shuf2.predict(sple_rshp)\n",
        "    p2_argmx_i=np.argmax(p2_i,axis=1)\n",
        "    p2_argmx_i_final=(p2_argmx_i)\n",
        "    preds_shuf2.append(p2_argmx_i_final)\n",
        "    p3_i=loaded_model_shuf3.predict(sple_rshp)\n",
        "    p3_argmx_i=np.argmax(p3_i,axis=1)\n",
        "    p3_argmx_i_final=(p3_argmx_i)\n",
        "    preds_shuf3.append(p3_argmx_i_final)\n",
        "    mode_i=mode([p1_argmx_i_final,p2_argmx_i_final,p3_argmx_i_final])\n",
        "    m_vote_i=mode_i[0][0]\n",
        "    m_vote.append(m_vote_i)"
      ],
      "metadata": {
        "id": "vv3OQm_uUGhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_dt_transfer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vom7Hn5UaeTK",
        "outputId": "31fba99c-349b-487b-93b5-0587d8a6d70a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2302      4\n",
            "31195     3\n",
            "82207     1\n",
            "2198      2\n",
            "107738    0\n",
            "         ..\n",
            "20894     2\n",
            "78249     4\n",
            "57039     4\n",
            "34319     2\n",
            "17826     2\n",
            "Name: sleep_stage, Length: 116718, dtype: int32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_m1 = accuracy_score(y_dt_transfer, preds_shuf1)\n",
        "print('Accuracy1: %f' % accuracy_m1)\n",
        "accuracy_m2 = accuracy_score(y_dt_transfer, preds_shuf2)\n",
        "print('Accuracy2: %f' % accuracy_m2)\n",
        "accuracy_m3 = accuracy_score(y_dt_transfer, preds_shuf3)\n",
        "print('Accuracy3: %f' % accuracy_m3)\n",
        "accuracy_majority = accuracy_score(y_dt_transfer, m_vote)\n",
        "print('Accuracy_maj: %f' % accuracy_majority)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAwYADhCVgAl",
        "outputId": "0467d24d-6e73-4cae-eb1e-679c6bbe1c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy1: 0.845414\n",
            "Accuracy2: 0.841593\n",
            "Accuracy3: 0.849166\n",
            "Accuracy_maj: 0.852516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m_vote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viD3ZfaEsHk5",
        "outputId": "79611778-c656-4b17-dbcc-e3ce2a87d4c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([4]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([3]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([3]),\n",
              " array([3]),\n",
              " array([3]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([1]),\n",
              " array([1]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([3]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([3]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([3]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([3]),\n",
              " array([3]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([1]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([1]),\n",
              " array([3]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([3]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([4]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([1]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([4]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([1]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([1]),\n",
              " array([3]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([3]),\n",
              " array([3]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([1]),\n",
              " array([1]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([3]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([4]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([3]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([4]),\n",
              " array([4]),\n",
              " array([0]),\n",
              " array([1]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " array([2]),\n",
              " array([0]),\n",
              " array([0]),\n",
              " array([2]),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(m_vote[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP0FTnLusktJ",
        "outputId": "bc79cdcb-4937-49b4-b878-cbae60fac3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fin_array=np.concatenate( m_vote, axis=0 )"
      ],
      "metadata": {
        "id": "JPqqguG_ugeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fin_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyxEOiydulmS",
        "outputId": "6cc43684-3a0f-4e3b-d5d7-8a0d421fb270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 3, 2, ..., 4, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trans_x_bse_new_transfer.shape #x_dt_transfer is already a dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGyvQ5PYvMkq",
        "outputId": "44113988-ab48-4b41-a40f-a60bdea4b4fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13836, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trans_x_bse_new_transfer_df #x_dt_transfer is already a dataframe"
      ],
      "metadata": {
        "id": "X_HKQPY9vTmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_dt_transfer['m_vote']=fin_array"
      ],
      "metadata": {
        "id": "8T2Kh5p4vkoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_dt_transfer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Rdvx8sxdvsLw",
        "outputId": "776c6a43-266a-45d0-e9bb-d7e19bc0cf33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-101a0d23-323b-4a80-84b6-cc4f26f0e599\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>2961</th>\n",
              "      <th>2962</th>\n",
              "      <th>2963</th>\n",
              "      <th>2964</th>\n",
              "      <th>2965</th>\n",
              "      <th>2966</th>\n",
              "      <th>2967</th>\n",
              "      <th>2968</th>\n",
              "      <th>2969</th>\n",
              "      <th>2970</th>\n",
              "      <th>2971</th>\n",
              "      <th>2972</th>\n",
              "      <th>2973</th>\n",
              "      <th>2974</th>\n",
              "      <th>2975</th>\n",
              "      <th>2976</th>\n",
              "      <th>2977</th>\n",
              "      <th>2978</th>\n",
              "      <th>2979</th>\n",
              "      <th>2980</th>\n",
              "      <th>2981</th>\n",
              "      <th>2982</th>\n",
              "      <th>2983</th>\n",
              "      <th>2984</th>\n",
              "      <th>2985</th>\n",
              "      <th>2986</th>\n",
              "      <th>2987</th>\n",
              "      <th>2988</th>\n",
              "      <th>2989</th>\n",
              "      <th>2990</th>\n",
              "      <th>2991</th>\n",
              "      <th>2992</th>\n",
              "      <th>2993</th>\n",
              "      <th>2994</th>\n",
              "      <th>2995</th>\n",
              "      <th>2996</th>\n",
              "      <th>2997</th>\n",
              "      <th>2998</th>\n",
              "      <th>2999</th>\n",
              "      <th>m_vote</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2302</th>\n",
              "      <td>0.068014</td>\n",
              "      <td>0.082915</td>\n",
              "      <td>0.077628</td>\n",
              "      <td>0.074744</td>\n",
              "      <td>0.060804</td>\n",
              "      <td>0.063688</td>\n",
              "      <td>0.050710</td>\n",
              "      <td>0.029561</td>\n",
              "      <td>0.010815</td>\n",
              "      <td>0.008412</td>\n",
              "      <td>0.016102</td>\n",
              "      <td>0.014660</td>\n",
              "      <td>0.029080</td>\n",
              "      <td>0.012738</td>\n",
              "      <td>0.022351</td>\n",
              "      <td>0.043981</td>\n",
              "      <td>0.045423</td>\n",
              "      <td>0.052633</td>\n",
              "      <td>0.038213</td>\n",
              "      <td>0.029080</td>\n",
              "      <td>0.021870</td>\n",
              "      <td>0.013218</td>\n",
              "      <td>0.004566</td>\n",
              "      <td>0.002644</td>\n",
              "      <td>-0.000721</td>\n",
              "      <td>0.005047</td>\n",
              "      <td>0.007450</td>\n",
              "      <td>0.023793</td>\n",
              "      <td>0.011776</td>\n",
              "      <td>0.007450</td>\n",
              "      <td>0.001682</td>\n",
              "      <td>0.003605</td>\n",
              "      <td>0.011776</td>\n",
              "      <td>0.011296</td>\n",
              "      <td>0.008892</td>\n",
              "      <td>0.029561</td>\n",
              "      <td>0.028119</td>\n",
              "      <td>0.032445</td>\n",
              "      <td>0.031003</td>\n",
              "      <td>0.037732</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.057440</td>\n",
              "      <td>-0.060324</td>\n",
              "      <td>-0.058401</td>\n",
              "      <td>-0.060804</td>\n",
              "      <td>-0.068014</td>\n",
              "      <td>-0.063688</td>\n",
              "      <td>-0.054556</td>\n",
              "      <td>-0.054075</td>\n",
              "      <td>-0.053114</td>\n",
              "      <td>-0.050230</td>\n",
              "      <td>-0.060324</td>\n",
              "      <td>-0.059843</td>\n",
              "      <td>-0.054075</td>\n",
              "      <td>-0.050710</td>\n",
              "      <td>-0.040136</td>\n",
              "      <td>-0.057440</td>\n",
              "      <td>-0.053594</td>\n",
              "      <td>-0.037252</td>\n",
              "      <td>-0.033406</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>-0.005047</td>\n",
              "      <td>0.004086</td>\n",
              "      <td>0.008892</td>\n",
              "      <td>0.010815</td>\n",
              "      <td>0.014660</td>\n",
              "      <td>0.031484</td>\n",
              "      <td>0.020909</td>\n",
              "      <td>0.044942</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>-0.007450</td>\n",
              "      <td>-0.010334</td>\n",
              "      <td>-0.016102</td>\n",
              "      <td>-0.034368</td>\n",
              "      <td>-0.055998</td>\n",
              "      <td>-0.074263</td>\n",
              "      <td>-0.071860</td>\n",
              "      <td>-0.077147</td>\n",
              "      <td>-0.084838</td>\n",
              "      <td>-0.090125</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31195</th>\n",
              "      <td>0.104729</td>\n",
              "      <td>0.054513</td>\n",
              "      <td>-0.020131</td>\n",
              "      <td>-0.064918</td>\n",
              "      <td>-0.122825</td>\n",
              "      <td>-0.127801</td>\n",
              "      <td>-0.107443</td>\n",
              "      <td>-0.086633</td>\n",
              "      <td>-0.051799</td>\n",
              "      <td>-0.033251</td>\n",
              "      <td>-0.013346</td>\n",
              "      <td>-0.023751</td>\n",
              "      <td>-0.005203</td>\n",
              "      <td>0.001583</td>\n",
              "      <td>0.003393</td>\n",
              "      <td>0.020584</td>\n",
              "      <td>0.017417</td>\n",
              "      <td>-0.010631</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>-0.006560</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>0.004750</td>\n",
              "      <td>0.039132</td>\n",
              "      <td>0.064466</td>\n",
              "      <td>0.067180</td>\n",
              "      <td>0.054513</td>\n",
              "      <td>0.048180</td>\n",
              "      <td>0.033251</td>\n",
              "      <td>0.040037</td>\n",
              "      <td>0.040037</td>\n",
              "      <td>0.025108</td>\n",
              "      <td>0.005203</td>\n",
              "      <td>0.011988</td>\n",
              "      <td>-0.031894</td>\n",
              "      <td>-0.048180</td>\n",
              "      <td>-0.108348</td>\n",
              "      <td>-0.094776</td>\n",
              "      <td>-0.113324</td>\n",
              "      <td>-0.091157</td>\n",
              "      <td>-0.108800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.043203</td>\n",
              "      <td>0.015608</td>\n",
              "      <td>0.062656</td>\n",
              "      <td>0.059942</td>\n",
              "      <td>0.095681</td>\n",
              "      <td>0.097491</td>\n",
              "      <td>0.060394</td>\n",
              "      <td>0.055870</td>\n",
              "      <td>0.040489</td>\n",
              "      <td>0.015608</td>\n",
              "      <td>0.020584</td>\n",
              "      <td>0.036870</td>\n",
              "      <td>0.050894</td>\n",
              "      <td>0.066728</td>\n",
              "      <td>0.090252</td>\n",
              "      <td>0.130515</td>\n",
              "      <td>0.178017</td>\n",
              "      <td>0.179826</td>\n",
              "      <td>0.196565</td>\n",
              "      <td>0.176659</td>\n",
              "      <td>0.162635</td>\n",
              "      <td>0.115586</td>\n",
              "      <td>0.076228</td>\n",
              "      <td>0.041846</td>\n",
              "      <td>0.000679</td>\n",
              "      <td>-0.002941</td>\n",
              "      <td>-0.046823</td>\n",
              "      <td>-0.040037</td>\n",
              "      <td>-0.070347</td>\n",
              "      <td>-0.102467</td>\n",
              "      <td>-0.123729</td>\n",
              "      <td>-0.120563</td>\n",
              "      <td>-0.129158</td>\n",
              "      <td>-0.149968</td>\n",
              "      <td>-0.173945</td>\n",
              "      <td>-0.187064</td>\n",
              "      <td>-0.171231</td>\n",
              "      <td>-0.149516</td>\n",
              "      <td>-0.121467</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82207</th>\n",
              "      <td>0.002281</td>\n",
              "      <td>-0.031309</td>\n",
              "      <td>-0.007672</td>\n",
              "      <td>-0.020527</td>\n",
              "      <td>-0.003110</td>\n",
              "      <td>-0.011404</td>\n",
              "      <td>0.006013</td>\n",
              "      <td>-0.029236</td>\n",
              "      <td>-0.025089</td>\n",
              "      <td>-0.042091</td>\n",
              "      <td>-0.021357</td>\n",
              "      <td>-0.010160</td>\n",
              "      <td>-0.032553</td>\n",
              "      <td>-0.015136</td>\n",
              "      <td>-0.024260</td>\n",
              "      <td>-0.035042</td>\n",
              "      <td>-0.059508</td>\n",
              "      <td>-0.047482</td>\n",
              "      <td>-0.049141</td>\n",
              "      <td>-0.018869</td>\n",
              "      <td>-0.009331</td>\n",
              "      <td>-0.001866</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>-0.001037</td>\n",
              "      <td>-0.005598</td>\n",
              "      <td>0.006013</td>\n",
              "      <td>0.027577</td>\n",
              "      <td>0.029651</td>\n",
              "      <td>0.064485</td>\n",
              "      <td>0.063241</td>\n",
              "      <td>0.025504</td>\n",
              "      <td>0.040433</td>\n",
              "      <td>0.035456</td>\n",
              "      <td>0.042506</td>\n",
              "      <td>0.026333</td>\n",
              "      <td>0.035456</td>\n",
              "      <td>0.023430</td>\n",
              "      <td>-0.001451</td>\n",
              "      <td>-0.027162</td>\n",
              "      <td>0.024674</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022601</td>\n",
              "      <td>0.001037</td>\n",
              "      <td>0.003525</td>\n",
              "      <td>-0.009745</td>\n",
              "      <td>-0.031724</td>\n",
              "      <td>-0.015136</td>\n",
              "      <td>-0.012233</td>\n",
              "      <td>-0.014722</td>\n",
              "      <td>-0.036286</td>\n",
              "      <td>-0.028406</td>\n",
              "      <td>-0.025918</td>\n",
              "      <td>0.001866</td>\n",
              "      <td>0.019698</td>\n",
              "      <td>0.014722</td>\n",
              "      <td>-0.031309</td>\n",
              "      <td>0.011819</td>\n",
              "      <td>-0.007257</td>\n",
              "      <td>-0.003110</td>\n",
              "      <td>0.018454</td>\n",
              "      <td>0.010575</td>\n",
              "      <td>-0.002696</td>\n",
              "      <td>0.002281</td>\n",
              "      <td>0.011404</td>\n",
              "      <td>0.044580</td>\n",
              "      <td>0.027162</td>\n",
              "      <td>0.057020</td>\n",
              "      <td>0.086464</td>\n",
              "      <td>0.056191</td>\n",
              "      <td>0.036700</td>\n",
              "      <td>0.054532</td>\n",
              "      <td>0.088122</td>\n",
              "      <td>0.057850</td>\n",
              "      <td>0.027992</td>\n",
              "      <td>0.038359</td>\n",
              "      <td>0.040847</td>\n",
              "      <td>0.053703</td>\n",
              "      <td>0.072779</td>\n",
              "      <td>0.055362</td>\n",
              "      <td>0.029651</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2198</th>\n",
              "      <td>-0.025235</td>\n",
              "      <td>-0.037732</td>\n",
              "      <td>-0.033406</td>\n",
              "      <td>-0.031964</td>\n",
              "      <td>-0.034848</td>\n",
              "      <td>-0.041097</td>\n",
              "      <td>-0.031484</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>-0.019948</td>\n",
              "      <td>-0.030522</td>\n",
              "      <td>-0.031484</td>\n",
              "      <td>-0.035329</td>\n",
              "      <td>-0.035810</td>\n",
              "      <td>-0.031964</td>\n",
              "      <td>-0.034368</td>\n",
              "      <td>-0.031964</td>\n",
              "      <td>-0.030522</td>\n",
              "      <td>-0.035810</td>\n",
              "      <td>-0.048788</td>\n",
              "      <td>-0.046865</td>\n",
              "      <td>-0.055998</td>\n",
              "      <td>-0.069456</td>\n",
              "      <td>-0.068014</td>\n",
              "      <td>-0.070898</td>\n",
              "      <td>-0.063208</td>\n",
              "      <td>-0.052152</td>\n",
              "      <td>-0.059362</td>\n",
              "      <td>-0.066092</td>\n",
              "      <td>-0.058401</td>\n",
              "      <td>-0.045904</td>\n",
              "      <td>-0.036290</td>\n",
              "      <td>-0.023793</td>\n",
              "      <td>-0.017544</td>\n",
              "      <td>-0.019467</td>\n",
              "      <td>-0.021390</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.014660</td>\n",
              "      <td>-0.023793</td>\n",
              "      <td>-0.024754</td>\n",
              "      <td>-0.026677</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028119</td>\n",
              "      <td>-0.022351</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.029561</td>\n",
              "      <td>-0.028600</td>\n",
              "      <td>-0.027638</td>\n",
              "      <td>-0.034368</td>\n",
              "      <td>-0.039655</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>-0.023793</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.009854</td>\n",
              "      <td>-0.011296</td>\n",
              "      <td>-0.015141</td>\n",
              "      <td>-0.002163</td>\n",
              "      <td>-0.003124</td>\n",
              "      <td>-0.004086</td>\n",
              "      <td>-0.016102</td>\n",
              "      <td>-0.026196</td>\n",
              "      <td>-0.025235</td>\n",
              "      <td>-0.013699</td>\n",
              "      <td>-0.003605</td>\n",
              "      <td>0.000721</td>\n",
              "      <td>0.014660</td>\n",
              "      <td>0.014180</td>\n",
              "      <td>0.032445</td>\n",
              "      <td>0.021870</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.010334</td>\n",
              "      <td>-0.012738</td>\n",
              "      <td>-0.015141</td>\n",
              "      <td>-0.013699</td>\n",
              "      <td>-0.018025</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.021390</td>\n",
              "      <td>-0.002644</td>\n",
              "      <td>-0.020428</td>\n",
              "      <td>-0.025235</td>\n",
              "      <td>-0.024754</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107738</th>\n",
              "      <td>0.097914</td>\n",
              "      <td>-0.100520</td>\n",
              "      <td>-0.044574</td>\n",
              "      <td>-0.079540</td>\n",
              "      <td>-0.071235</td>\n",
              "      <td>-0.029713</td>\n",
              "      <td>-0.041951</td>\n",
              "      <td>0.000445</td>\n",
              "      <td>-0.031024</td>\n",
              "      <td>0.172217</td>\n",
              "      <td>0.081305</td>\n",
              "      <td>-0.077792</td>\n",
              "      <td>0.055954</td>\n",
              "      <td>0.078245</td>\n",
              "      <td>0.012683</td>\n",
              "      <td>0.071252</td>\n",
              "      <td>0.033226</td>\n",
              "      <td>-0.018349</td>\n",
              "      <td>0.053332</td>\n",
              "      <td>0.029292</td>\n",
              "      <td>0.057265</td>\n",
              "      <td>0.113648</td>\n",
              "      <td>0.114960</td>\n",
              "      <td>-0.008733</td>\n",
              "      <td>0.083053</td>\n",
              "      <td>0.309896</td>\n",
              "      <td>-0.039329</td>\n",
              "      <td>0.017054</td>\n",
              "      <td>0.020988</td>\n",
              "      <td>0.075623</td>\n",
              "      <td>0.035849</td>\n",
              "      <td>0.084801</td>\n",
              "      <td>0.085238</td>\n",
              "      <td>0.089172</td>\n",
              "      <td>0.064259</td>\n",
              "      <td>0.090920</td>\n",
              "      <td>0.112337</td>\n",
              "      <td>0.100536</td>\n",
              "      <td>0.103158</td>\n",
              "      <td>0.123701</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048524</td>\n",
              "      <td>0.044590</td>\n",
              "      <td>0.061636</td>\n",
              "      <td>0.131569</td>\n",
              "      <td>-0.057686</td>\n",
              "      <td>-0.183127</td>\n",
              "      <td>-0.274039</td>\n",
              "      <td>-0.252622</td>\n",
              "      <td>-0.243444</td>\n",
              "      <td>-0.238636</td>\n",
              "      <td>-0.231206</td>\n",
              "      <td>-0.213723</td>\n",
              "      <td>-0.209789</td>\n",
              "      <td>-0.165644</td>\n",
              "      <td>-0.112758</td>\n",
              "      <td>-0.099208</td>\n",
              "      <td>0.284546</td>\n",
              "      <td>0.265314</td>\n",
              "      <td>0.390318</td>\n",
              "      <td>0.430966</td>\n",
              "      <td>0.370650</td>\n",
              "      <td>0.395563</td>\n",
              "      <td>0.399934</td>\n",
              "      <td>0.405616</td>\n",
              "      <td>0.363657</td>\n",
              "      <td>0.385073</td>\n",
              "      <td>0.365842</td>\n",
              "      <td>0.339617</td>\n",
              "      <td>0.292413</td>\n",
              "      <td>0.264003</td>\n",
              "      <td>0.167409</td>\n",
              "      <td>0.220732</td>\n",
              "      <td>0.191011</td>\n",
              "      <td>0.119767</td>\n",
              "      <td>0.165661</td>\n",
              "      <td>0.270996</td>\n",
              "      <td>0.200190</td>\n",
              "      <td>0.246520</td>\n",
              "      <td>0.166535</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20894</th>\n",
              "      <td>0.032558</td>\n",
              "      <td>0.033944</td>\n",
              "      <td>0.046413</td>\n",
              "      <td>0.056111</td>\n",
              "      <td>0.060267</td>\n",
              "      <td>0.066271</td>\n",
              "      <td>0.077816</td>\n",
              "      <td>0.058882</td>\n",
              "      <td>0.078278</td>\n",
              "      <td>0.051493</td>\n",
              "      <td>0.040871</td>\n",
              "      <td>0.061191</td>\n",
              "      <td>0.023322</td>\n",
              "      <td>0.020089</td>\n",
              "      <td>-0.002540</td>\n",
              "      <td>0.032558</td>\n",
              "      <td>0.050569</td>\n",
              "      <td>0.007620</td>\n",
              "      <td>-0.010853</td>\n",
              "      <td>-0.022860</td>\n",
              "      <td>-0.023322</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>0.066271</td>\n",
              "      <td>0.086129</td>\n",
              "      <td>0.061653</td>\n",
              "      <td>0.001616</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>0.001616</td>\n",
              "      <td>0.003925</td>\n",
              "      <td>0.010391</td>\n",
              "      <td>0.000693</td>\n",
              "      <td>0.038562</td>\n",
              "      <td>-0.009467</td>\n",
              "      <td>-0.008544</td>\n",
              "      <td>0.016395</td>\n",
              "      <td>0.021475</td>\n",
              "      <td>0.052416</td>\n",
              "      <td>0.087514</td>\n",
              "      <td>0.063962</td>\n",
              "      <td>0.018242</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.039024</td>\n",
              "      <td>-0.089362</td>\n",
              "      <td>-0.062576</td>\n",
              "      <td>-0.087976</td>\n",
              "      <td>-0.094442</td>\n",
              "      <td>-0.128616</td>\n",
              "      <td>-0.102293</td>\n",
              "      <td>-0.103678</td>\n",
              "      <td>-0.123998</td>\n",
              "      <td>-0.111529</td>\n",
              "      <td>-0.124922</td>\n",
              "      <td>-0.077816</td>\n",
              "      <td>-0.069965</td>\n",
              "      <td>-0.093980</td>\n",
              "      <td>-0.049184</td>\n",
              "      <td>-0.066271</td>\n",
              "      <td>-0.044104</td>\n",
              "      <td>-0.045489</td>\n",
              "      <td>-0.018242</td>\n",
              "      <td>-0.021936</td>\n",
              "      <td>-0.031173</td>\n",
              "      <td>-0.020551</td>\n",
              "      <td>-0.010853</td>\n",
              "      <td>-0.014085</td>\n",
              "      <td>-0.013624</td>\n",
              "      <td>0.019627</td>\n",
              "      <td>0.042718</td>\n",
              "      <td>0.064885</td>\n",
              "      <td>0.028864</td>\n",
              "      <td>0.026093</td>\n",
              "      <td>0.024707</td>\n",
              "      <td>0.025631</td>\n",
              "      <td>0.015933</td>\n",
              "      <td>0.044565</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>0.018242</td>\n",
              "      <td>-0.028402</td>\n",
              "      <td>0.021475</td>\n",
              "      <td>0.028402</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78249</th>\n",
              "      <td>0.068695</td>\n",
              "      <td>0.059483</td>\n",
              "      <td>0.051071</td>\n",
              "      <td>0.044662</td>\n",
              "      <td>0.037051</td>\n",
              "      <td>0.041057</td>\n",
              "      <td>0.040656</td>\n",
              "      <td>0.046264</td>\n",
              "      <td>0.039054</td>\n",
              "      <td>0.045063</td>\n",
              "      <td>0.044261</td>\n",
              "      <td>0.039855</td>\n",
              "      <td>0.034648</td>\n",
              "      <td>0.025035</td>\n",
              "      <td>0.025836</td>\n",
              "      <td>0.022631</td>\n",
              "      <td>0.009413</td>\n",
              "      <td>0.004206</td>\n",
              "      <td>0.006209</td>\n",
              "      <td>0.000601</td>\n",
              "      <td>-0.003805</td>\n",
              "      <td>0.001402</td>\n",
              "      <td>-0.005408</td>\n",
              "      <td>-0.004606</td>\n",
              "      <td>-0.005408</td>\n",
              "      <td>-0.008612</td>\n",
              "      <td>-0.013018</td>\n",
              "      <td>-0.010615</td>\n",
              "      <td>-0.006209</td>\n",
              "      <td>0.003405</td>\n",
              "      <td>0.012217</td>\n",
              "      <td>0.010615</td>\n",
              "      <td>0.007010</td>\n",
              "      <td>0.003004</td>\n",
              "      <td>0.011416</td>\n",
              "      <td>0.000601</td>\n",
              "      <td>-0.010214</td>\n",
              "      <td>-0.005808</td>\n",
              "      <td>0.001402</td>\n",
              "      <td>0.010214</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011015</td>\n",
              "      <td>0.012217</td>\n",
              "      <td>0.024234</td>\n",
              "      <td>0.022231</td>\n",
              "      <td>0.028640</td>\n",
              "      <td>0.035049</td>\n",
              "      <td>0.030643</td>\n",
              "      <td>0.024634</td>\n",
              "      <td>0.019026</td>\n",
              "      <td>0.021029</td>\n",
              "      <td>0.005808</td>\n",
              "      <td>0.003405</td>\n",
              "      <td>0.015021</td>\n",
              "      <td>0.019828</td>\n",
              "      <td>0.020228</td>\n",
              "      <td>0.011416</td>\n",
              "      <td>0.013819</td>\n",
              "      <td>0.007811</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>0.002203</td>\n",
              "      <td>-0.006209</td>\n",
              "      <td>-0.015421</td>\n",
              "      <td>-0.009413</td>\n",
              "      <td>0.005808</td>\n",
              "      <td>0.025035</td>\n",
              "      <td>0.024634</td>\n",
              "      <td>0.032245</td>\n",
              "      <td>0.033847</td>\n",
              "      <td>0.026236</td>\n",
              "      <td>0.032245</td>\n",
              "      <td>0.035850</td>\n",
              "      <td>0.031444</td>\n",
              "      <td>0.026637</td>\n",
              "      <td>0.023433</td>\n",
              "      <td>0.027839</td>\n",
              "      <td>0.023833</td>\n",
              "      <td>0.018626</td>\n",
              "      <td>0.005007</td>\n",
              "      <td>0.007010</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57039</th>\n",
              "      <td>0.013392</td>\n",
              "      <td>0.030717</td>\n",
              "      <td>0.029805</td>\n",
              "      <td>0.016127</td>\n",
              "      <td>0.026613</td>\n",
              "      <td>0.024334</td>\n",
              "      <td>0.019775</td>\n",
              "      <td>0.038012</td>\n",
              "      <td>0.027069</td>\n",
              "      <td>0.031629</td>\n",
              "      <td>0.029805</td>\n",
              "      <td>0.035276</td>\n",
              "      <td>0.038923</td>\n",
              "      <td>0.033908</td>\n",
              "      <td>0.034820</td>\n",
              "      <td>0.031629</td>\n",
              "      <td>0.018407</td>\n",
              "      <td>0.031629</td>\n",
              "      <td>0.036188</td>\n",
              "      <td>0.038468</td>\n",
              "      <td>0.045306</td>\n",
              "      <td>0.058072</td>\n",
              "      <td>0.064455</td>\n",
              "      <td>0.067191</td>\n",
              "      <td>0.048498</td>\n",
              "      <td>0.042115</td>\n",
              "      <td>0.041659</td>\n",
              "      <td>0.054881</td>\n",
              "      <td>0.050778</td>\n",
              "      <td>0.058528</td>\n",
              "      <td>0.058984</td>\n",
              "      <td>0.054881</td>\n",
              "      <td>0.073118</td>\n",
              "      <td>0.056249</td>\n",
              "      <td>0.066735</td>\n",
              "      <td>0.067647</td>\n",
              "      <td>0.053969</td>\n",
              "      <td>0.057616</td>\n",
              "      <td>0.056249</td>\n",
              "      <td>0.059440</td>\n",
              "      <td>...</td>\n",
              "      <td>0.029805</td>\n",
              "      <td>0.036188</td>\n",
              "      <td>0.032085</td>\n",
              "      <td>0.028893</td>\n",
              "      <td>0.032540</td>\n",
              "      <td>0.025246</td>\n",
              "      <td>0.030261</td>\n",
              "      <td>0.024790</td>\n",
              "      <td>0.027069</td>\n",
              "      <td>0.006097</td>\n",
              "      <td>0.005641</td>\n",
              "      <td>0.012936</td>\n",
              "      <td>0.021598</td>\n",
              "      <td>0.027981</td>\n",
              "      <td>0.026157</td>\n",
              "      <td>0.019319</td>\n",
              "      <td>0.018407</td>\n",
              "      <td>0.007009</td>\n",
              "      <td>0.001537</td>\n",
              "      <td>-0.003478</td>\n",
              "      <td>-0.006669</td>\n",
              "      <td>0.004729</td>\n",
              "      <td>0.012936</td>\n",
              "      <td>0.015671</td>\n",
              "      <td>0.011568</td>\n",
              "      <td>0.016583</td>\n",
              "      <td>0.016583</td>\n",
              "      <td>0.015671</td>\n",
              "      <td>0.007009</td>\n",
              "      <td>0.004273</td>\n",
              "      <td>0.013392</td>\n",
              "      <td>0.018863</td>\n",
              "      <td>0.034820</td>\n",
              "      <td>0.034364</td>\n",
              "      <td>0.042115</td>\n",
              "      <td>0.045306</td>\n",
              "      <td>0.041659</td>\n",
              "      <td>0.032996</td>\n",
              "      <td>0.024334</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34319</th>\n",
              "      <td>-0.057457</td>\n",
              "      <td>-0.065629</td>\n",
              "      <td>-0.101198</td>\n",
              "      <td>-0.114176</td>\n",
              "      <td>-0.141093</td>\n",
              "      <td>-0.184354</td>\n",
              "      <td>-0.222807</td>\n",
              "      <td>-0.230017</td>\n",
              "      <td>-0.242514</td>\n",
              "      <td>-0.231459</td>\n",
              "      <td>-0.214636</td>\n",
              "      <td>-0.201177</td>\n",
              "      <td>-0.194448</td>\n",
              "      <td>-0.182912</td>\n",
              "      <td>-0.164646</td>\n",
              "      <td>-0.146861</td>\n",
              "      <td>-0.135325</td>\n",
              "      <td>-0.129557</td>\n",
              "      <td>-0.120905</td>\n",
              "      <td>-0.129557</td>\n",
              "      <td>-0.148784</td>\n",
              "      <td>-0.165608</td>\n",
              "      <td>-0.181470</td>\n",
              "      <td>-0.172337</td>\n",
              "      <td>-0.145900</td>\n",
              "      <td>-0.143497</td>\n",
              "      <td>-0.133403</td>\n",
              "      <td>-0.126673</td>\n",
              "      <td>-0.128596</td>\n",
              "      <td>-0.130038</td>\n",
              "      <td>-0.112734</td>\n",
              "      <td>-0.101679</td>\n",
              "      <td>-0.106966</td>\n",
              "      <td>-0.084855</td>\n",
              "      <td>-0.062745</td>\n",
              "      <td>-0.063706</td>\n",
              "      <td>-0.049286</td>\n",
              "      <td>-0.065629</td>\n",
              "      <td>-0.060822</td>\n",
              "      <td>-0.057457</td>\n",
              "      <td>...</td>\n",
              "      <td>0.219407</td>\n",
              "      <td>0.210755</td>\n",
              "      <td>0.191048</td>\n",
              "      <td>0.169418</td>\n",
              "      <td>0.135290</td>\n",
              "      <td>0.114141</td>\n",
              "      <td>0.103085</td>\n",
              "      <td>0.096356</td>\n",
              "      <td>0.093472</td>\n",
              "      <td>0.091549</td>\n",
              "      <td>0.094433</td>\n",
              "      <td>0.072323</td>\n",
              "      <td>0.042041</td>\n",
              "      <td>0.010797</td>\n",
              "      <td>-0.013236</td>\n",
              "      <td>-0.033424</td>\n",
              "      <td>-0.029579</td>\n",
              "      <td>-0.028617</td>\n",
              "      <td>-0.036789</td>\n",
              "      <td>-0.047363</td>\n",
              "      <td>-0.064187</td>\n",
              "      <td>-0.071877</td>\n",
              "      <td>-0.080049</td>\n",
              "      <td>-0.053131</td>\n",
              "      <td>-0.051689</td>\n",
              "      <td>-0.046402</td>\n",
              "      <td>-0.063225</td>\n",
              "      <td>-0.052170</td>\n",
              "      <td>-0.074281</td>\n",
              "      <td>-0.079087</td>\n",
              "      <td>-0.085817</td>\n",
              "      <td>-0.068993</td>\n",
              "      <td>-0.058899</td>\n",
              "      <td>-0.043999</td>\n",
              "      <td>-0.058419</td>\n",
              "      <td>-0.065629</td>\n",
              "      <td>-0.070916</td>\n",
              "      <td>-0.068513</td>\n",
              "      <td>-0.090143</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17826</th>\n",
              "      <td>-0.065742</td>\n",
              "      <td>-0.082698</td>\n",
              "      <td>-0.086365</td>\n",
              "      <td>-0.053368</td>\n",
              "      <td>-0.023122</td>\n",
              "      <td>-0.024038</td>\n",
              "      <td>-0.046494</td>\n",
              "      <td>-0.133109</td>\n",
              "      <td>-0.211476</td>\n",
              "      <td>-0.300383</td>\n",
              "      <td>-0.332463</td>\n",
              "      <td>-0.329713</td>\n",
              "      <td>-0.355835</td>\n",
              "      <td>-0.354919</td>\n",
              "      <td>-0.328338</td>\n",
              "      <td>-0.288467</td>\n",
              "      <td>-0.260970</td>\n",
              "      <td>-0.271053</td>\n",
              "      <td>-0.271969</td>\n",
              "      <td>-0.232099</td>\n",
              "      <td>-0.191311</td>\n",
              "      <td>-0.132193</td>\n",
              "      <td>-0.048785</td>\n",
              "      <td>0.000709</td>\n",
              "      <td>0.043788</td>\n",
              "      <td>0.034164</td>\n",
              "      <td>0.035539</td>\n",
              "      <td>0.087325</td>\n",
              "      <td>0.130403</td>\n",
              "      <td>0.125821</td>\n",
              "      <td>0.083200</td>\n",
              "      <td>0.050204</td>\n",
              "      <td>0.046996</td>\n",
              "      <td>0.060744</td>\n",
              "      <td>0.028664</td>\n",
              "      <td>-0.039620</td>\n",
              "      <td>-0.069866</td>\n",
              "      <td>-0.056118</td>\n",
              "      <td>-0.013039</td>\n",
              "      <td>-0.011206</td>\n",
              "      <td>...</td>\n",
              "      <td>0.161108</td>\n",
              "      <td>0.153776</td>\n",
              "      <td>0.141860</td>\n",
              "      <td>0.093282</td>\n",
              "      <td>0.067619</td>\n",
              "      <td>0.056620</td>\n",
              "      <td>0.041038</td>\n",
              "      <td>0.019041</td>\n",
              "      <td>0.071743</td>\n",
              "      <td>0.098782</td>\n",
              "      <td>0.080450</td>\n",
              "      <td>0.012625</td>\n",
              "      <td>0.031414</td>\n",
              "      <td>0.062577</td>\n",
              "      <td>0.058911</td>\n",
              "      <td>-0.007540</td>\n",
              "      <td>-0.025413</td>\n",
              "      <td>0.024998</td>\n",
              "      <td>0.069452</td>\n",
              "      <td>0.037830</td>\n",
              "      <td>-0.017164</td>\n",
              "      <td>-0.020830</td>\n",
              "      <td>-0.029537</td>\n",
              "      <td>-0.040078</td>\n",
              "      <td>-0.102863</td>\n",
              "      <td>-0.134026</td>\n",
              "      <td>-0.169772</td>\n",
              "      <td>-0.123027</td>\n",
              "      <td>-0.103321</td>\n",
              "      <td>-0.111570</td>\n",
              "      <td>-0.135401</td>\n",
              "      <td>-0.128985</td>\n",
              "      <td>-0.091864</td>\n",
              "      <td>-0.071700</td>\n",
              "      <td>-0.102404</td>\n",
              "      <td>-0.157398</td>\n",
              "      <td>-0.150524</td>\n",
              "      <td>-0.087281</td>\n",
              "      <td>-0.042828</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>116718 rows × 3001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-101a0d23-323b-4a80-84b6-cc4f26f0e599')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-101a0d23-323b-4a80-84b6-cc4f26f0e599 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-101a0d23-323b-4a80-84b6-cc4f26f0e599');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "               0         1         2  ...      2998      2999  m_vote\n",
              "2302    0.068014  0.082915  0.077628  ... -0.084838 -0.090125       4\n",
              "31195   0.104729  0.054513 -0.020131  ... -0.149516 -0.121467       3\n",
              "82207   0.002281 -0.031309 -0.007672  ...  0.055362  0.029651       2\n",
              "2198   -0.025235 -0.037732 -0.033406  ... -0.025235 -0.024754       2\n",
              "107738  0.097914 -0.100520 -0.044574  ...  0.246520  0.166535       0\n",
              "...          ...       ...       ...  ...       ...       ...     ...\n",
              "20894   0.032558  0.033944  0.046413  ...  0.021475  0.028402       2\n",
              "78249   0.068695  0.059483  0.051071  ...  0.005007  0.007010       4\n",
              "57039   0.013392  0.030717  0.029805  ...  0.032996  0.024334       4\n",
              "34319  -0.057457 -0.065629 -0.101198  ... -0.068513 -0.090143       2\n",
              "17826  -0.065742 -0.082698 -0.086365  ... -0.087281 -0.042828       2\n",
              "\n",
              "[116718 rows x 3001 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#deleted this file from drive due to lack of space while performing kd with tri-training and personalization"
      ],
      "metadata": {
        "id": "n9dDFLMPKPex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_dt_transfer.to_csv(r'/gdrive/My Drive/physionet/ensemble/50_subs/transfer_set_50_subs.csv', header=False, index=False)"
      ],
      "metadata": {
        "id": "FEg-RGpmvwRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KD"
      ],
      "metadata": {
        "id": "yAkTUDelWJFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning the Teacher model wrt to the transfer set, its original labels"
      ],
      "metadata": {
        "id": "KHyg8g4j4sMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q -U keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzYFG7APWVzQ",
        "outputId": "4c5bc713-f9c1-4dac-aa36-c5badbb360ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 40 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 81 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 98 kB 2.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "zCUN8dDGWV4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_30_epochs=model_b(verbose=VBS)"
      ],
      "metadata": {
        "id": "htz3PhiBXE6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3781a4ef-d670-476d-fdb6-b6c9fce07185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inLayer (InputLayer)           [(None, 3000, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " fConv1 (Conv1D)                (None, 500, 64)      3264        ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " cConv1 (Conv1D)                (None, 60, 32)       12832       ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " fMaxP1 (MaxPooling1D)          (None, 62, 64)       0           ['fConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP1 (MaxPooling1D)          (None, 15, 32)       0           ['cConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " fDrop1 (Dropout)               (None, 62, 64)       0           ['fMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " cDrop1 (Dropout)               (None, 15, 32)       0           ['cMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv2 (Conv1D)                (None, 62, 128)      65664       ['fDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv2 (Conv1D)                (None, 15, 128)      24704       ['cDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv3 (Conv1D)                (None, 62, 128)      131200      ['fConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv3 (Conv1D)                (None, 15, 128)      98432       ['cConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv4 (Conv1D)                (None, 62, 128)      131200      ['fConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv4 (Conv1D)                (None, 15, 128)      98432       ['cConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " fMaxP2 (MaxPooling1D)          (None, 15, 128)      0           ['fConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP2 (MaxPooling1D)          (None, 7, 128)       0           ['cConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " fFlat1 (Flatten)               (None, 1920)         0           ['fMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " cFlat1 (Flatten)               (None, 896)          0           ['cMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " merge_1 (Concatenate)          (None, 2816)         0           ['fFlat1[0][0]',                 \n",
            "                                                                  'cFlat1[0][0]']                 \n",
            "                                                                                                  \n",
            " mDrop1 (Dropout)               (None, 2816)         0           ['merge_1[0][0]']                \n",
            "                                                                                                  \n",
            " reshape1 (Reshape)             (None, 1, 2816)      0           ['mDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 1, 64)        737536      ['reshape1[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 64)           33024       ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " outLayer (Dense)               (None, 5)            325         ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,336,613\n",
            "Trainable params: 1,336,613\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_30_epochs.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY95My2CXMuq",
        "outputId": "3c38d375-9194-40a5-d8b5-1b1177f28891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inLayer (InputLayer)           [(None, 3000, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " fConv1 (Conv1D)                (None, 500, 64)      3264        ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " cConv1 (Conv1D)                (None, 60, 32)       12832       ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " fMaxP1 (MaxPooling1D)          (None, 62, 64)       0           ['fConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP1 (MaxPooling1D)          (None, 15, 32)       0           ['cConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " fDrop1 (Dropout)               (None, 62, 64)       0           ['fMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " cDrop1 (Dropout)               (None, 15, 32)       0           ['cMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv2 (Conv1D)                (None, 62, 128)      65664       ['fDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv2 (Conv1D)                (None, 15, 128)      24704       ['cDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv3 (Conv1D)                (None, 62, 128)      131200      ['fConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv3 (Conv1D)                (None, 15, 128)      98432       ['cConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv4 (Conv1D)                (None, 62, 128)      131200      ['fConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv4 (Conv1D)                (None, 15, 128)      98432       ['cConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " fMaxP2 (MaxPooling1D)          (None, 15, 128)      0           ['fConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP2 (MaxPooling1D)          (None, 7, 128)       0           ['cConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " fFlat1 (Flatten)               (None, 1920)         0           ['fMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " cFlat1 (Flatten)               (None, 896)          0           ['cMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " merge_1 (Concatenate)          (None, 2816)         0           ['fFlat1[0][0]',                 \n",
            "                                                                  'cFlat1[0][0]']                 \n",
            "                                                                                                  \n",
            " mDrop1 (Dropout)               (None, 2816)         0           ['merge_1[0][0]']                \n",
            "                                                                                                  \n",
            " reshape1 (Reshape)             (None, 1, 2816)      0           ['mDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 1, 64)        737536      ['reshape1[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 64)           33024       ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " outLayer (Dense)               (None, 5)            325         ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,336,613\n",
            "Trainable params: 1,336,613\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=Adam(lr=1e-4)"
      ],
      "metadata": {
        "id": "LC47hv2Nna7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_30_epochs.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_3yuHXQ3pLGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_df=pd.read_csv('/content/gdrive/My Drive/physionet/ensemble/50_subs/transfer_set_50_subs.csv',header=None)"
      ],
      "metadata": {
        "id": "ub3LEbnWmUCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "y2uRVDiSL7ln",
        "outputId": "3f6beeb2-75ed-4f0d-ba6b-51f90508e81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8b5fbedd-4578-438c-8af6-3a4a4b4112ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>2961</th>\n",
              "      <th>2962</th>\n",
              "      <th>2963</th>\n",
              "      <th>2964</th>\n",
              "      <th>2965</th>\n",
              "      <th>2966</th>\n",
              "      <th>2967</th>\n",
              "      <th>2968</th>\n",
              "      <th>2969</th>\n",
              "      <th>2970</th>\n",
              "      <th>2971</th>\n",
              "      <th>2972</th>\n",
              "      <th>2973</th>\n",
              "      <th>2974</th>\n",
              "      <th>2975</th>\n",
              "      <th>2976</th>\n",
              "      <th>2977</th>\n",
              "      <th>2978</th>\n",
              "      <th>2979</th>\n",
              "      <th>2980</th>\n",
              "      <th>2981</th>\n",
              "      <th>2982</th>\n",
              "      <th>2983</th>\n",
              "      <th>2984</th>\n",
              "      <th>2985</th>\n",
              "      <th>2986</th>\n",
              "      <th>2987</th>\n",
              "      <th>2988</th>\n",
              "      <th>2989</th>\n",
              "      <th>2990</th>\n",
              "      <th>2991</th>\n",
              "      <th>2992</th>\n",
              "      <th>2993</th>\n",
              "      <th>2994</th>\n",
              "      <th>2995</th>\n",
              "      <th>2996</th>\n",
              "      <th>2997</th>\n",
              "      <th>2998</th>\n",
              "      <th>2999</th>\n",
              "      <th>3000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.068014</td>\n",
              "      <td>0.082915</td>\n",
              "      <td>0.077628</td>\n",
              "      <td>0.074744</td>\n",
              "      <td>0.060804</td>\n",
              "      <td>0.063688</td>\n",
              "      <td>0.050710</td>\n",
              "      <td>0.029561</td>\n",
              "      <td>0.010815</td>\n",
              "      <td>0.008412</td>\n",
              "      <td>0.016102</td>\n",
              "      <td>0.014660</td>\n",
              "      <td>0.029080</td>\n",
              "      <td>0.012738</td>\n",
              "      <td>0.022351</td>\n",
              "      <td>0.043981</td>\n",
              "      <td>0.045423</td>\n",
              "      <td>0.052633</td>\n",
              "      <td>0.038213</td>\n",
              "      <td>0.029080</td>\n",
              "      <td>0.021870</td>\n",
              "      <td>0.013218</td>\n",
              "      <td>0.004566</td>\n",
              "      <td>0.002644</td>\n",
              "      <td>-0.000721</td>\n",
              "      <td>0.005047</td>\n",
              "      <td>0.007450</td>\n",
              "      <td>0.023793</td>\n",
              "      <td>0.011776</td>\n",
              "      <td>0.007450</td>\n",
              "      <td>0.001682</td>\n",
              "      <td>0.003605</td>\n",
              "      <td>0.011776</td>\n",
              "      <td>0.011296</td>\n",
              "      <td>0.008892</td>\n",
              "      <td>0.029561</td>\n",
              "      <td>0.028119</td>\n",
              "      <td>0.032445</td>\n",
              "      <td>0.031003</td>\n",
              "      <td>0.037732</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.057440</td>\n",
              "      <td>-0.060324</td>\n",
              "      <td>-0.058401</td>\n",
              "      <td>-0.060804</td>\n",
              "      <td>-0.068014</td>\n",
              "      <td>-0.063688</td>\n",
              "      <td>-0.054556</td>\n",
              "      <td>-0.054075</td>\n",
              "      <td>-0.053114</td>\n",
              "      <td>-0.050230</td>\n",
              "      <td>-0.060324</td>\n",
              "      <td>-0.059843</td>\n",
              "      <td>-0.054075</td>\n",
              "      <td>-0.050710</td>\n",
              "      <td>-0.040136</td>\n",
              "      <td>-0.057440</td>\n",
              "      <td>-0.053594</td>\n",
              "      <td>-0.037252</td>\n",
              "      <td>-0.033406</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>-0.005047</td>\n",
              "      <td>0.004086</td>\n",
              "      <td>0.008892</td>\n",
              "      <td>0.010815</td>\n",
              "      <td>0.014660</td>\n",
              "      <td>0.031484</td>\n",
              "      <td>0.020909</td>\n",
              "      <td>0.044942</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>-0.007450</td>\n",
              "      <td>-0.010334</td>\n",
              "      <td>-0.016102</td>\n",
              "      <td>-0.034368</td>\n",
              "      <td>-0.055998</td>\n",
              "      <td>-0.074263</td>\n",
              "      <td>-0.071860</td>\n",
              "      <td>-0.077147</td>\n",
              "      <td>-0.084838</td>\n",
              "      <td>-0.090125</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.104729</td>\n",
              "      <td>0.054513</td>\n",
              "      <td>-0.020131</td>\n",
              "      <td>-0.064918</td>\n",
              "      <td>-0.122825</td>\n",
              "      <td>-0.127801</td>\n",
              "      <td>-0.107443</td>\n",
              "      <td>-0.086633</td>\n",
              "      <td>-0.051799</td>\n",
              "      <td>-0.033251</td>\n",
              "      <td>-0.013346</td>\n",
              "      <td>-0.023751</td>\n",
              "      <td>-0.005203</td>\n",
              "      <td>0.001583</td>\n",
              "      <td>0.003393</td>\n",
              "      <td>0.020584</td>\n",
              "      <td>0.017417</td>\n",
              "      <td>-0.010631</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>-0.006560</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>0.004750</td>\n",
              "      <td>0.039132</td>\n",
              "      <td>0.064466</td>\n",
              "      <td>0.067180</td>\n",
              "      <td>0.054513</td>\n",
              "      <td>0.048180</td>\n",
              "      <td>0.033251</td>\n",
              "      <td>0.040037</td>\n",
              "      <td>0.040037</td>\n",
              "      <td>0.025108</td>\n",
              "      <td>0.005203</td>\n",
              "      <td>0.011988</td>\n",
              "      <td>-0.031894</td>\n",
              "      <td>-0.048180</td>\n",
              "      <td>-0.108348</td>\n",
              "      <td>-0.094776</td>\n",
              "      <td>-0.113324</td>\n",
              "      <td>-0.091157</td>\n",
              "      <td>-0.108800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.043203</td>\n",
              "      <td>0.015608</td>\n",
              "      <td>0.062656</td>\n",
              "      <td>0.059942</td>\n",
              "      <td>0.095681</td>\n",
              "      <td>0.097491</td>\n",
              "      <td>0.060394</td>\n",
              "      <td>0.055870</td>\n",
              "      <td>0.040489</td>\n",
              "      <td>0.015608</td>\n",
              "      <td>0.020584</td>\n",
              "      <td>0.036870</td>\n",
              "      <td>0.050894</td>\n",
              "      <td>0.066728</td>\n",
              "      <td>0.090252</td>\n",
              "      <td>0.130515</td>\n",
              "      <td>0.178017</td>\n",
              "      <td>0.179826</td>\n",
              "      <td>0.196565</td>\n",
              "      <td>0.176659</td>\n",
              "      <td>0.162635</td>\n",
              "      <td>0.115586</td>\n",
              "      <td>0.076228</td>\n",
              "      <td>0.041846</td>\n",
              "      <td>0.000679</td>\n",
              "      <td>-0.002941</td>\n",
              "      <td>-0.046823</td>\n",
              "      <td>-0.040037</td>\n",
              "      <td>-0.070347</td>\n",
              "      <td>-0.102467</td>\n",
              "      <td>-0.123729</td>\n",
              "      <td>-0.120563</td>\n",
              "      <td>-0.129158</td>\n",
              "      <td>-0.149968</td>\n",
              "      <td>-0.173945</td>\n",
              "      <td>-0.187064</td>\n",
              "      <td>-0.171231</td>\n",
              "      <td>-0.149516</td>\n",
              "      <td>-0.121467</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002281</td>\n",
              "      <td>-0.031309</td>\n",
              "      <td>-0.007672</td>\n",
              "      <td>-0.020527</td>\n",
              "      <td>-0.003110</td>\n",
              "      <td>-0.011404</td>\n",
              "      <td>0.006013</td>\n",
              "      <td>-0.029236</td>\n",
              "      <td>-0.025089</td>\n",
              "      <td>-0.042091</td>\n",
              "      <td>-0.021357</td>\n",
              "      <td>-0.010160</td>\n",
              "      <td>-0.032553</td>\n",
              "      <td>-0.015136</td>\n",
              "      <td>-0.024260</td>\n",
              "      <td>-0.035042</td>\n",
              "      <td>-0.059508</td>\n",
              "      <td>-0.047482</td>\n",
              "      <td>-0.049141</td>\n",
              "      <td>-0.018869</td>\n",
              "      <td>-0.009331</td>\n",
              "      <td>-0.001866</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>-0.001037</td>\n",
              "      <td>-0.005598</td>\n",
              "      <td>0.006013</td>\n",
              "      <td>0.027577</td>\n",
              "      <td>0.029651</td>\n",
              "      <td>0.064485</td>\n",
              "      <td>0.063241</td>\n",
              "      <td>0.025504</td>\n",
              "      <td>0.040433</td>\n",
              "      <td>0.035456</td>\n",
              "      <td>0.042506</td>\n",
              "      <td>0.026333</td>\n",
              "      <td>0.035456</td>\n",
              "      <td>0.023430</td>\n",
              "      <td>-0.001451</td>\n",
              "      <td>-0.027162</td>\n",
              "      <td>0.024674</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022601</td>\n",
              "      <td>0.001037</td>\n",
              "      <td>0.003525</td>\n",
              "      <td>-0.009745</td>\n",
              "      <td>-0.031724</td>\n",
              "      <td>-0.015136</td>\n",
              "      <td>-0.012233</td>\n",
              "      <td>-0.014722</td>\n",
              "      <td>-0.036286</td>\n",
              "      <td>-0.028406</td>\n",
              "      <td>-0.025918</td>\n",
              "      <td>0.001866</td>\n",
              "      <td>0.019698</td>\n",
              "      <td>0.014722</td>\n",
              "      <td>-0.031309</td>\n",
              "      <td>0.011819</td>\n",
              "      <td>-0.007257</td>\n",
              "      <td>-0.003110</td>\n",
              "      <td>0.018454</td>\n",
              "      <td>0.010575</td>\n",
              "      <td>-0.002696</td>\n",
              "      <td>0.002281</td>\n",
              "      <td>0.011404</td>\n",
              "      <td>0.044580</td>\n",
              "      <td>0.027162</td>\n",
              "      <td>0.057020</td>\n",
              "      <td>0.086464</td>\n",
              "      <td>0.056191</td>\n",
              "      <td>0.036700</td>\n",
              "      <td>0.054532</td>\n",
              "      <td>0.088122</td>\n",
              "      <td>0.057850</td>\n",
              "      <td>0.027992</td>\n",
              "      <td>0.038359</td>\n",
              "      <td>0.040847</td>\n",
              "      <td>0.053703</td>\n",
              "      <td>0.072779</td>\n",
              "      <td>0.055362</td>\n",
              "      <td>0.029651</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.025235</td>\n",
              "      <td>-0.037732</td>\n",
              "      <td>-0.033406</td>\n",
              "      <td>-0.031964</td>\n",
              "      <td>-0.034848</td>\n",
              "      <td>-0.041097</td>\n",
              "      <td>-0.031484</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>-0.019948</td>\n",
              "      <td>-0.030522</td>\n",
              "      <td>-0.031484</td>\n",
              "      <td>-0.035329</td>\n",
              "      <td>-0.035810</td>\n",
              "      <td>-0.031964</td>\n",
              "      <td>-0.034368</td>\n",
              "      <td>-0.031964</td>\n",
              "      <td>-0.030522</td>\n",
              "      <td>-0.035810</td>\n",
              "      <td>-0.048788</td>\n",
              "      <td>-0.046865</td>\n",
              "      <td>-0.055998</td>\n",
              "      <td>-0.069456</td>\n",
              "      <td>-0.068014</td>\n",
              "      <td>-0.070898</td>\n",
              "      <td>-0.063208</td>\n",
              "      <td>-0.052152</td>\n",
              "      <td>-0.059362</td>\n",
              "      <td>-0.066092</td>\n",
              "      <td>-0.058401</td>\n",
              "      <td>-0.045904</td>\n",
              "      <td>-0.036290</td>\n",
              "      <td>-0.023793</td>\n",
              "      <td>-0.017544</td>\n",
              "      <td>-0.019467</td>\n",
              "      <td>-0.021390</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.014660</td>\n",
              "      <td>-0.023793</td>\n",
              "      <td>-0.024754</td>\n",
              "      <td>-0.026677</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028119</td>\n",
              "      <td>-0.022351</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.029561</td>\n",
              "      <td>-0.028600</td>\n",
              "      <td>-0.027638</td>\n",
              "      <td>-0.034368</td>\n",
              "      <td>-0.039655</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>-0.023793</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.009854</td>\n",
              "      <td>-0.011296</td>\n",
              "      <td>-0.015141</td>\n",
              "      <td>-0.002163</td>\n",
              "      <td>-0.003124</td>\n",
              "      <td>-0.004086</td>\n",
              "      <td>-0.016102</td>\n",
              "      <td>-0.026196</td>\n",
              "      <td>-0.025235</td>\n",
              "      <td>-0.013699</td>\n",
              "      <td>-0.003605</td>\n",
              "      <td>0.000721</td>\n",
              "      <td>0.014660</td>\n",
              "      <td>0.014180</td>\n",
              "      <td>0.032445</td>\n",
              "      <td>0.021870</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.010334</td>\n",
              "      <td>-0.012738</td>\n",
              "      <td>-0.015141</td>\n",
              "      <td>-0.013699</td>\n",
              "      <td>-0.018025</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.021390</td>\n",
              "      <td>-0.002644</td>\n",
              "      <td>-0.020428</td>\n",
              "      <td>-0.025235</td>\n",
              "      <td>-0.024754</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.097914</td>\n",
              "      <td>-0.100520</td>\n",
              "      <td>-0.044574</td>\n",
              "      <td>-0.079540</td>\n",
              "      <td>-0.071235</td>\n",
              "      <td>-0.029713</td>\n",
              "      <td>-0.041951</td>\n",
              "      <td>0.000445</td>\n",
              "      <td>-0.031024</td>\n",
              "      <td>0.172217</td>\n",
              "      <td>0.081305</td>\n",
              "      <td>-0.077792</td>\n",
              "      <td>0.055954</td>\n",
              "      <td>0.078245</td>\n",
              "      <td>0.012683</td>\n",
              "      <td>0.071252</td>\n",
              "      <td>0.033226</td>\n",
              "      <td>-0.018349</td>\n",
              "      <td>0.053332</td>\n",
              "      <td>0.029292</td>\n",
              "      <td>0.057265</td>\n",
              "      <td>0.113648</td>\n",
              "      <td>0.114960</td>\n",
              "      <td>-0.008733</td>\n",
              "      <td>0.083053</td>\n",
              "      <td>0.309896</td>\n",
              "      <td>-0.039329</td>\n",
              "      <td>0.017054</td>\n",
              "      <td>0.020988</td>\n",
              "      <td>0.075623</td>\n",
              "      <td>0.035849</td>\n",
              "      <td>0.084801</td>\n",
              "      <td>0.085238</td>\n",
              "      <td>0.089172</td>\n",
              "      <td>0.064259</td>\n",
              "      <td>0.090920</td>\n",
              "      <td>0.112337</td>\n",
              "      <td>0.100536</td>\n",
              "      <td>0.103158</td>\n",
              "      <td>0.123701</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048524</td>\n",
              "      <td>0.044590</td>\n",
              "      <td>0.061636</td>\n",
              "      <td>0.131569</td>\n",
              "      <td>-0.057686</td>\n",
              "      <td>-0.183127</td>\n",
              "      <td>-0.274039</td>\n",
              "      <td>-0.252622</td>\n",
              "      <td>-0.243444</td>\n",
              "      <td>-0.238636</td>\n",
              "      <td>-0.231206</td>\n",
              "      <td>-0.213723</td>\n",
              "      <td>-0.209789</td>\n",
              "      <td>-0.165644</td>\n",
              "      <td>-0.112758</td>\n",
              "      <td>-0.099208</td>\n",
              "      <td>0.284546</td>\n",
              "      <td>0.265314</td>\n",
              "      <td>0.390318</td>\n",
              "      <td>0.430966</td>\n",
              "      <td>0.370650</td>\n",
              "      <td>0.395563</td>\n",
              "      <td>0.399934</td>\n",
              "      <td>0.405616</td>\n",
              "      <td>0.363657</td>\n",
              "      <td>0.385073</td>\n",
              "      <td>0.365842</td>\n",
              "      <td>0.339617</td>\n",
              "      <td>0.292413</td>\n",
              "      <td>0.264003</td>\n",
              "      <td>0.167409</td>\n",
              "      <td>0.220732</td>\n",
              "      <td>0.191011</td>\n",
              "      <td>0.119767</td>\n",
              "      <td>0.165661</td>\n",
              "      <td>0.270996</td>\n",
              "      <td>0.200190</td>\n",
              "      <td>0.246520</td>\n",
              "      <td>0.166535</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116713</th>\n",
              "      <td>0.032558</td>\n",
              "      <td>0.033944</td>\n",
              "      <td>0.046413</td>\n",
              "      <td>0.056111</td>\n",
              "      <td>0.060267</td>\n",
              "      <td>0.066271</td>\n",
              "      <td>0.077816</td>\n",
              "      <td>0.058882</td>\n",
              "      <td>0.078278</td>\n",
              "      <td>0.051493</td>\n",
              "      <td>0.040871</td>\n",
              "      <td>0.061191</td>\n",
              "      <td>0.023322</td>\n",
              "      <td>0.020089</td>\n",
              "      <td>-0.002540</td>\n",
              "      <td>0.032558</td>\n",
              "      <td>0.050569</td>\n",
              "      <td>0.007620</td>\n",
              "      <td>-0.010853</td>\n",
              "      <td>-0.022860</td>\n",
              "      <td>-0.023322</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>0.066271</td>\n",
              "      <td>0.086129</td>\n",
              "      <td>0.061653</td>\n",
              "      <td>0.001616</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>0.001616</td>\n",
              "      <td>0.003925</td>\n",
              "      <td>0.010391</td>\n",
              "      <td>0.000693</td>\n",
              "      <td>0.038562</td>\n",
              "      <td>-0.009467</td>\n",
              "      <td>-0.008544</td>\n",
              "      <td>0.016395</td>\n",
              "      <td>0.021475</td>\n",
              "      <td>0.052416</td>\n",
              "      <td>0.087514</td>\n",
              "      <td>0.063962</td>\n",
              "      <td>0.018242</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.039024</td>\n",
              "      <td>-0.089362</td>\n",
              "      <td>-0.062576</td>\n",
              "      <td>-0.087976</td>\n",
              "      <td>-0.094442</td>\n",
              "      <td>-0.128616</td>\n",
              "      <td>-0.102293</td>\n",
              "      <td>-0.103678</td>\n",
              "      <td>-0.123998</td>\n",
              "      <td>-0.111529</td>\n",
              "      <td>-0.124922</td>\n",
              "      <td>-0.077816</td>\n",
              "      <td>-0.069965</td>\n",
              "      <td>-0.093980</td>\n",
              "      <td>-0.049184</td>\n",
              "      <td>-0.066271</td>\n",
              "      <td>-0.044104</td>\n",
              "      <td>-0.045489</td>\n",
              "      <td>-0.018242</td>\n",
              "      <td>-0.021936</td>\n",
              "      <td>-0.031173</td>\n",
              "      <td>-0.020551</td>\n",
              "      <td>-0.010853</td>\n",
              "      <td>-0.014085</td>\n",
              "      <td>-0.013624</td>\n",
              "      <td>0.019627</td>\n",
              "      <td>0.042718</td>\n",
              "      <td>0.064885</td>\n",
              "      <td>0.028864</td>\n",
              "      <td>0.026093</td>\n",
              "      <td>0.024707</td>\n",
              "      <td>0.025631</td>\n",
              "      <td>0.015933</td>\n",
              "      <td>0.044565</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>0.018242</td>\n",
              "      <td>-0.028402</td>\n",
              "      <td>0.021475</td>\n",
              "      <td>0.028402</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116714</th>\n",
              "      <td>0.068695</td>\n",
              "      <td>0.059483</td>\n",
              "      <td>0.051071</td>\n",
              "      <td>0.044662</td>\n",
              "      <td>0.037051</td>\n",
              "      <td>0.041057</td>\n",
              "      <td>0.040656</td>\n",
              "      <td>0.046264</td>\n",
              "      <td>0.039054</td>\n",
              "      <td>0.045063</td>\n",
              "      <td>0.044261</td>\n",
              "      <td>0.039855</td>\n",
              "      <td>0.034648</td>\n",
              "      <td>0.025035</td>\n",
              "      <td>0.025836</td>\n",
              "      <td>0.022631</td>\n",
              "      <td>0.009413</td>\n",
              "      <td>0.004206</td>\n",
              "      <td>0.006209</td>\n",
              "      <td>0.000601</td>\n",
              "      <td>-0.003805</td>\n",
              "      <td>0.001402</td>\n",
              "      <td>-0.005408</td>\n",
              "      <td>-0.004606</td>\n",
              "      <td>-0.005408</td>\n",
              "      <td>-0.008612</td>\n",
              "      <td>-0.013018</td>\n",
              "      <td>-0.010615</td>\n",
              "      <td>-0.006209</td>\n",
              "      <td>0.003405</td>\n",
              "      <td>0.012217</td>\n",
              "      <td>0.010615</td>\n",
              "      <td>0.007010</td>\n",
              "      <td>0.003004</td>\n",
              "      <td>0.011416</td>\n",
              "      <td>0.000601</td>\n",
              "      <td>-0.010214</td>\n",
              "      <td>-0.005808</td>\n",
              "      <td>0.001402</td>\n",
              "      <td>0.010214</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011015</td>\n",
              "      <td>0.012217</td>\n",
              "      <td>0.024234</td>\n",
              "      <td>0.022231</td>\n",
              "      <td>0.028640</td>\n",
              "      <td>0.035049</td>\n",
              "      <td>0.030643</td>\n",
              "      <td>0.024634</td>\n",
              "      <td>0.019026</td>\n",
              "      <td>0.021029</td>\n",
              "      <td>0.005808</td>\n",
              "      <td>0.003405</td>\n",
              "      <td>0.015021</td>\n",
              "      <td>0.019828</td>\n",
              "      <td>0.020228</td>\n",
              "      <td>0.011416</td>\n",
              "      <td>0.013819</td>\n",
              "      <td>0.007811</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>0.002203</td>\n",
              "      <td>-0.006209</td>\n",
              "      <td>-0.015421</td>\n",
              "      <td>-0.009413</td>\n",
              "      <td>0.005808</td>\n",
              "      <td>0.025035</td>\n",
              "      <td>0.024634</td>\n",
              "      <td>0.032245</td>\n",
              "      <td>0.033847</td>\n",
              "      <td>0.026236</td>\n",
              "      <td>0.032245</td>\n",
              "      <td>0.035850</td>\n",
              "      <td>0.031444</td>\n",
              "      <td>0.026637</td>\n",
              "      <td>0.023433</td>\n",
              "      <td>0.027839</td>\n",
              "      <td>0.023833</td>\n",
              "      <td>0.018626</td>\n",
              "      <td>0.005007</td>\n",
              "      <td>0.007010</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116715</th>\n",
              "      <td>0.013392</td>\n",
              "      <td>0.030717</td>\n",
              "      <td>0.029805</td>\n",
              "      <td>0.016127</td>\n",
              "      <td>0.026613</td>\n",
              "      <td>0.024334</td>\n",
              "      <td>0.019775</td>\n",
              "      <td>0.038012</td>\n",
              "      <td>0.027069</td>\n",
              "      <td>0.031629</td>\n",
              "      <td>0.029805</td>\n",
              "      <td>0.035276</td>\n",
              "      <td>0.038923</td>\n",
              "      <td>0.033908</td>\n",
              "      <td>0.034820</td>\n",
              "      <td>0.031629</td>\n",
              "      <td>0.018407</td>\n",
              "      <td>0.031629</td>\n",
              "      <td>0.036188</td>\n",
              "      <td>0.038468</td>\n",
              "      <td>0.045306</td>\n",
              "      <td>0.058072</td>\n",
              "      <td>0.064455</td>\n",
              "      <td>0.067191</td>\n",
              "      <td>0.048498</td>\n",
              "      <td>0.042115</td>\n",
              "      <td>0.041659</td>\n",
              "      <td>0.054881</td>\n",
              "      <td>0.050778</td>\n",
              "      <td>0.058528</td>\n",
              "      <td>0.058984</td>\n",
              "      <td>0.054881</td>\n",
              "      <td>0.073118</td>\n",
              "      <td>0.056249</td>\n",
              "      <td>0.066735</td>\n",
              "      <td>0.067647</td>\n",
              "      <td>0.053969</td>\n",
              "      <td>0.057616</td>\n",
              "      <td>0.056249</td>\n",
              "      <td>0.059440</td>\n",
              "      <td>...</td>\n",
              "      <td>0.029805</td>\n",
              "      <td>0.036188</td>\n",
              "      <td>0.032085</td>\n",
              "      <td>0.028893</td>\n",
              "      <td>0.032540</td>\n",
              "      <td>0.025246</td>\n",
              "      <td>0.030261</td>\n",
              "      <td>0.024790</td>\n",
              "      <td>0.027069</td>\n",
              "      <td>0.006097</td>\n",
              "      <td>0.005641</td>\n",
              "      <td>0.012936</td>\n",
              "      <td>0.021598</td>\n",
              "      <td>0.027981</td>\n",
              "      <td>0.026157</td>\n",
              "      <td>0.019319</td>\n",
              "      <td>0.018407</td>\n",
              "      <td>0.007009</td>\n",
              "      <td>0.001537</td>\n",
              "      <td>-0.003478</td>\n",
              "      <td>-0.006669</td>\n",
              "      <td>0.004729</td>\n",
              "      <td>0.012936</td>\n",
              "      <td>0.015671</td>\n",
              "      <td>0.011568</td>\n",
              "      <td>0.016583</td>\n",
              "      <td>0.016583</td>\n",
              "      <td>0.015671</td>\n",
              "      <td>0.007009</td>\n",
              "      <td>0.004273</td>\n",
              "      <td>0.013392</td>\n",
              "      <td>0.018863</td>\n",
              "      <td>0.034820</td>\n",
              "      <td>0.034364</td>\n",
              "      <td>0.042115</td>\n",
              "      <td>0.045306</td>\n",
              "      <td>0.041659</td>\n",
              "      <td>0.032996</td>\n",
              "      <td>0.024334</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116716</th>\n",
              "      <td>-0.057457</td>\n",
              "      <td>-0.065629</td>\n",
              "      <td>-0.101198</td>\n",
              "      <td>-0.114176</td>\n",
              "      <td>-0.141093</td>\n",
              "      <td>-0.184354</td>\n",
              "      <td>-0.222807</td>\n",
              "      <td>-0.230017</td>\n",
              "      <td>-0.242514</td>\n",
              "      <td>-0.231459</td>\n",
              "      <td>-0.214636</td>\n",
              "      <td>-0.201177</td>\n",
              "      <td>-0.194448</td>\n",
              "      <td>-0.182912</td>\n",
              "      <td>-0.164646</td>\n",
              "      <td>-0.146861</td>\n",
              "      <td>-0.135325</td>\n",
              "      <td>-0.129557</td>\n",
              "      <td>-0.120905</td>\n",
              "      <td>-0.129557</td>\n",
              "      <td>-0.148784</td>\n",
              "      <td>-0.165608</td>\n",
              "      <td>-0.181470</td>\n",
              "      <td>-0.172337</td>\n",
              "      <td>-0.145900</td>\n",
              "      <td>-0.143497</td>\n",
              "      <td>-0.133403</td>\n",
              "      <td>-0.126673</td>\n",
              "      <td>-0.128596</td>\n",
              "      <td>-0.130038</td>\n",
              "      <td>-0.112734</td>\n",
              "      <td>-0.101679</td>\n",
              "      <td>-0.106966</td>\n",
              "      <td>-0.084855</td>\n",
              "      <td>-0.062745</td>\n",
              "      <td>-0.063706</td>\n",
              "      <td>-0.049286</td>\n",
              "      <td>-0.065629</td>\n",
              "      <td>-0.060822</td>\n",
              "      <td>-0.057457</td>\n",
              "      <td>...</td>\n",
              "      <td>0.219407</td>\n",
              "      <td>0.210755</td>\n",
              "      <td>0.191048</td>\n",
              "      <td>0.169418</td>\n",
              "      <td>0.135290</td>\n",
              "      <td>0.114141</td>\n",
              "      <td>0.103085</td>\n",
              "      <td>0.096356</td>\n",
              "      <td>0.093472</td>\n",
              "      <td>0.091549</td>\n",
              "      <td>0.094433</td>\n",
              "      <td>0.072323</td>\n",
              "      <td>0.042041</td>\n",
              "      <td>0.010797</td>\n",
              "      <td>-0.013236</td>\n",
              "      <td>-0.033424</td>\n",
              "      <td>-0.029579</td>\n",
              "      <td>-0.028617</td>\n",
              "      <td>-0.036789</td>\n",
              "      <td>-0.047363</td>\n",
              "      <td>-0.064187</td>\n",
              "      <td>-0.071877</td>\n",
              "      <td>-0.080049</td>\n",
              "      <td>-0.053131</td>\n",
              "      <td>-0.051689</td>\n",
              "      <td>-0.046402</td>\n",
              "      <td>-0.063225</td>\n",
              "      <td>-0.052170</td>\n",
              "      <td>-0.074281</td>\n",
              "      <td>-0.079087</td>\n",
              "      <td>-0.085817</td>\n",
              "      <td>-0.068993</td>\n",
              "      <td>-0.058899</td>\n",
              "      <td>-0.043999</td>\n",
              "      <td>-0.058419</td>\n",
              "      <td>-0.065629</td>\n",
              "      <td>-0.070916</td>\n",
              "      <td>-0.068513</td>\n",
              "      <td>-0.090143</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116717</th>\n",
              "      <td>-0.065742</td>\n",
              "      <td>-0.082698</td>\n",
              "      <td>-0.086365</td>\n",
              "      <td>-0.053368</td>\n",
              "      <td>-0.023122</td>\n",
              "      <td>-0.024038</td>\n",
              "      <td>-0.046494</td>\n",
              "      <td>-0.133109</td>\n",
              "      <td>-0.211476</td>\n",
              "      <td>-0.300383</td>\n",
              "      <td>-0.332463</td>\n",
              "      <td>-0.329713</td>\n",
              "      <td>-0.355835</td>\n",
              "      <td>-0.354919</td>\n",
              "      <td>-0.328338</td>\n",
              "      <td>-0.288467</td>\n",
              "      <td>-0.260970</td>\n",
              "      <td>-0.271053</td>\n",
              "      <td>-0.271969</td>\n",
              "      <td>-0.232099</td>\n",
              "      <td>-0.191311</td>\n",
              "      <td>-0.132193</td>\n",
              "      <td>-0.048785</td>\n",
              "      <td>0.000709</td>\n",
              "      <td>0.043788</td>\n",
              "      <td>0.034164</td>\n",
              "      <td>0.035539</td>\n",
              "      <td>0.087325</td>\n",
              "      <td>0.130403</td>\n",
              "      <td>0.125821</td>\n",
              "      <td>0.083200</td>\n",
              "      <td>0.050204</td>\n",
              "      <td>0.046996</td>\n",
              "      <td>0.060744</td>\n",
              "      <td>0.028664</td>\n",
              "      <td>-0.039620</td>\n",
              "      <td>-0.069866</td>\n",
              "      <td>-0.056118</td>\n",
              "      <td>-0.013039</td>\n",
              "      <td>-0.011206</td>\n",
              "      <td>...</td>\n",
              "      <td>0.161108</td>\n",
              "      <td>0.153776</td>\n",
              "      <td>0.141860</td>\n",
              "      <td>0.093282</td>\n",
              "      <td>0.067619</td>\n",
              "      <td>0.056620</td>\n",
              "      <td>0.041038</td>\n",
              "      <td>0.019041</td>\n",
              "      <td>0.071743</td>\n",
              "      <td>0.098782</td>\n",
              "      <td>0.080450</td>\n",
              "      <td>0.012625</td>\n",
              "      <td>0.031414</td>\n",
              "      <td>0.062577</td>\n",
              "      <td>0.058911</td>\n",
              "      <td>-0.007540</td>\n",
              "      <td>-0.025413</td>\n",
              "      <td>0.024998</td>\n",
              "      <td>0.069452</td>\n",
              "      <td>0.037830</td>\n",
              "      <td>-0.017164</td>\n",
              "      <td>-0.020830</td>\n",
              "      <td>-0.029537</td>\n",
              "      <td>-0.040078</td>\n",
              "      <td>-0.102863</td>\n",
              "      <td>-0.134026</td>\n",
              "      <td>-0.169772</td>\n",
              "      <td>-0.123027</td>\n",
              "      <td>-0.103321</td>\n",
              "      <td>-0.111570</td>\n",
              "      <td>-0.135401</td>\n",
              "      <td>-0.128985</td>\n",
              "      <td>-0.091864</td>\n",
              "      <td>-0.071700</td>\n",
              "      <td>-0.102404</td>\n",
              "      <td>-0.157398</td>\n",
              "      <td>-0.150524</td>\n",
              "      <td>-0.087281</td>\n",
              "      <td>-0.042828</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>116718 rows × 3001 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b5fbedd-4578-438c-8af6-3a4a4b4112ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b5fbedd-4578-438c-8af6-3a4a4b4112ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b5fbedd-4578-438c-8af6-3a4a4b4112ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0         1         2     ...      2998      2999  3000\n",
              "0       0.068014  0.082915  0.077628  ... -0.084838 -0.090125     4\n",
              "1       0.104729  0.054513 -0.020131  ... -0.149516 -0.121467     3\n",
              "2       0.002281 -0.031309 -0.007672  ...  0.055362  0.029651     2\n",
              "3      -0.025235 -0.037732 -0.033406  ... -0.025235 -0.024754     2\n",
              "4       0.097914 -0.100520 -0.044574  ...  0.246520  0.166535     0\n",
              "...          ...       ...       ...  ...       ...       ...   ...\n",
              "116713  0.032558  0.033944  0.046413  ...  0.021475  0.028402     2\n",
              "116714  0.068695  0.059483  0.051071  ...  0.005007  0.007010     4\n",
              "116715  0.013392  0.030717  0.029805  ...  0.032996  0.024334     4\n",
              "116716 -0.057457 -0.065629 -0.101198  ... -0.068513 -0.090143     2\n",
              "116717 -0.065742 -0.082698 -0.086365  ... -0.087281 -0.042828     2\n",
              "\n",
              "[116718 rows x 3001 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zb3xNvZIL-bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_df[3000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03SvXvUcgX8u",
        "outputId": "608558d5-af71-4522-d5be-bb06ee323d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         4\n",
              "1         3\n",
              "2         2\n",
              "3         2\n",
              "4         0\n",
              "         ..\n",
              "116713    2\n",
              "116714    4\n",
              "116715    4\n",
              "116716    2\n",
              "116717    2\n",
              "Name: 3000, Length: 116718, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_transfer_set=transfer_df.drop([3000],axis=1)"
      ],
      "metadata": {
        "id": "h-x3q_j3fU05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_transfer_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "gCVO7-O6ggAd",
        "outputId": "7f2fa399-2505-4331-9137-c77db526d50f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f68e7ad5-a2b3-4cd2-a4a3-926770a9ced6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>2960</th>\n",
              "      <th>2961</th>\n",
              "      <th>2962</th>\n",
              "      <th>2963</th>\n",
              "      <th>2964</th>\n",
              "      <th>2965</th>\n",
              "      <th>2966</th>\n",
              "      <th>2967</th>\n",
              "      <th>2968</th>\n",
              "      <th>2969</th>\n",
              "      <th>2970</th>\n",
              "      <th>2971</th>\n",
              "      <th>2972</th>\n",
              "      <th>2973</th>\n",
              "      <th>2974</th>\n",
              "      <th>2975</th>\n",
              "      <th>2976</th>\n",
              "      <th>2977</th>\n",
              "      <th>2978</th>\n",
              "      <th>2979</th>\n",
              "      <th>2980</th>\n",
              "      <th>2981</th>\n",
              "      <th>2982</th>\n",
              "      <th>2983</th>\n",
              "      <th>2984</th>\n",
              "      <th>2985</th>\n",
              "      <th>2986</th>\n",
              "      <th>2987</th>\n",
              "      <th>2988</th>\n",
              "      <th>2989</th>\n",
              "      <th>2990</th>\n",
              "      <th>2991</th>\n",
              "      <th>2992</th>\n",
              "      <th>2993</th>\n",
              "      <th>2994</th>\n",
              "      <th>2995</th>\n",
              "      <th>2996</th>\n",
              "      <th>2997</th>\n",
              "      <th>2998</th>\n",
              "      <th>2999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.068014</td>\n",
              "      <td>0.082915</td>\n",
              "      <td>0.077628</td>\n",
              "      <td>0.074744</td>\n",
              "      <td>0.060804</td>\n",
              "      <td>0.063688</td>\n",
              "      <td>0.050710</td>\n",
              "      <td>0.029561</td>\n",
              "      <td>0.010815</td>\n",
              "      <td>0.008412</td>\n",
              "      <td>0.016102</td>\n",
              "      <td>0.014660</td>\n",
              "      <td>0.029080</td>\n",
              "      <td>0.012738</td>\n",
              "      <td>0.022351</td>\n",
              "      <td>0.043981</td>\n",
              "      <td>0.045423</td>\n",
              "      <td>0.052633</td>\n",
              "      <td>0.038213</td>\n",
              "      <td>0.029080</td>\n",
              "      <td>0.021870</td>\n",
              "      <td>0.013218</td>\n",
              "      <td>0.004566</td>\n",
              "      <td>0.002644</td>\n",
              "      <td>-0.000721</td>\n",
              "      <td>0.005047</td>\n",
              "      <td>0.007450</td>\n",
              "      <td>0.023793</td>\n",
              "      <td>0.011776</td>\n",
              "      <td>0.007450</td>\n",
              "      <td>0.001682</td>\n",
              "      <td>0.003605</td>\n",
              "      <td>0.011776</td>\n",
              "      <td>0.011296</td>\n",
              "      <td>0.008892</td>\n",
              "      <td>0.029561</td>\n",
              "      <td>0.028119</td>\n",
              "      <td>0.032445</td>\n",
              "      <td>0.031003</td>\n",
              "      <td>0.037732</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.049268</td>\n",
              "      <td>-0.057440</td>\n",
              "      <td>-0.060324</td>\n",
              "      <td>-0.058401</td>\n",
              "      <td>-0.060804</td>\n",
              "      <td>-0.068014</td>\n",
              "      <td>-0.063688</td>\n",
              "      <td>-0.054556</td>\n",
              "      <td>-0.054075</td>\n",
              "      <td>-0.053114</td>\n",
              "      <td>-0.050230</td>\n",
              "      <td>-0.060324</td>\n",
              "      <td>-0.059843</td>\n",
              "      <td>-0.054075</td>\n",
              "      <td>-0.050710</td>\n",
              "      <td>-0.040136</td>\n",
              "      <td>-0.057440</td>\n",
              "      <td>-0.053594</td>\n",
              "      <td>-0.037252</td>\n",
              "      <td>-0.033406</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>-0.005047</td>\n",
              "      <td>0.004086</td>\n",
              "      <td>0.008892</td>\n",
              "      <td>0.010815</td>\n",
              "      <td>0.014660</td>\n",
              "      <td>0.031484</td>\n",
              "      <td>0.020909</td>\n",
              "      <td>0.044942</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>-0.007450</td>\n",
              "      <td>-0.010334</td>\n",
              "      <td>-0.016102</td>\n",
              "      <td>-0.034368</td>\n",
              "      <td>-0.055998</td>\n",
              "      <td>-0.074263</td>\n",
              "      <td>-0.071860</td>\n",
              "      <td>-0.077147</td>\n",
              "      <td>-0.084838</td>\n",
              "      <td>-0.090125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.104729</td>\n",
              "      <td>0.054513</td>\n",
              "      <td>-0.020131</td>\n",
              "      <td>-0.064918</td>\n",
              "      <td>-0.122825</td>\n",
              "      <td>-0.127801</td>\n",
              "      <td>-0.107443</td>\n",
              "      <td>-0.086633</td>\n",
              "      <td>-0.051799</td>\n",
              "      <td>-0.033251</td>\n",
              "      <td>-0.013346</td>\n",
              "      <td>-0.023751</td>\n",
              "      <td>-0.005203</td>\n",
              "      <td>0.001583</td>\n",
              "      <td>0.003393</td>\n",
              "      <td>0.020584</td>\n",
              "      <td>0.017417</td>\n",
              "      <td>-0.010631</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>-0.006560</td>\n",
              "      <td>0.007012</td>\n",
              "      <td>0.004750</td>\n",
              "      <td>0.039132</td>\n",
              "      <td>0.064466</td>\n",
              "      <td>0.067180</td>\n",
              "      <td>0.054513</td>\n",
              "      <td>0.048180</td>\n",
              "      <td>0.033251</td>\n",
              "      <td>0.040037</td>\n",
              "      <td>0.040037</td>\n",
              "      <td>0.025108</td>\n",
              "      <td>0.005203</td>\n",
              "      <td>0.011988</td>\n",
              "      <td>-0.031894</td>\n",
              "      <td>-0.048180</td>\n",
              "      <td>-0.108348</td>\n",
              "      <td>-0.094776</td>\n",
              "      <td>-0.113324</td>\n",
              "      <td>-0.091157</td>\n",
              "      <td>-0.108800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.058585</td>\n",
              "      <td>0.043203</td>\n",
              "      <td>0.015608</td>\n",
              "      <td>0.062656</td>\n",
              "      <td>0.059942</td>\n",
              "      <td>0.095681</td>\n",
              "      <td>0.097491</td>\n",
              "      <td>0.060394</td>\n",
              "      <td>0.055870</td>\n",
              "      <td>0.040489</td>\n",
              "      <td>0.015608</td>\n",
              "      <td>0.020584</td>\n",
              "      <td>0.036870</td>\n",
              "      <td>0.050894</td>\n",
              "      <td>0.066728</td>\n",
              "      <td>0.090252</td>\n",
              "      <td>0.130515</td>\n",
              "      <td>0.178017</td>\n",
              "      <td>0.179826</td>\n",
              "      <td>0.196565</td>\n",
              "      <td>0.176659</td>\n",
              "      <td>0.162635</td>\n",
              "      <td>0.115586</td>\n",
              "      <td>0.076228</td>\n",
              "      <td>0.041846</td>\n",
              "      <td>0.000679</td>\n",
              "      <td>-0.002941</td>\n",
              "      <td>-0.046823</td>\n",
              "      <td>-0.040037</td>\n",
              "      <td>-0.070347</td>\n",
              "      <td>-0.102467</td>\n",
              "      <td>-0.123729</td>\n",
              "      <td>-0.120563</td>\n",
              "      <td>-0.129158</td>\n",
              "      <td>-0.149968</td>\n",
              "      <td>-0.173945</td>\n",
              "      <td>-0.187064</td>\n",
              "      <td>-0.171231</td>\n",
              "      <td>-0.149516</td>\n",
              "      <td>-0.121467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002281</td>\n",
              "      <td>-0.031309</td>\n",
              "      <td>-0.007672</td>\n",
              "      <td>-0.020527</td>\n",
              "      <td>-0.003110</td>\n",
              "      <td>-0.011404</td>\n",
              "      <td>0.006013</td>\n",
              "      <td>-0.029236</td>\n",
              "      <td>-0.025089</td>\n",
              "      <td>-0.042091</td>\n",
              "      <td>-0.021357</td>\n",
              "      <td>-0.010160</td>\n",
              "      <td>-0.032553</td>\n",
              "      <td>-0.015136</td>\n",
              "      <td>-0.024260</td>\n",
              "      <td>-0.035042</td>\n",
              "      <td>-0.059508</td>\n",
              "      <td>-0.047482</td>\n",
              "      <td>-0.049141</td>\n",
              "      <td>-0.018869</td>\n",
              "      <td>-0.009331</td>\n",
              "      <td>-0.001866</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>-0.001037</td>\n",
              "      <td>-0.005598</td>\n",
              "      <td>0.006013</td>\n",
              "      <td>0.027577</td>\n",
              "      <td>0.029651</td>\n",
              "      <td>0.064485</td>\n",
              "      <td>0.063241</td>\n",
              "      <td>0.025504</td>\n",
              "      <td>0.040433</td>\n",
              "      <td>0.035456</td>\n",
              "      <td>0.042506</td>\n",
              "      <td>0.026333</td>\n",
              "      <td>0.035456</td>\n",
              "      <td>0.023430</td>\n",
              "      <td>-0.001451</td>\n",
              "      <td>-0.027162</td>\n",
              "      <td>0.024674</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003110</td>\n",
              "      <td>0.022601</td>\n",
              "      <td>0.001037</td>\n",
              "      <td>0.003525</td>\n",
              "      <td>-0.009745</td>\n",
              "      <td>-0.031724</td>\n",
              "      <td>-0.015136</td>\n",
              "      <td>-0.012233</td>\n",
              "      <td>-0.014722</td>\n",
              "      <td>-0.036286</td>\n",
              "      <td>-0.028406</td>\n",
              "      <td>-0.025918</td>\n",
              "      <td>0.001866</td>\n",
              "      <td>0.019698</td>\n",
              "      <td>0.014722</td>\n",
              "      <td>-0.031309</td>\n",
              "      <td>0.011819</td>\n",
              "      <td>-0.007257</td>\n",
              "      <td>-0.003110</td>\n",
              "      <td>0.018454</td>\n",
              "      <td>0.010575</td>\n",
              "      <td>-0.002696</td>\n",
              "      <td>0.002281</td>\n",
              "      <td>0.011404</td>\n",
              "      <td>0.044580</td>\n",
              "      <td>0.027162</td>\n",
              "      <td>0.057020</td>\n",
              "      <td>0.086464</td>\n",
              "      <td>0.056191</td>\n",
              "      <td>0.036700</td>\n",
              "      <td>0.054532</td>\n",
              "      <td>0.088122</td>\n",
              "      <td>0.057850</td>\n",
              "      <td>0.027992</td>\n",
              "      <td>0.038359</td>\n",
              "      <td>0.040847</td>\n",
              "      <td>0.053703</td>\n",
              "      <td>0.072779</td>\n",
              "      <td>0.055362</td>\n",
              "      <td>0.029651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.025235</td>\n",
              "      <td>-0.037732</td>\n",
              "      <td>-0.033406</td>\n",
              "      <td>-0.031964</td>\n",
              "      <td>-0.034848</td>\n",
              "      <td>-0.041097</td>\n",
              "      <td>-0.031484</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>-0.019948</td>\n",
              "      <td>-0.030522</td>\n",
              "      <td>-0.031484</td>\n",
              "      <td>-0.035329</td>\n",
              "      <td>-0.035810</td>\n",
              "      <td>-0.031964</td>\n",
              "      <td>-0.034368</td>\n",
              "      <td>-0.031964</td>\n",
              "      <td>-0.030522</td>\n",
              "      <td>-0.035810</td>\n",
              "      <td>-0.048788</td>\n",
              "      <td>-0.046865</td>\n",
              "      <td>-0.055998</td>\n",
              "      <td>-0.069456</td>\n",
              "      <td>-0.068014</td>\n",
              "      <td>-0.070898</td>\n",
              "      <td>-0.063208</td>\n",
              "      <td>-0.052152</td>\n",
              "      <td>-0.059362</td>\n",
              "      <td>-0.066092</td>\n",
              "      <td>-0.058401</td>\n",
              "      <td>-0.045904</td>\n",
              "      <td>-0.036290</td>\n",
              "      <td>-0.023793</td>\n",
              "      <td>-0.017544</td>\n",
              "      <td>-0.019467</td>\n",
              "      <td>-0.021390</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.014660</td>\n",
              "      <td>-0.023793</td>\n",
              "      <td>-0.024754</td>\n",
              "      <td>-0.026677</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.033887</td>\n",
              "      <td>-0.028119</td>\n",
              "      <td>-0.022351</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.029561</td>\n",
              "      <td>-0.028600</td>\n",
              "      <td>-0.027638</td>\n",
              "      <td>-0.034368</td>\n",
              "      <td>-0.039655</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>-0.023793</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.009854</td>\n",
              "      <td>-0.011296</td>\n",
              "      <td>-0.015141</td>\n",
              "      <td>-0.002163</td>\n",
              "      <td>-0.003124</td>\n",
              "      <td>-0.004086</td>\n",
              "      <td>-0.016102</td>\n",
              "      <td>-0.026196</td>\n",
              "      <td>-0.025235</td>\n",
              "      <td>-0.013699</td>\n",
              "      <td>-0.003605</td>\n",
              "      <td>0.000721</td>\n",
              "      <td>0.014660</td>\n",
              "      <td>0.014180</td>\n",
              "      <td>0.032445</td>\n",
              "      <td>0.021870</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.010334</td>\n",
              "      <td>-0.012738</td>\n",
              "      <td>-0.015141</td>\n",
              "      <td>-0.013699</td>\n",
              "      <td>-0.018025</td>\n",
              "      <td>-0.020909</td>\n",
              "      <td>-0.021390</td>\n",
              "      <td>-0.002644</td>\n",
              "      <td>-0.020428</td>\n",
              "      <td>-0.025235</td>\n",
              "      <td>-0.024754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.097914</td>\n",
              "      <td>-0.100520</td>\n",
              "      <td>-0.044574</td>\n",
              "      <td>-0.079540</td>\n",
              "      <td>-0.071235</td>\n",
              "      <td>-0.029713</td>\n",
              "      <td>-0.041951</td>\n",
              "      <td>0.000445</td>\n",
              "      <td>-0.031024</td>\n",
              "      <td>0.172217</td>\n",
              "      <td>0.081305</td>\n",
              "      <td>-0.077792</td>\n",
              "      <td>0.055954</td>\n",
              "      <td>0.078245</td>\n",
              "      <td>0.012683</td>\n",
              "      <td>0.071252</td>\n",
              "      <td>0.033226</td>\n",
              "      <td>-0.018349</td>\n",
              "      <td>0.053332</td>\n",
              "      <td>0.029292</td>\n",
              "      <td>0.057265</td>\n",
              "      <td>0.113648</td>\n",
              "      <td>0.114960</td>\n",
              "      <td>-0.008733</td>\n",
              "      <td>0.083053</td>\n",
              "      <td>0.309896</td>\n",
              "      <td>-0.039329</td>\n",
              "      <td>0.017054</td>\n",
              "      <td>0.020988</td>\n",
              "      <td>0.075623</td>\n",
              "      <td>0.035849</td>\n",
              "      <td>0.084801</td>\n",
              "      <td>0.085238</td>\n",
              "      <td>0.089172</td>\n",
              "      <td>0.064259</td>\n",
              "      <td>0.090920</td>\n",
              "      <td>0.112337</td>\n",
              "      <td>0.100536</td>\n",
              "      <td>0.103158</td>\n",
              "      <td>0.123701</td>\n",
              "      <td>...</td>\n",
              "      <td>0.202375</td>\n",
              "      <td>0.048524</td>\n",
              "      <td>0.044590</td>\n",
              "      <td>0.061636</td>\n",
              "      <td>0.131569</td>\n",
              "      <td>-0.057686</td>\n",
              "      <td>-0.183127</td>\n",
              "      <td>-0.274039</td>\n",
              "      <td>-0.252622</td>\n",
              "      <td>-0.243444</td>\n",
              "      <td>-0.238636</td>\n",
              "      <td>-0.231206</td>\n",
              "      <td>-0.213723</td>\n",
              "      <td>-0.209789</td>\n",
              "      <td>-0.165644</td>\n",
              "      <td>-0.112758</td>\n",
              "      <td>-0.099208</td>\n",
              "      <td>0.284546</td>\n",
              "      <td>0.265314</td>\n",
              "      <td>0.390318</td>\n",
              "      <td>0.430966</td>\n",
              "      <td>0.370650</td>\n",
              "      <td>0.395563</td>\n",
              "      <td>0.399934</td>\n",
              "      <td>0.405616</td>\n",
              "      <td>0.363657</td>\n",
              "      <td>0.385073</td>\n",
              "      <td>0.365842</td>\n",
              "      <td>0.339617</td>\n",
              "      <td>0.292413</td>\n",
              "      <td>0.264003</td>\n",
              "      <td>0.167409</td>\n",
              "      <td>0.220732</td>\n",
              "      <td>0.191011</td>\n",
              "      <td>0.119767</td>\n",
              "      <td>0.165661</td>\n",
              "      <td>0.270996</td>\n",
              "      <td>0.200190</td>\n",
              "      <td>0.246520</td>\n",
              "      <td>0.166535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116713</th>\n",
              "      <td>0.032558</td>\n",
              "      <td>0.033944</td>\n",
              "      <td>0.046413</td>\n",
              "      <td>0.056111</td>\n",
              "      <td>0.060267</td>\n",
              "      <td>0.066271</td>\n",
              "      <td>0.077816</td>\n",
              "      <td>0.058882</td>\n",
              "      <td>0.078278</td>\n",
              "      <td>0.051493</td>\n",
              "      <td>0.040871</td>\n",
              "      <td>0.061191</td>\n",
              "      <td>0.023322</td>\n",
              "      <td>0.020089</td>\n",
              "      <td>-0.002540</td>\n",
              "      <td>0.032558</td>\n",
              "      <td>0.050569</td>\n",
              "      <td>0.007620</td>\n",
              "      <td>-0.010853</td>\n",
              "      <td>-0.022860</td>\n",
              "      <td>-0.023322</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>0.066271</td>\n",
              "      <td>0.086129</td>\n",
              "      <td>0.061653</td>\n",
              "      <td>0.001616</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>0.001616</td>\n",
              "      <td>0.003925</td>\n",
              "      <td>0.010391</td>\n",
              "      <td>0.000693</td>\n",
              "      <td>0.038562</td>\n",
              "      <td>-0.009467</td>\n",
              "      <td>-0.008544</td>\n",
              "      <td>0.016395</td>\n",
              "      <td>0.021475</td>\n",
              "      <td>0.052416</td>\n",
              "      <td>0.087514</td>\n",
              "      <td>0.063962</td>\n",
              "      <td>0.018242</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.049645</td>\n",
              "      <td>-0.039024</td>\n",
              "      <td>-0.089362</td>\n",
              "      <td>-0.062576</td>\n",
              "      <td>-0.087976</td>\n",
              "      <td>-0.094442</td>\n",
              "      <td>-0.128616</td>\n",
              "      <td>-0.102293</td>\n",
              "      <td>-0.103678</td>\n",
              "      <td>-0.123998</td>\n",
              "      <td>-0.111529</td>\n",
              "      <td>-0.124922</td>\n",
              "      <td>-0.077816</td>\n",
              "      <td>-0.069965</td>\n",
              "      <td>-0.093980</td>\n",
              "      <td>-0.049184</td>\n",
              "      <td>-0.066271</td>\n",
              "      <td>-0.044104</td>\n",
              "      <td>-0.045489</td>\n",
              "      <td>-0.018242</td>\n",
              "      <td>-0.021936</td>\n",
              "      <td>-0.031173</td>\n",
              "      <td>-0.020551</td>\n",
              "      <td>-0.010853</td>\n",
              "      <td>-0.014085</td>\n",
              "      <td>-0.013624</td>\n",
              "      <td>0.019627</td>\n",
              "      <td>0.042718</td>\n",
              "      <td>0.064885</td>\n",
              "      <td>0.028864</td>\n",
              "      <td>0.026093</td>\n",
              "      <td>0.024707</td>\n",
              "      <td>0.025631</td>\n",
              "      <td>0.015933</td>\n",
              "      <td>0.044565</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>0.018242</td>\n",
              "      <td>-0.028402</td>\n",
              "      <td>0.021475</td>\n",
              "      <td>0.028402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116714</th>\n",
              "      <td>0.068695</td>\n",
              "      <td>0.059483</td>\n",
              "      <td>0.051071</td>\n",
              "      <td>0.044662</td>\n",
              "      <td>0.037051</td>\n",
              "      <td>0.041057</td>\n",
              "      <td>0.040656</td>\n",
              "      <td>0.046264</td>\n",
              "      <td>0.039054</td>\n",
              "      <td>0.045063</td>\n",
              "      <td>0.044261</td>\n",
              "      <td>0.039855</td>\n",
              "      <td>0.034648</td>\n",
              "      <td>0.025035</td>\n",
              "      <td>0.025836</td>\n",
              "      <td>0.022631</td>\n",
              "      <td>0.009413</td>\n",
              "      <td>0.004206</td>\n",
              "      <td>0.006209</td>\n",
              "      <td>0.000601</td>\n",
              "      <td>-0.003805</td>\n",
              "      <td>0.001402</td>\n",
              "      <td>-0.005408</td>\n",
              "      <td>-0.004606</td>\n",
              "      <td>-0.005408</td>\n",
              "      <td>-0.008612</td>\n",
              "      <td>-0.013018</td>\n",
              "      <td>-0.010615</td>\n",
              "      <td>-0.006209</td>\n",
              "      <td>0.003405</td>\n",
              "      <td>0.012217</td>\n",
              "      <td>0.010615</td>\n",
              "      <td>0.007010</td>\n",
              "      <td>0.003004</td>\n",
              "      <td>0.011416</td>\n",
              "      <td>0.000601</td>\n",
              "      <td>-0.010214</td>\n",
              "      <td>-0.005808</td>\n",
              "      <td>0.001402</td>\n",
              "      <td>0.010214</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006609</td>\n",
              "      <td>0.011015</td>\n",
              "      <td>0.012217</td>\n",
              "      <td>0.024234</td>\n",
              "      <td>0.022231</td>\n",
              "      <td>0.028640</td>\n",
              "      <td>0.035049</td>\n",
              "      <td>0.030643</td>\n",
              "      <td>0.024634</td>\n",
              "      <td>0.019026</td>\n",
              "      <td>0.021029</td>\n",
              "      <td>0.005808</td>\n",
              "      <td>0.003405</td>\n",
              "      <td>0.015021</td>\n",
              "      <td>0.019828</td>\n",
              "      <td>0.020228</td>\n",
              "      <td>0.011416</td>\n",
              "      <td>0.013819</td>\n",
              "      <td>0.007811</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>0.002203</td>\n",
              "      <td>-0.006209</td>\n",
              "      <td>-0.015421</td>\n",
              "      <td>-0.009413</td>\n",
              "      <td>0.005808</td>\n",
              "      <td>0.025035</td>\n",
              "      <td>0.024634</td>\n",
              "      <td>0.032245</td>\n",
              "      <td>0.033847</td>\n",
              "      <td>0.026236</td>\n",
              "      <td>0.032245</td>\n",
              "      <td>0.035850</td>\n",
              "      <td>0.031444</td>\n",
              "      <td>0.026637</td>\n",
              "      <td>0.023433</td>\n",
              "      <td>0.027839</td>\n",
              "      <td>0.023833</td>\n",
              "      <td>0.018626</td>\n",
              "      <td>0.005007</td>\n",
              "      <td>0.007010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116715</th>\n",
              "      <td>0.013392</td>\n",
              "      <td>0.030717</td>\n",
              "      <td>0.029805</td>\n",
              "      <td>0.016127</td>\n",
              "      <td>0.026613</td>\n",
              "      <td>0.024334</td>\n",
              "      <td>0.019775</td>\n",
              "      <td>0.038012</td>\n",
              "      <td>0.027069</td>\n",
              "      <td>0.031629</td>\n",
              "      <td>0.029805</td>\n",
              "      <td>0.035276</td>\n",
              "      <td>0.038923</td>\n",
              "      <td>0.033908</td>\n",
              "      <td>0.034820</td>\n",
              "      <td>0.031629</td>\n",
              "      <td>0.018407</td>\n",
              "      <td>0.031629</td>\n",
              "      <td>0.036188</td>\n",
              "      <td>0.038468</td>\n",
              "      <td>0.045306</td>\n",
              "      <td>0.058072</td>\n",
              "      <td>0.064455</td>\n",
              "      <td>0.067191</td>\n",
              "      <td>0.048498</td>\n",
              "      <td>0.042115</td>\n",
              "      <td>0.041659</td>\n",
              "      <td>0.054881</td>\n",
              "      <td>0.050778</td>\n",
              "      <td>0.058528</td>\n",
              "      <td>0.058984</td>\n",
              "      <td>0.054881</td>\n",
              "      <td>0.073118</td>\n",
              "      <td>0.056249</td>\n",
              "      <td>0.066735</td>\n",
              "      <td>0.067647</td>\n",
              "      <td>0.053969</td>\n",
              "      <td>0.057616</td>\n",
              "      <td>0.056249</td>\n",
              "      <td>0.059440</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033452</td>\n",
              "      <td>0.029805</td>\n",
              "      <td>0.036188</td>\n",
              "      <td>0.032085</td>\n",
              "      <td>0.028893</td>\n",
              "      <td>0.032540</td>\n",
              "      <td>0.025246</td>\n",
              "      <td>0.030261</td>\n",
              "      <td>0.024790</td>\n",
              "      <td>0.027069</td>\n",
              "      <td>0.006097</td>\n",
              "      <td>0.005641</td>\n",
              "      <td>0.012936</td>\n",
              "      <td>0.021598</td>\n",
              "      <td>0.027981</td>\n",
              "      <td>0.026157</td>\n",
              "      <td>0.019319</td>\n",
              "      <td>0.018407</td>\n",
              "      <td>0.007009</td>\n",
              "      <td>0.001537</td>\n",
              "      <td>-0.003478</td>\n",
              "      <td>-0.006669</td>\n",
              "      <td>0.004729</td>\n",
              "      <td>0.012936</td>\n",
              "      <td>0.015671</td>\n",
              "      <td>0.011568</td>\n",
              "      <td>0.016583</td>\n",
              "      <td>0.016583</td>\n",
              "      <td>0.015671</td>\n",
              "      <td>0.007009</td>\n",
              "      <td>0.004273</td>\n",
              "      <td>0.013392</td>\n",
              "      <td>0.018863</td>\n",
              "      <td>0.034820</td>\n",
              "      <td>0.034364</td>\n",
              "      <td>0.042115</td>\n",
              "      <td>0.045306</td>\n",
              "      <td>0.041659</td>\n",
              "      <td>0.032996</td>\n",
              "      <td>0.024334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116716</th>\n",
              "      <td>-0.057457</td>\n",
              "      <td>-0.065629</td>\n",
              "      <td>-0.101198</td>\n",
              "      <td>-0.114176</td>\n",
              "      <td>-0.141093</td>\n",
              "      <td>-0.184354</td>\n",
              "      <td>-0.222807</td>\n",
              "      <td>-0.230017</td>\n",
              "      <td>-0.242514</td>\n",
              "      <td>-0.231459</td>\n",
              "      <td>-0.214636</td>\n",
              "      <td>-0.201177</td>\n",
              "      <td>-0.194448</td>\n",
              "      <td>-0.182912</td>\n",
              "      <td>-0.164646</td>\n",
              "      <td>-0.146861</td>\n",
              "      <td>-0.135325</td>\n",
              "      <td>-0.129557</td>\n",
              "      <td>-0.120905</td>\n",
              "      <td>-0.129557</td>\n",
              "      <td>-0.148784</td>\n",
              "      <td>-0.165608</td>\n",
              "      <td>-0.181470</td>\n",
              "      <td>-0.172337</td>\n",
              "      <td>-0.145900</td>\n",
              "      <td>-0.143497</td>\n",
              "      <td>-0.133403</td>\n",
              "      <td>-0.126673</td>\n",
              "      <td>-0.128596</td>\n",
              "      <td>-0.130038</td>\n",
              "      <td>-0.112734</td>\n",
              "      <td>-0.101679</td>\n",
              "      <td>-0.106966</td>\n",
              "      <td>-0.084855</td>\n",
              "      <td>-0.062745</td>\n",
              "      <td>-0.063706</td>\n",
              "      <td>-0.049286</td>\n",
              "      <td>-0.065629</td>\n",
              "      <td>-0.060822</td>\n",
              "      <td>-0.057457</td>\n",
              "      <td>...</td>\n",
              "      <td>0.226617</td>\n",
              "      <td>0.219407</td>\n",
              "      <td>0.210755</td>\n",
              "      <td>0.191048</td>\n",
              "      <td>0.169418</td>\n",
              "      <td>0.135290</td>\n",
              "      <td>0.114141</td>\n",
              "      <td>0.103085</td>\n",
              "      <td>0.096356</td>\n",
              "      <td>0.093472</td>\n",
              "      <td>0.091549</td>\n",
              "      <td>0.094433</td>\n",
              "      <td>0.072323</td>\n",
              "      <td>0.042041</td>\n",
              "      <td>0.010797</td>\n",
              "      <td>-0.013236</td>\n",
              "      <td>-0.033424</td>\n",
              "      <td>-0.029579</td>\n",
              "      <td>-0.028617</td>\n",
              "      <td>-0.036789</td>\n",
              "      <td>-0.047363</td>\n",
              "      <td>-0.064187</td>\n",
              "      <td>-0.071877</td>\n",
              "      <td>-0.080049</td>\n",
              "      <td>-0.053131</td>\n",
              "      <td>-0.051689</td>\n",
              "      <td>-0.046402</td>\n",
              "      <td>-0.063225</td>\n",
              "      <td>-0.052170</td>\n",
              "      <td>-0.074281</td>\n",
              "      <td>-0.079087</td>\n",
              "      <td>-0.085817</td>\n",
              "      <td>-0.068993</td>\n",
              "      <td>-0.058899</td>\n",
              "      <td>-0.043999</td>\n",
              "      <td>-0.058419</td>\n",
              "      <td>-0.065629</td>\n",
              "      <td>-0.070916</td>\n",
              "      <td>-0.068513</td>\n",
              "      <td>-0.090143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116717</th>\n",
              "      <td>-0.065742</td>\n",
              "      <td>-0.082698</td>\n",
              "      <td>-0.086365</td>\n",
              "      <td>-0.053368</td>\n",
              "      <td>-0.023122</td>\n",
              "      <td>-0.024038</td>\n",
              "      <td>-0.046494</td>\n",
              "      <td>-0.133109</td>\n",
              "      <td>-0.211476</td>\n",
              "      <td>-0.300383</td>\n",
              "      <td>-0.332463</td>\n",
              "      <td>-0.329713</td>\n",
              "      <td>-0.355835</td>\n",
              "      <td>-0.354919</td>\n",
              "      <td>-0.328338</td>\n",
              "      <td>-0.288467</td>\n",
              "      <td>-0.260970</td>\n",
              "      <td>-0.271053</td>\n",
              "      <td>-0.271969</td>\n",
              "      <td>-0.232099</td>\n",
              "      <td>-0.191311</td>\n",
              "      <td>-0.132193</td>\n",
              "      <td>-0.048785</td>\n",
              "      <td>0.000709</td>\n",
              "      <td>0.043788</td>\n",
              "      <td>0.034164</td>\n",
              "      <td>0.035539</td>\n",
              "      <td>0.087325</td>\n",
              "      <td>0.130403</td>\n",
              "      <td>0.125821</td>\n",
              "      <td>0.083200</td>\n",
              "      <td>0.050204</td>\n",
              "      <td>0.046996</td>\n",
              "      <td>0.060744</td>\n",
              "      <td>0.028664</td>\n",
              "      <td>-0.039620</td>\n",
              "      <td>-0.069866</td>\n",
              "      <td>-0.056118</td>\n",
              "      <td>-0.013039</td>\n",
              "      <td>-0.011206</td>\n",
              "      <td>...</td>\n",
              "      <td>0.150110</td>\n",
              "      <td>0.161108</td>\n",
              "      <td>0.153776</td>\n",
              "      <td>0.141860</td>\n",
              "      <td>0.093282</td>\n",
              "      <td>0.067619</td>\n",
              "      <td>0.056620</td>\n",
              "      <td>0.041038</td>\n",
              "      <td>0.019041</td>\n",
              "      <td>0.071743</td>\n",
              "      <td>0.098782</td>\n",
              "      <td>0.080450</td>\n",
              "      <td>0.012625</td>\n",
              "      <td>0.031414</td>\n",
              "      <td>0.062577</td>\n",
              "      <td>0.058911</td>\n",
              "      <td>-0.007540</td>\n",
              "      <td>-0.025413</td>\n",
              "      <td>0.024998</td>\n",
              "      <td>0.069452</td>\n",
              "      <td>0.037830</td>\n",
              "      <td>-0.017164</td>\n",
              "      <td>-0.020830</td>\n",
              "      <td>-0.029537</td>\n",
              "      <td>-0.040078</td>\n",
              "      <td>-0.102863</td>\n",
              "      <td>-0.134026</td>\n",
              "      <td>-0.169772</td>\n",
              "      <td>-0.123027</td>\n",
              "      <td>-0.103321</td>\n",
              "      <td>-0.111570</td>\n",
              "      <td>-0.135401</td>\n",
              "      <td>-0.128985</td>\n",
              "      <td>-0.091864</td>\n",
              "      <td>-0.071700</td>\n",
              "      <td>-0.102404</td>\n",
              "      <td>-0.157398</td>\n",
              "      <td>-0.150524</td>\n",
              "      <td>-0.087281</td>\n",
              "      <td>-0.042828</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>116718 rows × 3000 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f68e7ad5-a2b3-4cd2-a4a3-926770a9ced6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f68e7ad5-a2b3-4cd2-a4a3-926770a9ced6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f68e7ad5-a2b3-4cd2-a4a3-926770a9ced6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0         1         2     ...      2997      2998      2999\n",
              "0       0.068014  0.082915  0.077628  ... -0.077147 -0.084838 -0.090125\n",
              "1       0.104729  0.054513 -0.020131  ... -0.171231 -0.149516 -0.121467\n",
              "2       0.002281 -0.031309 -0.007672  ...  0.072779  0.055362  0.029651\n",
              "3      -0.025235 -0.037732 -0.033406  ... -0.020428 -0.025235 -0.024754\n",
              "4       0.097914 -0.100520 -0.044574  ...  0.200190  0.246520  0.166535\n",
              "...          ...       ...       ...  ...       ...       ...       ...\n",
              "116713  0.032558  0.033944  0.046413  ... -0.028402  0.021475  0.028402\n",
              "116714  0.068695  0.059483  0.051071  ...  0.018626  0.005007  0.007010\n",
              "116715  0.013392  0.030717  0.029805  ...  0.041659  0.032996  0.024334\n",
              "116716 -0.057457 -0.065629 -0.101198  ... -0.070916 -0.068513 -0.090143\n",
              "116717 -0.065742 -0.082698 -0.086365  ... -0.150524 -0.087281 -0.042828\n",
              "\n",
              "[116718 rows x 3000 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_transfer=transfer_df[3000]"
      ],
      "metadata": {
        "id": "rntc1jv9gh-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_transfer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud4rIBkPgqcU",
        "outputId": "35f1f886-6c65-4046-831f-44280264f67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         4\n",
              "1         3\n",
              "2         2\n",
              "3         2\n",
              "4         0\n",
              "         ..\n",
              "116713    2\n",
              "116714    4\n",
              "116715    4\n",
              "116716    2\n",
              "116717    2\n",
              "Name: 3000, Length: 116718, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_transfer_set_rshp=np.array(x_transfer_set).reshape((116718,3000,1))"
      ],
      "metadata": {
        "id": "5qy1c-KdiUwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_transfer_set_rshp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_5oee6jiU0E",
        "outputId": "f898913c-e4b3-4d69-b2ea-2ee93f752f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.0680144 ],\n",
              "        [ 0.08291509],\n",
              "        [ 0.07762775],\n",
              "        ...,\n",
              "        [-0.07714708],\n",
              "        [-0.08483776],\n",
              "        [-0.09012509]],\n",
              "\n",
              "       [[ 0.1047289 ],\n",
              "        [ 0.05451331],\n",
              "        [-0.02013147],\n",
              "        ...,\n",
              "        [-0.17123062],\n",
              "        [-0.14951577],\n",
              "        [-0.12146743]],\n",
              "\n",
              "       [[ 0.00228081],\n",
              "        [-0.03130934],\n",
              "        [-0.00767183],\n",
              "        ...,\n",
              "        [ 0.07277867],\n",
              "        [ 0.05536155],\n",
              "        [ 0.02965057]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.01339153],\n",
              "        [ 0.03071675],\n",
              "        [ 0.0298049 ],\n",
              "        ...,\n",
              "        [ 0.041659  ],\n",
              "        [ 0.03299639],\n",
              "        [ 0.02433378]],\n",
              "\n",
              "       [[-0.0574574 ],\n",
              "        [-0.06562874],\n",
              "        [-0.10119811],\n",
              "        ...,\n",
              "        [-0.07091608],\n",
              "        [-0.06851275],\n",
              "        [-0.09014277]],\n",
              "\n",
              "       [[-0.06574184],\n",
              "        [-0.08269832],\n",
              "        [-0.08636458],\n",
              "        ...,\n",
              "        [-0.15052423],\n",
              "        [-0.08728115],\n",
              "        [-0.04282768]]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_transfer_=np_utils.to_categorical(y_transfer)"
      ],
      "metadata": {
        "id": "xLY0IMEM7G1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_transfer_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_gbs4NliU8O",
        "outputId": "e59b4996-4aaf-4d5e-d364-24518e0a94da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the teacher model wrt to the transfer set, majority voted labels"
      ],
      "metadata": {
        "id": "hxTtuzN4Ypbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_teacher_model_30_epochs = \"/gdrive/My Drive/physionet/ensemble/teacher_wts_30_epochs_50_subs.ckpt\""
      ],
      "metadata": {
        "id": "WrIIjHFEp2Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_teacher_model_30_epochs = \"/content/gdrive/My Drive/physionet/ensemble/teacher_wts_30_epochs_50_subs_trial_3.ckpt\""
      ],
      "metadata": {
        "id": "vQHCJVxo0m-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_teacher_model_30_epochs_dir = os.path.dirname(checkpoint_teacher_model_30_epochs)"
      ],
      "metadata": {
        "id": "v7xL4JG8qV9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp_callback_teacher_model_30_epochs = tensorflow.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_teacher_model_30_epochs,\n",
        "    monitor='accuracy', \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    mode = 'max',\n",
        "    period=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yELYDhWlqlXY",
        "outputId": "f0e46f84-8b53-4d8e-8d27-d0521642cdb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_30_epochs.fit(x_transfer_set_rshp, y_transfer_, epochs=30, callbacks=[cp_callback_teacher_model_30_epochs])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4Dz25DTq9b1",
        "outputId": "bd368f30-1813-4337-a45b-7e5efeecac47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "3648/3648 [==============================] - 46s 8ms/step - loss: 0.6881 - accuracy: 0.7223\n",
            "Epoch 2/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.4046 - accuracy: 0.8414\n",
            "Epoch 3/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.3315 - accuracy: 0.8688\n",
            "Epoch 4/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.2891 - accuracy: 0.8857\n",
            "Epoch 5/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.2562 - accuracy: 0.8991\n",
            "Epoch 6/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.2300 - accuracy: 0.9099\n",
            "Epoch 7/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.2134 - accuracy: 0.9153\n",
            "Epoch 8/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1986 - accuracy: 0.9214\n",
            "Epoch 9/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1903 - accuracy: 0.9248\n",
            "Epoch 10/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1808 - accuracy: 0.9282\n",
            "Epoch 11/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1724 - accuracy: 0.9307\n",
            "Epoch 12/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1654 - accuracy: 0.9341\n",
            "Epoch 13/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1604 - accuracy: 0.9356\n",
            "Epoch 14/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1537 - accuracy: 0.9391\n",
            "Epoch 15/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1510 - accuracy: 0.9406\n",
            "Epoch 16/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1439 - accuracy: 0.9431\n",
            "Epoch 17/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1429 - accuracy: 0.9436\n",
            "Epoch 18/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1378 - accuracy: 0.9455\n",
            "Epoch 19/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1338 - accuracy: 0.9473\n",
            "Epoch 20/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1294 - accuracy: 0.9488\n",
            "Epoch 21/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1253 - accuracy: 0.9505\n",
            "Epoch 22/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1234 - accuracy: 0.9515\n",
            "Epoch 23/30\n",
            "3648/3648 [==============================] - 28s 8ms/step - loss: 0.1209 - accuracy: 0.9529\n",
            "Epoch 24/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1178 - accuracy: 0.9538\n",
            "Epoch 25/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1158 - accuracy: 0.9547\n",
            "Epoch 26/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1133 - accuracy: 0.9556\n",
            "Epoch 27/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1106 - accuracy: 0.9567\n",
            "Epoch 28/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1085 - accuracy: 0.9574\n",
            "Epoch 29/30\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1058 - accuracy: 0.9593\n",
            "Epoch 30/30\n",
            "3646/3648 [============================>.] - ETA: 0s - loss: 0.1037 - accuracy: 0.9599\n",
            "Epoch 30: saving model to /content/gdrive/My Drive/physionet/ensemble/teacher_wts_30_epochs_50_subs_trial_3.ckpt\n",
            "3648/3648 [==============================] - 27s 7ms/step - loss: 0.1037 - accuracy: 0.9599\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29bc3426d0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latest_teacher_30_epochs=tensorflow.train.latest_checkpoint(checkpoint_teacher_model_30_epochs_dir)"
      ],
      "metadata": {
        "id": "2owc5vxHsmk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_pt_path=\"/content/gdrive/My Drive/physionet/ensemble/teacher_wts_30_epochs_50_subs_trial_3.ckpt\""
      ],
      "metadata": {
        "id": "qmP1wipj-s_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(latest_teacher_30_epochs)\n",
        "print(check_pt_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJrWrXp9s2DO",
        "outputId": "4a48e645-c19b-4d0a-c636-98ddecaf6f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/physionet/ensemble/teacher_wts_30_epochs_50_subs_trial_3.ckpt\n",
            "/content/gdrive/My Drive/physionet/ensemble/teacher_wts_30_epochs_50_subs_trial_3.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_teacher_model_30_epochs_original = teacher_30_epochs.evaluate(pp_X_sub_482, y_sub_482_) #just change the data to test data, the accuracy will change, this was the previous output with old data (complete sub data and not just test data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk6aje2_s2Na",
        "outputId": "0a81a1a8-3d27-425e-cb25-ca3d5f5bdb31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96/96 [==============================] - 2s 6ms/step - loss: 0.8174 - accuracy: 0.8521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_30_epochs=model_b(verbose=VBS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uebr87kLB_jV",
        "outputId": "52837a4e-c75f-4345-bdc9-480be3aafee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inLayer (InputLayer)           [(None, 3000, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " fConv1 (Conv1D)                (None, 500, 64)      3264        ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " cConv1 (Conv1D)                (None, 60, 32)       12832       ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " fMaxP1 (MaxPooling1D)          (None, 62, 64)       0           ['fConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP1 (MaxPooling1D)          (None, 15, 32)       0           ['cConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " fDrop1 (Dropout)               (None, 62, 64)       0           ['fMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " cDrop1 (Dropout)               (None, 15, 32)       0           ['cMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv2 (Conv1D)                (None, 62, 128)      65664       ['fDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv2 (Conv1D)                (None, 15, 128)      24704       ['cDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv3 (Conv1D)                (None, 62, 128)      131200      ['fConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv3 (Conv1D)                (None, 15, 128)      98432       ['cConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv4 (Conv1D)                (None, 62, 128)      131200      ['fConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv4 (Conv1D)                (None, 15, 128)      98432       ['cConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " fMaxP2 (MaxPooling1D)          (None, 15, 128)      0           ['fConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP2 (MaxPooling1D)          (None, 7, 128)       0           ['cConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " fFlat1 (Flatten)               (None, 1920)         0           ['fMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " cFlat1 (Flatten)               (None, 896)          0           ['cMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " merge_1 (Concatenate)          (None, 2816)         0           ['fFlat1[0][0]',                 \n",
            "                                                                  'cFlat1[0][0]']                 \n",
            "                                                                                                  \n",
            " mDrop1 (Dropout)               (None, 2816)         0           ['merge_1[0][0]']                \n",
            "                                                                                                  \n",
            " reshape1 (Reshape)             (None, 1, 2816)      0           ['mDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, 1, 64)        737536      ['reshape1[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, 64)           33024       ['lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " outLayer (Dense)               (None, 5)            325         ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,336,613\n",
            "Trainable params: 1,336,613\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_30_epochs.load_weights(check_pt_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ORbxXiOs2Qd",
        "outputId": "dafdee6d-da35-4556-8a23-89ae1b9327fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f2986efce10>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_30_epochs.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mHKo1CuqtDPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_test_data=pd.read_csv('/content/gdrive/My Drive/physionet/ensemble/50_subs/x_test_sub.csv',header=None)"
      ],
      "metadata": {
        "id": "a1yV3a6lIgAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_dt=sub_test_data.drop([3000],axis=1)\n",
        "y_test_dt=sub_test_data[3000]"
      ],
      "metadata": {
        "id": "7UdabrDyIySA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_dt.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpzU4hAkBwYd",
        "outputId": "8e1374fd-b109-4a83-8af8-3a6a4fab4db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(494, 3000)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_dt_=np_utils.to_categorical(y_test_dt)"
      ],
      "metadata": {
        "id": "KCS0N2wyI0fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_dt_rshp=np.array(x_test_dt).reshape(494,3000,1)"
      ],
      "metadata": {
        "id": "uLo4G-2UI6yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_teacher_model_30_epochs_wts_loaded = teacher_30_epochs.evaluate(x_test_dt_rshp, y_test_dt_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33ZhOvWrtDS0",
        "outputId": "b750ac40-d176-4e24-9494-0755fce47f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 4ms/step - loss: 1.4282 - accuracy: 0.7368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## student model tuning wrt the transfer set, original labels"
      ],
      "metadata": {
        "id": "nG40bVaCLwp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "-CU3aTShMhs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_contrib.layers import CRF"
      ],
      "metadata": {
        "id": "Y_tqmZ8i6sIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = tf.keras.Sequential()\n",
        "  \n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units1 = hp.Int('units1', min_value=18, max_value=512, step=18)\n",
        "  hp_units2 = hp.Int('units2', min_value=15, max_value=512, step=5)\n",
        "  hp_units3 = hp.Int('units3', min_value=10, max_value=512, step=5)\n",
        "  model.add(Dense(units=hp_units1, input_dim=18, activation=hp.Choice('act1', values=['relu','sigmoid','tanh'])))\n",
        "  model.add(tf.keras.layers.Dense(units=hp_units2, activation=hp.Choice('act2', values=['relu','sigmoid','tanh'])))\n",
        "  model.add(tf.keras.layers.Dense(units=hp_units3, activation=hp.Choice('act3', values=['sigmoid','relu','tanh'])))\n",
        "  model.add(Dense(5, activation='softmax'))\n",
        "  hp_learning_rate_seq = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "  optimizer_seq = Adam(learning_rate=hp_learning_rate_seq)\n",
        "  model.compile(optimizer=optimizer_seq, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "X6CYHogw5JTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q -U keras-tuner"
      ],
      "metadata": {
        "id": "rynUpXNaB1uG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "-AQjREK5B61i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='accuracy',\n",
        "    max_epochs=30,\n",
        "    hyperband_iterations=3, seed=100)"
      ],
      "metadata": {
        "id": "3285cmT3PhSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14UVXJDnhf_n",
        "outputId": "925d0571-e5d0-48ba-9294-653aa5c070ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 7\n",
            "units1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 18, 'max_value': 512, 'step': 18, 'sampling': None}\n",
            "units2 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 15, 'max_value': 512, 'step': 5, 'sampling': None}\n",
            "units3 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 512, 'step': 5, 'sampling': None}\n",
            "act1 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
            "act2 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid', 'tanh'], 'ordered': False}\n",
            "act3 (Choice)\n",
            "{'default': 'sigmoid', 'conditions': [], 'values': ['sigmoid', 'relu', 'tanh'], 'ordered': False}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(x_transfer_set_rshp, y_transfer_set_)"
      ],
      "metadata": {
        "id": "XcKscYsomkyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b38352c-e0a5-46ae-d0d2-08d26f8bab02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 270 Complete [00h 00m 59s]\n",
            "accuracy: 0.4689939320087433\n",
            "\n",
            "Best accuracy So Far: 0.5725643038749695\n",
            "Total elapsed time: 01h 00m 49s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()"
      ],
      "metadata": {
        "id": "c28Ygy_anLwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e37446-6447-4e08-f893-901cc46c88ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units1: 36\n",
            "units2: 155\n",
            "units3: 430\n",
            "act1: relu\n",
            "act2: relu\n",
            "act3: relu\n",
            "learning_rate: 0.001\n",
            "tuner/epochs: 30\n",
            "tuner/initial_epoch: 10\n",
            "tuner/bracket: 3\n",
            "tuner/round: 3\n",
            "tuner/trial_id: d9108e42f21af93f7b1ed22095ecf641\n",
            "Score: 0.5725643038749695\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units1: 450\n",
            "units2: 345\n",
            "units3: 335\n",
            "act1: relu\n",
            "act2: relu\n",
            "act3: relu\n",
            "learning_rate: 0.001\n",
            "tuner/epochs: 30\n",
            "tuner/initial_epoch: 10\n",
            "tuner/bracket: 2\n",
            "tuner/round: 2\n",
            "tuner/trial_id: f3e9c6ecbf6b8163390f1f2756d0270c\n",
            "Score: 0.5688782930374146\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units1: 90\n",
            "units2: 100\n",
            "units3: 420\n",
            "act1: relu\n",
            "act2: relu\n",
            "act3: tanh\n",
            "learning_rate: 0.001\n",
            "tuner/epochs: 30\n",
            "tuner/initial_epoch: 10\n",
            "tuner/bracket: 1\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 9dffb785d2df5f174563f6a88bd5849a\n",
            "Score: 0.5648308992385864\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units1: 306\n",
            "units2: 165\n",
            "units3: 210\n",
            "act1: relu\n",
            "act2: relu\n",
            "act3: relu\n",
            "learning_rate: 0.001\n",
            "tuner/epochs: 30\n",
            "tuner/initial_epoch: 10\n",
            "tuner/bracket: 2\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 92e6ff0c4df134aba91d6631a7c114c1\n",
            "Score: 0.5647585988044739\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units1: 180\n",
            "units2: 370\n",
            "units3: 25\n",
            "act1: tanh\n",
            "act2: relu\n",
            "act3: relu\n",
            "learning_rate: 0.001\n",
            "tuner/epochs: 30\n",
            "tuner/initial_epoch: 10\n",
            "tuner/bracket: 2\n",
            "tuner/round: 2\n",
            "tuner/trial_id: d139a856935d337cd49c992c504640d2\n",
            "Score: 0.5644695162773132\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units1: 486\n",
            "units2: 390\n",
            "units3: 70\n",
            "act1: relu\n",
            "act2: relu\n",
            "act3: tanh\n",
            "learning_rate: 0.001\n",
            "tuner/epochs: 30\n",
            "tuner/initial_epoch: 10\n",
            "tuner/bracket: 3\n",
            "tuner/round: 3\n",
            "tuner/trial_id: 046262e39aba5f8278d37152c5ff41f6\n",
            "Score: 0.5641803741455078\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units1: 216\n",
            "units2: 90\n",
            "units3: 270\n",
            "act1: relu\n",
            "act2: relu\n",
            "act3: relu\n",
            "learning_rate: 0.001\n",
            "tuner/epochs: 30\n",
            "tuner/initial_epoch: 10\n",
            "tuner/bracket: 3\n",
            "tuner/round: 3\n",
            "tuner/trial_id: 457e8983a0fc1b0115e39941ebdf17a5\n",
            "Score: 0.563529908657074\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units1: 54\n",
            "units2: 100\n",
            "units3: 380\n",
            "act1: tanh\n",
            "act2: relu\n",
            "act3: tanh\n",
            "learning_rate: 0.001\n",
            "tuner/epochs: 30\n",
            "tuner/initial_epoch: 10\n",
            "tuner/bracket: 3\n",
            "tuner/round: 3\n",
            "tuner/trial_id: 9dc03e33988116dce2567436f7dae898\n",
            "Score: 0.5604943633079529\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units1: 144\n",
            "units2: 45\n",
            "units3: 295\n",
            "act1: tanh\n",
            "act2: relu\n",
            "act3: relu\n",
            "learning_rate: 0.001\n",
            "tuner/epochs: 30\n",
            "tuner/initial_epoch: 10\n",
            "tuner/bracket: 2\n",
            "tuner/round: 2\n",
            "tuner/trial_id: acb26534ce2c7a5a34c6ed2406ca7e0d\n",
            "Score: 0.5587597489356995\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units1: 144\n",
            "units2: 145\n",
            "units3: 375\n",
            "act1: tanh\n",
            "act2: tanh\n",
            "act3: relu\n",
            "learning_rate: 0.001\n",
            "tuner/epochs: 30\n",
            "tuner/initial_epoch: 10\n",
            "tuner/bracket: 3\n",
            "tuner/round: 3\n",
            "tuner/trial_id: b0f3387f9af88fc1e969dfeefdc99a3b\n",
            "Score: 0.5576756000518799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models(1)[0]"
      ],
      "metadata": {
        "id": "5obpmSfwcv7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hchsKahzc47P",
        "outputId": "d1180421-7c17-4678-889f-109a4e13c1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': [{'class_name': 'InputLayer',\n",
              "   'config': {'batch_input_shape': (None, 18),\n",
              "    'dtype': 'float32',\n",
              "    'name': 'dense_input',\n",
              "    'ragged': False,\n",
              "    'sparse': False}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'batch_input_shape': (None, 18),\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense',\n",
              "    'trainable': True,\n",
              "    'units': 36,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_1',\n",
              "    'trainable': True,\n",
              "    'units': 155,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_2',\n",
              "    'trainable': True,\n",
              "    'units': 430,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'softmax',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_3',\n",
              "    'trainable': True,\n",
              "    'units': 5,\n",
              "    'use_bias': True}}],\n",
              " 'name': 'sequential'}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJSoJTwodDEr",
        "outputId": "45565fa8-59e7-4b40-c73d-928767678077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 36)                684       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 155)               5735      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 430)               67080     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 2155      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 75,654\n",
            "Trainable params: 75,654\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_learning_rate_student=0.001\n",
        "optimizer_student = Adam(learning_rate=best_learning_rate_student)"
      ],
      "metadata": {
        "id": "yjAT9QIsDP8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "json_config_best_model_student_50_subs = best_model.to_json()\n",
        "with open(\"/content/gdrive/My Drive/physionet/ensemble/json_config_best_model_student_50_subs.json\",\"w\") as file:\n",
        "  file.write(json_config_best_model_student_50_subs)\n",
        "#best_model.save(\"/content/gdrive/My Drive/dt_shuf1/s828/best_model_s828\")"
      ],
      "metadata": {
        "id": "IfdQpimbdWU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "30 epochs"
      ],
      "metadata": {
        "id": "G9f4pCk6IGP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "with open(\"/content/gdrive/My Drive/physionet/ensemble/json_config_best_model_student_50_subs.json\",\"r\") as file:\n",
        "  read_model=file.read()\n",
        "\n",
        "\n",
        "student_30_epochs=model_from_json(read_model)"
      ],
      "metadata": {
        "id": "kdr1MPSidvGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_30_epochs.compile(optimizer=optimizer_student, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "eaI7qKbBCoDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_student_model_30_epochs = \"/content/gdrive/My Drive/physionet/ensemble/student/student_30_epochs/weights-30_epochs.ckpt\""
      ],
      "metadata": {
        "id": "zIdPkMiwDfrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_student_model_30_epochs_dir = os.path.dirname(checkpoint_student_model_30_epochs)"
      ],
      "metadata": {
        "id": "cUxnfAneDfwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp_callback_student_model_30_epochs = tensorflow.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_student_model_30_epochs,\n",
        "    monitor='accuracy', \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    mode = 'max',\n",
        "    period=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlbRPQqeDf1t",
        "outputId": "09adbde1-c7bf-4ac2-eb3d-7f23eaa513b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_30_epochs.fit(x_transfer_set_rshp, y_transfer_set_, epochs=30, callbacks=[cp_callback_student_model_30_epochs])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlV6f0dYDf7y",
        "outputId": "d253b905-0f02-4eb7-f7a9-8905bdabf541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 1.0323 - accuracy: 0.5906\n",
            "Epoch 2/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.9359 - accuracy: 0.6174\n",
            "Epoch 3/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.9072 - accuracy: 0.6328\n",
            "Epoch 4/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8857 - accuracy: 0.6513\n",
            "Epoch 5/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.8712 - accuracy: 0.6610\n",
            "Epoch 6/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.8547 - accuracy: 0.6654\n",
            "Epoch 7/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.8422 - accuracy: 0.6699\n",
            "Epoch 8/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.8357 - accuracy: 0.6746\n",
            "Epoch 9/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8205 - accuracy: 0.6800\n",
            "Epoch 10/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8162 - accuracy: 0.6856\n",
            "Epoch 11/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8045 - accuracy: 0.6883\n",
            "Epoch 12/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8009 - accuracy: 0.6889\n",
            "Epoch 13/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7934 - accuracy: 0.6946\n",
            "Epoch 14/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7904 - accuracy: 0.6927\n",
            "Epoch 15/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7888 - accuracy: 0.6941\n",
            "Epoch 16/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7775 - accuracy: 0.6996\n",
            "Epoch 17/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7733 - accuracy: 0.7004\n",
            "Epoch 18/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7685 - accuracy: 0.7050\n",
            "Epoch 19/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7692 - accuracy: 0.6972\n",
            "Epoch 20/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7606 - accuracy: 0.7067\n",
            "Epoch 21/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7525 - accuracy: 0.7083\n",
            "Epoch 22/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7507 - accuracy: 0.7095\n",
            "Epoch 23/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7527 - accuracy: 0.7098\n",
            "Epoch 24/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7517 - accuracy: 0.7103\n",
            "Epoch 25/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7410 - accuracy: 0.7152\n",
            "Epoch 26/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7411 - accuracy: 0.7128\n",
            "Epoch 27/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7385 - accuracy: 0.7130\n",
            "Epoch 28/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7338 - accuracy: 0.7146\n",
            "Epoch 29/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7335 - accuracy: 0.7136\n",
            "Epoch 30/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7254 - accuracy: 0.7197\n",
            "Epoch 31/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7201 - accuracy: 0.7202\n",
            "Epoch 32/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7233 - accuracy: 0.7207\n",
            "Epoch 33/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7194 - accuracy: 0.7234\n",
            "Epoch 34/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7197 - accuracy: 0.7186\n",
            "Epoch 35/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7128 - accuracy: 0.7215\n",
            "Epoch 36/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7120 - accuracy: 0.7228\n",
            "Epoch 37/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7056 - accuracy: 0.7251\n",
            "Epoch 38/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7034 - accuracy: 0.7263\n",
            "Epoch 39/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7019 - accuracy: 0.7255\n",
            "Epoch 40/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6966 - accuracy: 0.7286\n",
            "Epoch 41/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6934 - accuracy: 0.7280\n",
            "Epoch 42/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6944 - accuracy: 0.7319\n",
            "Epoch 43/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6886 - accuracy: 0.7328\n",
            "Epoch 44/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6908 - accuracy: 0.7326\n",
            "Epoch 45/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6841 - accuracy: 0.7346\n",
            "Epoch 46/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6806 - accuracy: 0.7374\n",
            "Epoch 47/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6851 - accuracy: 0.7307\n",
            "Epoch 48/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6793 - accuracy: 0.7353\n",
            "Epoch 49/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6808 - accuracy: 0.7325\n",
            "Epoch 50/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6736 - accuracy: 0.7368\n",
            "Epoch 51/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6784 - accuracy: 0.7344\n",
            "Epoch 52/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6667 - accuracy: 0.7368\n",
            "Epoch 53/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6608 - accuracy: 0.7427\n",
            "Epoch 54/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6612 - accuracy: 0.7430\n",
            "Epoch 55/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6645 - accuracy: 0.7397\n",
            "Epoch 56/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6591 - accuracy: 0.7416\n",
            "Epoch 57/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6546 - accuracy: 0.7469\n",
            "Epoch 58/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6590 - accuracy: 0.7447\n",
            "Epoch 59/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6566 - accuracy: 0.7477\n",
            "Epoch 60/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6494 - accuracy: 0.7465\n",
            "Epoch 61/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6431 - accuracy: 0.7519\n",
            "Epoch 62/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6440 - accuracy: 0.7472\n",
            "Epoch 63/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6417 - accuracy: 0.7483\n",
            "Epoch 64/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6433 - accuracy: 0.7465\n",
            "Epoch 65/100\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6410 - accuracy: 0.7507\n",
            "Epoch 66/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6361 - accuracy: 0.7511\n",
            "Epoch 67/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6334 - accuracy: 0.7514\n",
            "Epoch 68/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6299 - accuracy: 0.7551\n",
            "Epoch 69/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6327 - accuracy: 0.7542\n",
            "Epoch 70/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6229 - accuracy: 0.7593\n",
            "Epoch 71/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6232 - accuracy: 0.7558\n",
            "Epoch 72/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6214 - accuracy: 0.7572\n",
            "Epoch 73/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6242 - accuracy: 0.7568\n",
            "Epoch 74/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6122 - accuracy: 0.7620\n",
            "Epoch 75/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6151 - accuracy: 0.7580\n",
            "Epoch 76/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6128 - accuracy: 0.7638\n",
            "Epoch 77/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6142 - accuracy: 0.7593\n",
            "Epoch 78/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6021 - accuracy: 0.7679\n",
            "Epoch 79/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6018 - accuracy: 0.7660\n",
            "Epoch 80/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6094 - accuracy: 0.7631\n",
            "Epoch 81/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6061 - accuracy: 0.7632\n",
            "Epoch 82/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6000 - accuracy: 0.7698\n",
            "Epoch 83/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5921 - accuracy: 0.7728\n",
            "Epoch 84/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5945 - accuracy: 0.7678\n",
            "Epoch 85/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5916 - accuracy: 0.7725\n",
            "Epoch 86/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5929 - accuracy: 0.7699\n",
            "Epoch 87/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5894 - accuracy: 0.7699\n",
            "Epoch 88/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5856 - accuracy: 0.7713\n",
            "Epoch 89/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5887 - accuracy: 0.7707\n",
            "Epoch 90/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5847 - accuracy: 0.7725\n",
            "Epoch 91/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5809 - accuracy: 0.7702\n",
            "Epoch 92/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5775 - accuracy: 0.7777\n",
            "Epoch 93/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5761 - accuracy: 0.7801\n",
            "Epoch 94/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5784 - accuracy: 0.7762\n",
            "Epoch 95/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5725 - accuracy: 0.7781\n",
            "Epoch 96/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5725 - accuracy: 0.7772\n",
            "Epoch 97/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5678 - accuracy: 0.7808\n",
            "Epoch 98/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5706 - accuracy: 0.7812\n",
            "Epoch 99/100\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5635 - accuracy: 0.7817\n",
            "Epoch 100/100\n",
            "425/433 [============================>.] - ETA: 0s - loss: 0.5667 - accuracy: 0.7772\n",
            "Epoch 00100: saving model to /content/gdrive/My Drive/ensemble/s828/student/student_100_epochs/weights-100-0.777.ckpt\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5669 - accuracy: 0.7775\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7ba21b4c50>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latest_student_30_epochs=tensorflow.train.latest_checkpoint(checkpoint_student_model_30_epochs_dir)"
      ],
      "metadata": {
        "id": "KujN_IDFDgA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(latest_student_30_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rosxqOS0Ejc5",
        "outputId": "0672f27e-aaf7-4985-908f-d63b4483da0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/ensemble/s828/student/student_100_epochs/weights-100-0.777.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_30_epochs.load_weights(latest_student_30_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ab4Ut_5EjjK",
        "outputId": "892dfb0e-67ca-4f09-9d61-c75acec28fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7ba2205c90>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_30_epochs.compile(optimizer=optimizer_student, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Fh9I51NrEr9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_student_model_30_epochs = student_30_epochs.evaluate(pp_X_sub_482, y_sub_482_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT9B02bcEsC5",
        "outputId": "a9ee0c10-215e-4fd9-cc6c-5621494b1768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 4ms/step - loss: 3.5819 - accuracy: 0.6104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "200 epochs"
      ],
      "metadata": {
        "id": "Aw4cPA0QIJsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "with open(\"/content/gdrive/My Drive/physionet/ensemble/json_config_best_model_student_50_subs.json\",\"r\") as file:\n",
        "  read_model=file.read()\n",
        "\n",
        "\n",
        "student_60_epochs=model_from_json(read_model)"
      ],
      "metadata": {
        "id": "DUY0s-nPEsIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_60_epochs.compile(optimizer=optimizer_student, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YmPtrWKZEsOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_student_model_60_epochs = \"/content/gdrive/My Drive/physionet/ensemble/student/student_60_epochs/weights-60_epochs.ckpt\""
      ],
      "metadata": {
        "id": "E7zEvDt-Infj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_student_model_60_epochs_dir = os.path.dirname(checkpoint_student_model_60_epochs)"
      ],
      "metadata": {
        "id": "xbkd8nUnItj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp_callback_student_model_60_epochs = tensorflow.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_student_model_60_epochs,\n",
        "    monitor='accuracy', \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    mode = 'max',\n",
        "    period=60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqZ4d4jFI0V5",
        "outputId": "96618f0e-433c-4444-c31d-e6398d0fc189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_60_epochs.fit(x_transfer_set_rshp, y_transfer_set_, epochs=60, callbacks=[cp_callback_student_model_60_epochs])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQWaXXy2I7Mx",
        "outputId": "3fd4ef62-7d0f-46c0-c5bf-4b5b02f396c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 1.0281 - accuracy: 0.5854\n",
            "Epoch 2/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.9549 - accuracy: 0.6023\n",
            "Epoch 3/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.9207 - accuracy: 0.6233\n",
            "Epoch 4/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.9007 - accuracy: 0.6393\n",
            "Epoch 5/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8883 - accuracy: 0.6492\n",
            "Epoch 6/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8721 - accuracy: 0.6588\n",
            "Epoch 7/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.8622 - accuracy: 0.6648\n",
            "Epoch 8/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8535 - accuracy: 0.6644\n",
            "Epoch 9/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.8444 - accuracy: 0.6684\n",
            "Epoch 10/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.8334 - accuracy: 0.6747\n",
            "Epoch 11/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8322 - accuracy: 0.6757\n",
            "Epoch 12/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.8255 - accuracy: 0.6774\n",
            "Epoch 13/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.8189 - accuracy: 0.6817\n",
            "Epoch 14/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8116 - accuracy: 0.6831\n",
            "Epoch 15/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.8070 - accuracy: 0.6864\n",
            "Epoch 16/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8082 - accuracy: 0.6847\n",
            "Epoch 17/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8015 - accuracy: 0.6886\n",
            "Epoch 18/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7926 - accuracy: 0.6942\n",
            "Epoch 19/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7908 - accuracy: 0.6928\n",
            "Epoch 20/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7871 - accuracy: 0.6937\n",
            "Epoch 21/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7771 - accuracy: 0.6997\n",
            "Epoch 22/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7802 - accuracy: 0.6961\n",
            "Epoch 23/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7777 - accuracy: 0.6979\n",
            "Epoch 24/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7769 - accuracy: 0.6966\n",
            "Epoch 25/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7711 - accuracy: 0.7038\n",
            "Epoch 26/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7677 - accuracy: 0.7054\n",
            "Epoch 27/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7625 - accuracy: 0.7029\n",
            "Epoch 28/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7597 - accuracy: 0.7032\n",
            "Epoch 29/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7583 - accuracy: 0.7045\n",
            "Epoch 30/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7547 - accuracy: 0.7065\n",
            "Epoch 31/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7533 - accuracy: 0.7087\n",
            "Epoch 32/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7475 - accuracy: 0.7074\n",
            "Epoch 33/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7475 - accuracy: 0.7084\n",
            "Epoch 34/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7410 - accuracy: 0.7089\n",
            "Epoch 35/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7475 - accuracy: 0.7071\n",
            "Epoch 36/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7388 - accuracy: 0.7127\n",
            "Epoch 37/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7399 - accuracy: 0.7114\n",
            "Epoch 38/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7396 - accuracy: 0.7089\n",
            "Epoch 39/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7328 - accuracy: 0.7138\n",
            "Epoch 40/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7321 - accuracy: 0.7131\n",
            "Epoch 41/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7277 - accuracy: 0.7163\n",
            "Epoch 42/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7267 - accuracy: 0.7201\n",
            "Epoch 43/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7249 - accuracy: 0.7178\n",
            "Epoch 44/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7230 - accuracy: 0.7192\n",
            "Epoch 45/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7202 - accuracy: 0.7205\n",
            "Epoch 46/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7198 - accuracy: 0.7198\n",
            "Epoch 47/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7193 - accuracy: 0.7204\n",
            "Epoch 48/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7165 - accuracy: 0.7196\n",
            "Epoch 49/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7114 - accuracy: 0.7248\n",
            "Epoch 50/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7071 - accuracy: 0.7248\n",
            "Epoch 51/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7030 - accuracy: 0.7266\n",
            "Epoch 52/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7019 - accuracy: 0.7265\n",
            "Epoch 53/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7006 - accuracy: 0.7291\n",
            "Epoch 54/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7072 - accuracy: 0.7206\n",
            "Epoch 55/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6985 - accuracy: 0.7288\n",
            "Epoch 56/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7001 - accuracy: 0.7247\n",
            "Epoch 57/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6929 - accuracy: 0.7296\n",
            "Epoch 58/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6916 - accuracy: 0.7306\n",
            "Epoch 59/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6921 - accuracy: 0.7303\n",
            "Epoch 60/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6843 - accuracy: 0.7342\n",
            "Epoch 61/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6857 - accuracy: 0.7346\n",
            "Epoch 62/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6850 - accuracy: 0.7336\n",
            "Epoch 63/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6856 - accuracy: 0.7333\n",
            "Epoch 64/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6801 - accuracy: 0.7358\n",
            "Epoch 65/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6778 - accuracy: 0.7379\n",
            "Epoch 66/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6841 - accuracy: 0.7321\n",
            "Epoch 67/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6748 - accuracy: 0.7379\n",
            "Epoch 68/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6747 - accuracy: 0.7403\n",
            "Epoch 69/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6690 - accuracy: 0.7389\n",
            "Epoch 70/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6714 - accuracy: 0.7379\n",
            "Epoch 71/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6685 - accuracy: 0.7420\n",
            "Epoch 72/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6686 - accuracy: 0.7391\n",
            "Epoch 73/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6606 - accuracy: 0.7422\n",
            "Epoch 74/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6647 - accuracy: 0.7428\n",
            "Epoch 75/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6616 - accuracy: 0.7422\n",
            "Epoch 76/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6564 - accuracy: 0.7476\n",
            "Epoch 77/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6518 - accuracy: 0.7449\n",
            "Epoch 78/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6555 - accuracy: 0.7446\n",
            "Epoch 79/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6554 - accuracy: 0.7470\n",
            "Epoch 80/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6542 - accuracy: 0.7467\n",
            "Epoch 81/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6493 - accuracy: 0.7495\n",
            "Epoch 82/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6493 - accuracy: 0.7488\n",
            "Epoch 83/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6477 - accuracy: 0.7487\n",
            "Epoch 84/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6463 - accuracy: 0.7486\n",
            "Epoch 85/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6485 - accuracy: 0.7499\n",
            "Epoch 86/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6434 - accuracy: 0.7497\n",
            "Epoch 87/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6419 - accuracy: 0.7496\n",
            "Epoch 88/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6370 - accuracy: 0.7504\n",
            "Epoch 89/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6354 - accuracy: 0.7544\n",
            "Epoch 90/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6373 - accuracy: 0.7547\n",
            "Epoch 91/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6359 - accuracy: 0.7521\n",
            "Epoch 92/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6333 - accuracy: 0.7531\n",
            "Epoch 93/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6289 - accuracy: 0.7564\n",
            "Epoch 94/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6277 - accuracy: 0.7578\n",
            "Epoch 95/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6266 - accuracy: 0.7537\n",
            "Epoch 96/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6278 - accuracy: 0.7561\n",
            "Epoch 97/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6236 - accuracy: 0.7573\n",
            "Epoch 98/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6254 - accuracy: 0.7563\n",
            "Epoch 99/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6243 - accuracy: 0.7565\n",
            "Epoch 100/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6167 - accuracy: 0.7625\n",
            "Epoch 101/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6196 - accuracy: 0.7598\n",
            "Epoch 102/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6173 - accuracy: 0.7599\n",
            "Epoch 103/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6228 - accuracy: 0.7573\n",
            "Epoch 104/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6118 - accuracy: 0.7635\n",
            "Epoch 105/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6152 - accuracy: 0.7600\n",
            "Epoch 106/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6157 - accuracy: 0.7585\n",
            "Epoch 107/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6141 - accuracy: 0.7614\n",
            "Epoch 108/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6066 - accuracy: 0.7663\n",
            "Epoch 109/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6059 - accuracy: 0.7646\n",
            "Epoch 110/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6077 - accuracy: 0.7621\n",
            "Epoch 111/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6057 - accuracy: 0.7639\n",
            "Epoch 112/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6059 - accuracy: 0.7631\n",
            "Epoch 113/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6038 - accuracy: 0.7643\n",
            "Epoch 114/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6082 - accuracy: 0.7634\n",
            "Epoch 115/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5979 - accuracy: 0.7683\n",
            "Epoch 116/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6032 - accuracy: 0.7654\n",
            "Epoch 117/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5970 - accuracy: 0.7679\n",
            "Epoch 118/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5973 - accuracy: 0.7672\n",
            "Epoch 119/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5939 - accuracy: 0.7671\n",
            "Epoch 120/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5922 - accuracy: 0.7723\n",
            "Epoch 121/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5887 - accuracy: 0.7734\n",
            "Epoch 122/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5903 - accuracy: 0.7714\n",
            "Epoch 123/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5882 - accuracy: 0.7702\n",
            "Epoch 124/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5885 - accuracy: 0.7702\n",
            "Epoch 125/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5847 - accuracy: 0.7731\n",
            "Epoch 126/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5814 - accuracy: 0.7741\n",
            "Epoch 127/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5819 - accuracy: 0.7752\n",
            "Epoch 128/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5776 - accuracy: 0.7780\n",
            "Epoch 129/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5825 - accuracy: 0.7730\n",
            "Epoch 130/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5757 - accuracy: 0.7757\n",
            "Epoch 131/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5818 - accuracy: 0.7750\n",
            "Epoch 132/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5759 - accuracy: 0.7752\n",
            "Epoch 133/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5753 - accuracy: 0.7736\n",
            "Epoch 134/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5784 - accuracy: 0.7720\n",
            "Epoch 135/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5750 - accuracy: 0.7778\n",
            "Epoch 136/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5773 - accuracy: 0.7745\n",
            "Epoch 137/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5712 - accuracy: 0.7815\n",
            "Epoch 138/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5652 - accuracy: 0.7796\n",
            "Epoch 139/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5706 - accuracy: 0.7769\n",
            "Epoch 140/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5704 - accuracy: 0.7800\n",
            "Epoch 141/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5619 - accuracy: 0.7831\n",
            "Epoch 142/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5688 - accuracy: 0.7775\n",
            "Epoch 143/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5664 - accuracy: 0.7812\n",
            "Epoch 144/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5650 - accuracy: 0.7776\n",
            "Epoch 145/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5609 - accuracy: 0.7813\n",
            "Epoch 146/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5577 - accuracy: 0.7835\n",
            "Epoch 147/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5581 - accuracy: 0.7808\n",
            "Epoch 148/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5596 - accuracy: 0.7816\n",
            "Epoch 149/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5530 - accuracy: 0.7855\n",
            "Epoch 150/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5554 - accuracy: 0.7835\n",
            "Epoch 151/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5545 - accuracy: 0.7821\n",
            "Epoch 152/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5530 - accuracy: 0.7838\n",
            "Epoch 153/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5481 - accuracy: 0.7853\n",
            "Epoch 154/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5486 - accuracy: 0.7851\n",
            "Epoch 155/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5503 - accuracy: 0.7854\n",
            "Epoch 156/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5490 - accuracy: 0.7894\n",
            "Epoch 157/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5474 - accuracy: 0.7854\n",
            "Epoch 158/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5427 - accuracy: 0.7892\n",
            "Epoch 159/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5411 - accuracy: 0.7903\n",
            "Epoch 160/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5423 - accuracy: 0.7906\n",
            "Epoch 161/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5391 - accuracy: 0.7916\n",
            "Epoch 162/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5385 - accuracy: 0.7919\n",
            "Epoch 163/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5404 - accuracy: 0.7876\n",
            "Epoch 164/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5483 - accuracy: 0.7861\n",
            "Epoch 165/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5367 - accuracy: 0.7898\n",
            "Epoch 166/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5358 - accuracy: 0.7891\n",
            "Epoch 167/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5323 - accuracy: 0.7942\n",
            "Epoch 168/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5318 - accuracy: 0.7915\n",
            "Epoch 169/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5333 - accuracy: 0.7930\n",
            "Epoch 170/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5290 - accuracy: 0.7926\n",
            "Epoch 171/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5289 - accuracy: 0.7935\n",
            "Epoch 172/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5261 - accuracy: 0.7945\n",
            "Epoch 173/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5280 - accuracy: 0.7950\n",
            "Epoch 174/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5229 - accuracy: 0.7972\n",
            "Epoch 175/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5290 - accuracy: 0.7966\n",
            "Epoch 176/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5239 - accuracy: 0.7977\n",
            "Epoch 177/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5234 - accuracy: 0.7973\n",
            "Epoch 178/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5253 - accuracy: 0.7945\n",
            "Epoch 179/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5184 - accuracy: 0.7981\n",
            "Epoch 180/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5251 - accuracy: 0.7950\n",
            "Epoch 181/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5171 - accuracy: 0.7992\n",
            "Epoch 182/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5211 - accuracy: 0.7976\n",
            "Epoch 183/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5202 - accuracy: 0.7966\n",
            "Epoch 184/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5176 - accuracy: 0.7963\n",
            "Epoch 185/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5157 - accuracy: 0.7993\n",
            "Epoch 186/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5115 - accuracy: 0.7993\n",
            "Epoch 187/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5188 - accuracy: 0.7978\n",
            "Epoch 188/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5145 - accuracy: 0.7996\n",
            "Epoch 189/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5078 - accuracy: 0.8028\n",
            "Epoch 190/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5139 - accuracy: 0.7981\n",
            "Epoch 191/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5072 - accuracy: 0.8033\n",
            "Epoch 192/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5042 - accuracy: 0.8027\n",
            "Epoch 193/200\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5116 - accuracy: 0.8025\n",
            "Epoch 194/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5069 - accuracy: 0.8020\n",
            "Epoch 195/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5073 - accuracy: 0.8006\n",
            "Epoch 196/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5060 - accuracy: 0.8041\n",
            "Epoch 197/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5040 - accuracy: 0.8031\n",
            "Epoch 198/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5029 - accuracy: 0.8055\n",
            "Epoch 199/200\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5087 - accuracy: 0.8004\n",
            "Epoch 200/200\n",
            "424/433 [============================>.] - ETA: 0s - loss: 0.5021 - accuracy: 0.8036\n",
            "Epoch 00200: saving model to /content/gdrive/My Drive/ensemble/s828/student/student_200_epochs/weights-200-0.804.ckpt\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5013 - accuracy: 0.8039\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7ba22ea0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latest_student_60_epochs=tensorflow.train.latest_checkpoint(checkpoint_student_model_60_epochs_dir)"
      ],
      "metadata": {
        "id": "DZhRWVW_JBcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(latest_student_60_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C-j7rDZJKx0",
        "outputId": "3d0e6056-f999-4aff-a092-38fbd39d76db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/ensemble/s828/student/student_200_epochs/weights-200-0.804.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_60_epochs.load_weights(latest_student_60_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8NevyKQJK2M",
        "outputId": "0e961348-9e7d-417b-8ab4-0f5943ef2b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7c10202c10>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_60_epochs.compile(optimizer=optimizer_student, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ziAW2zc-JY-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_student_model_60_epochs = student_200_epochs.evaluate(pp_X_sub_482, y_sub_482_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IneVJwdJZDK",
        "outputId": "ad80f370-2d7a-47a7-f680-8a46c8c738a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 4ms/step - loss: 3.2923 - accuracy: 0.5513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "300 epochs"
      ],
      "metadata": {
        "id": "t5OMEARPLHVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "with open(\"/content/gdrive/My Drive/ensemble/s828/json_config_best_model_student_s828.json\",\"r\") as file:\n",
        "  read_model=file.read()\n",
        "\n",
        "\n",
        "student_300_epochs=model_from_json(read_model)"
      ],
      "metadata": {
        "id": "pory2dlaLF_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_300_epochs.compile(optimizer=optimizer_student, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hqCmLz_RLJxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_student_model_300_epochs = \"/content/gdrive/My Drive/ensemble/s828/student/student_300_epochs/weights-{epoch:02d}-{accuracy:.3f}.ckpt\""
      ],
      "metadata": {
        "id": "mhGDlYGSLJ14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_student_model_300_epochs_dir = os.path.dirname(checkpoint_student_model_300_epochs)"
      ],
      "metadata": {
        "id": "PHhsTlTbLGXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp_callback_student_model_300_epochs = tensorflow.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_student_model_300_epochs,\n",
        "    monitor='accuracy', \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    mode = 'max',\n",
        "    period=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvIKtRcWLGbF",
        "outputId": "0e84ee5f-878f-47c6-b4a5-3a4afa4d26d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_300_epochs.fit(x_transfer_set_cp_ar, y_transfer_ar_cp_ohe, epochs=300, callbacks=[cp_callback_student_model_300_epochs])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOhpjDisLGf6",
        "outputId": "ba18971a-15d9-4b34-b521-ec37a51bc95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 1.0121 - accuracy: 0.5907\n",
            "Epoch 2/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.9434 - accuracy: 0.6094\n",
            "Epoch 3/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.9051 - accuracy: 0.6378\n",
            "Epoch 4/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8865 - accuracy: 0.6465\n",
            "Epoch 5/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8674 - accuracy: 0.6599\n",
            "Epoch 6/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8530 - accuracy: 0.6678\n",
            "Epoch 7/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8472 - accuracy: 0.6698\n",
            "Epoch 8/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8397 - accuracy: 0.6797\n",
            "Epoch 9/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8306 - accuracy: 0.6810\n",
            "Epoch 10/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8212 - accuracy: 0.6844\n",
            "Epoch 11/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8121 - accuracy: 0.6880\n",
            "Epoch 12/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8047 - accuracy: 0.6883\n",
            "Epoch 13/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7987 - accuracy: 0.6942\n",
            "Epoch 14/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7933 - accuracy: 0.6977\n",
            "Epoch 15/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7927 - accuracy: 0.6953\n",
            "Epoch 16/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7862 - accuracy: 0.6954\n",
            "Epoch 17/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7817 - accuracy: 0.6984\n",
            "Epoch 18/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7735 - accuracy: 0.7004\n",
            "Epoch 19/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7727 - accuracy: 0.7017\n",
            "Epoch 20/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7672 - accuracy: 0.7042\n",
            "Epoch 21/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7641 - accuracy: 0.7069\n",
            "Epoch 22/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7617 - accuracy: 0.7040\n",
            "Epoch 23/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7596 - accuracy: 0.7063\n",
            "Epoch 24/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7524 - accuracy: 0.7082\n",
            "Epoch 25/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7521 - accuracy: 0.7090\n",
            "Epoch 26/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7488 - accuracy: 0.7082\n",
            "Epoch 27/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7427 - accuracy: 0.7140\n",
            "Epoch 28/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7422 - accuracy: 0.7115\n",
            "Epoch 29/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7404 - accuracy: 0.7139\n",
            "Epoch 30/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7378 - accuracy: 0.7129\n",
            "Epoch 31/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7339 - accuracy: 0.7165\n",
            "Epoch 32/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7291 - accuracy: 0.7157\n",
            "Epoch 33/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7264 - accuracy: 0.7190\n",
            "Epoch 34/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7244 - accuracy: 0.7184\n",
            "Epoch 35/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7204 - accuracy: 0.7222\n",
            "Epoch 36/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7205 - accuracy: 0.7194\n",
            "Epoch 37/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7152 - accuracy: 0.7225\n",
            "Epoch 38/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7196 - accuracy: 0.7220\n",
            "Epoch 39/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7146 - accuracy: 0.7235\n",
            "Epoch 40/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7081 - accuracy: 0.7264\n",
            "Epoch 41/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7087 - accuracy: 0.7291\n",
            "Epoch 42/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7016 - accuracy: 0.7303\n",
            "Epoch 43/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7063 - accuracy: 0.7268\n",
            "Epoch 44/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6981 - accuracy: 0.7312\n",
            "Epoch 45/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6960 - accuracy: 0.7300\n",
            "Epoch 46/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6996 - accuracy: 0.7321\n",
            "Epoch 47/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6879 - accuracy: 0.7364\n",
            "Epoch 48/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6925 - accuracy: 0.7311\n",
            "Epoch 49/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6916 - accuracy: 0.7331\n",
            "Epoch 50/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6852 - accuracy: 0.7363\n",
            "Epoch 51/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6838 - accuracy: 0.7357\n",
            "Epoch 52/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6847 - accuracy: 0.7325\n",
            "Epoch 53/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6778 - accuracy: 0.7395\n",
            "Epoch 54/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6748 - accuracy: 0.7404\n",
            "Epoch 55/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6764 - accuracy: 0.7402\n",
            "Epoch 56/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6723 - accuracy: 0.7431\n",
            "Epoch 57/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6714 - accuracy: 0.7399\n",
            "Epoch 58/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6709 - accuracy: 0.7405\n",
            "Epoch 59/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6689 - accuracy: 0.7412\n",
            "Epoch 60/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6724 - accuracy: 0.7376\n",
            "Epoch 61/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6635 - accuracy: 0.7415\n",
            "Epoch 62/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6586 - accuracy: 0.7459\n",
            "Epoch 63/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6583 - accuracy: 0.7472\n",
            "Epoch 64/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6595 - accuracy: 0.7439\n",
            "Epoch 65/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6546 - accuracy: 0.7480\n",
            "Epoch 66/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6521 - accuracy: 0.7443\n",
            "Epoch 67/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6507 - accuracy: 0.7516\n",
            "Epoch 68/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6471 - accuracy: 0.7489\n",
            "Epoch 69/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6463 - accuracy: 0.7507\n",
            "Epoch 70/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6420 - accuracy: 0.7532\n",
            "Epoch 71/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6453 - accuracy: 0.7468\n",
            "Epoch 72/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6415 - accuracy: 0.7509\n",
            "Epoch 73/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6423 - accuracy: 0.7534\n",
            "Epoch 74/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6357 - accuracy: 0.7561\n",
            "Epoch 75/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6358 - accuracy: 0.7527\n",
            "Epoch 76/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6364 - accuracy: 0.7526\n",
            "Epoch 77/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6365 - accuracy: 0.7537\n",
            "Epoch 78/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6382 - accuracy: 0.7536\n",
            "Epoch 79/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6271 - accuracy: 0.7564\n",
            "Epoch 80/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6253 - accuracy: 0.7579\n",
            "Epoch 81/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6293 - accuracy: 0.7583\n",
            "Epoch 82/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6252 - accuracy: 0.7553\n",
            "Epoch 83/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6222 - accuracy: 0.7598\n",
            "Epoch 84/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6221 - accuracy: 0.7573\n",
            "Epoch 85/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6201 - accuracy: 0.7587\n",
            "Epoch 86/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6188 - accuracy: 0.7622\n",
            "Epoch 87/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6159 - accuracy: 0.7610\n",
            "Epoch 88/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6162 - accuracy: 0.7617\n",
            "Epoch 89/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6106 - accuracy: 0.7647\n",
            "Epoch 90/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6129 - accuracy: 0.7666\n",
            "Epoch 91/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6078 - accuracy: 0.7651\n",
            "Epoch 92/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6095 - accuracy: 0.7634\n",
            "Epoch 93/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6089 - accuracy: 0.7591\n",
            "Epoch 94/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6021 - accuracy: 0.7642\n",
            "Epoch 95/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6088 - accuracy: 0.7620\n",
            "Epoch 96/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6015 - accuracy: 0.7658\n",
            "Epoch 97/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6005 - accuracy: 0.7657\n",
            "Epoch 98/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6008 - accuracy: 0.7675\n",
            "Epoch 99/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5941 - accuracy: 0.7722\n",
            "Epoch 100/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6023 - accuracy: 0.7697\n",
            "Epoch 101/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5996 - accuracy: 0.7669\n",
            "Epoch 102/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5957 - accuracy: 0.7680\n",
            "Epoch 103/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5930 - accuracy: 0.7707\n",
            "Epoch 104/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5942 - accuracy: 0.7674\n",
            "Epoch 105/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5889 - accuracy: 0.7694\n",
            "Epoch 106/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5854 - accuracy: 0.7736\n",
            "Epoch 107/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5826 - accuracy: 0.7757\n",
            "Epoch 108/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5857 - accuracy: 0.7720\n",
            "Epoch 109/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5782 - accuracy: 0.7770\n",
            "Epoch 110/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5839 - accuracy: 0.7739\n",
            "Epoch 111/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5819 - accuracy: 0.7735\n",
            "Epoch 112/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5761 - accuracy: 0.7783\n",
            "Epoch 113/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5745 - accuracy: 0.7744\n",
            "Epoch 114/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5687 - accuracy: 0.7795\n",
            "Epoch 115/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5686 - accuracy: 0.7812\n",
            "Epoch 116/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5689 - accuracy: 0.7813\n",
            "Epoch 117/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5719 - accuracy: 0.7783\n",
            "Epoch 118/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5758 - accuracy: 0.7785\n",
            "Epoch 119/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5662 - accuracy: 0.7808\n",
            "Epoch 120/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5736 - accuracy: 0.7781\n",
            "Epoch 121/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5614 - accuracy: 0.7814\n",
            "Epoch 122/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5639 - accuracy: 0.7822\n",
            "Epoch 123/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5596 - accuracy: 0.7822\n",
            "Epoch 124/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5600 - accuracy: 0.7833\n",
            "Epoch 125/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5604 - accuracy: 0.7838\n",
            "Epoch 126/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5585 - accuracy: 0.7842\n",
            "Epoch 127/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5600 - accuracy: 0.7832\n",
            "Epoch 128/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5527 - accuracy: 0.7855\n",
            "Epoch 129/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5511 - accuracy: 0.7858\n",
            "Epoch 130/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5499 - accuracy: 0.7859\n",
            "Epoch 131/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5566 - accuracy: 0.7835\n",
            "Epoch 132/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5512 - accuracy: 0.7843\n",
            "Epoch 133/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5453 - accuracy: 0.7864\n",
            "Epoch 134/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5446 - accuracy: 0.7882\n",
            "Epoch 135/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5459 - accuracy: 0.7898\n",
            "Epoch 136/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5433 - accuracy: 0.7892\n",
            "Epoch 137/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5424 - accuracy: 0.7908\n",
            "Epoch 138/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5461 - accuracy: 0.7871\n",
            "Epoch 139/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5385 - accuracy: 0.7897\n",
            "Epoch 140/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5368 - accuracy: 0.7918\n",
            "Epoch 141/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5393 - accuracy: 0.7921\n",
            "Epoch 142/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5383 - accuracy: 0.7905\n",
            "Epoch 143/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5321 - accuracy: 0.7916\n",
            "Epoch 144/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5311 - accuracy: 0.7944\n",
            "Epoch 145/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5403 - accuracy: 0.7891\n",
            "Epoch 146/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5283 - accuracy: 0.7963\n",
            "Epoch 147/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5278 - accuracy: 0.7960\n",
            "Epoch 148/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5353 - accuracy: 0.7896\n",
            "Epoch 149/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5239 - accuracy: 0.7937\n",
            "Epoch 150/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5247 - accuracy: 0.7968\n",
            "Epoch 151/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5252 - accuracy: 0.7921\n",
            "Epoch 152/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5263 - accuracy: 0.7952\n",
            "Epoch 153/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5231 - accuracy: 0.7950\n",
            "Epoch 154/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5206 - accuracy: 0.7991\n",
            "Epoch 155/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5191 - accuracy: 0.7982\n",
            "Epoch 156/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5231 - accuracy: 0.7966\n",
            "Epoch 157/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5139 - accuracy: 0.8010\n",
            "Epoch 158/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5144 - accuracy: 0.7997\n",
            "Epoch 159/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5136 - accuracy: 0.8002\n",
            "Epoch 160/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5139 - accuracy: 0.7983\n",
            "Epoch 161/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5181 - accuracy: 0.7988\n",
            "Epoch 162/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5117 - accuracy: 0.7991\n",
            "Epoch 163/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5109 - accuracy: 0.7983\n",
            "Epoch 164/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5082 - accuracy: 0.8002\n",
            "Epoch 165/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5113 - accuracy: 0.8010\n",
            "Epoch 166/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5075 - accuracy: 0.7994\n",
            "Epoch 167/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5039 - accuracy: 0.8008\n",
            "Epoch 168/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5021 - accuracy: 0.8055\n",
            "Epoch 169/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5039 - accuracy: 0.8044\n",
            "Epoch 170/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5007 - accuracy: 0.8061\n",
            "Epoch 171/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5037 - accuracy: 0.8029\n",
            "Epoch 172/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4934 - accuracy: 0.8068\n",
            "Epoch 173/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5029 - accuracy: 0.8020\n",
            "Epoch 174/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4939 - accuracy: 0.8066\n",
            "Epoch 175/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4969 - accuracy: 0.8064\n",
            "Epoch 176/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5024 - accuracy: 0.8049\n",
            "Epoch 177/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4945 - accuracy: 0.8067\n",
            "Epoch 178/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4939 - accuracy: 0.8076\n",
            "Epoch 179/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4973 - accuracy: 0.8103\n",
            "Epoch 180/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4878 - accuracy: 0.8109\n",
            "Epoch 181/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4918 - accuracy: 0.8114\n",
            "Epoch 182/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4848 - accuracy: 0.8095\n",
            "Epoch 183/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4831 - accuracy: 0.8113\n",
            "Epoch 184/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4856 - accuracy: 0.8106\n",
            "Epoch 185/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4853 - accuracy: 0.8078\n",
            "Epoch 186/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4872 - accuracy: 0.8092\n",
            "Epoch 187/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4868 - accuracy: 0.8088\n",
            "Epoch 188/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4776 - accuracy: 0.8122\n",
            "Epoch 189/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4842 - accuracy: 0.8106\n",
            "Epoch 190/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4781 - accuracy: 0.8156\n",
            "Epoch 191/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4745 - accuracy: 0.8164\n",
            "Epoch 192/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4786 - accuracy: 0.8146\n",
            "Epoch 193/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4788 - accuracy: 0.8103\n",
            "Epoch 194/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4708 - accuracy: 0.8175\n",
            "Epoch 195/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4745 - accuracy: 0.8156\n",
            "Epoch 196/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4750 - accuracy: 0.8136\n",
            "Epoch 197/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4689 - accuracy: 0.8151\n",
            "Epoch 198/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4774 - accuracy: 0.8145\n",
            "Epoch 199/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4711 - accuracy: 0.8132\n",
            "Epoch 200/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4734 - accuracy: 0.8156\n",
            "Epoch 201/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4693 - accuracy: 0.8178\n",
            "Epoch 202/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4653 - accuracy: 0.8174\n",
            "Epoch 203/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4698 - accuracy: 0.8204\n",
            "Epoch 204/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4640 - accuracy: 0.8184\n",
            "Epoch 205/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4628 - accuracy: 0.8187\n",
            "Epoch 206/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4600 - accuracy: 0.8220\n",
            "Epoch 207/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4671 - accuracy: 0.8176\n",
            "Epoch 208/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4611 - accuracy: 0.8208\n",
            "Epoch 209/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4557 - accuracy: 0.8225\n",
            "Epoch 210/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4539 - accuracy: 0.8216\n",
            "Epoch 211/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4559 - accuracy: 0.8237\n",
            "Epoch 212/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4676 - accuracy: 0.8185\n",
            "Epoch 213/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4536 - accuracy: 0.8240\n",
            "Epoch 214/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4542 - accuracy: 0.8221\n",
            "Epoch 215/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4522 - accuracy: 0.8263\n",
            "Epoch 216/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4464 - accuracy: 0.8276\n",
            "Epoch 217/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4547 - accuracy: 0.8209\n",
            "Epoch 218/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4503 - accuracy: 0.8267\n",
            "Epoch 219/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4433 - accuracy: 0.8283\n",
            "Epoch 220/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4487 - accuracy: 0.8236\n",
            "Epoch 221/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4501 - accuracy: 0.8248\n",
            "Epoch 222/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4516 - accuracy: 0.8257\n",
            "Epoch 223/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4456 - accuracy: 0.8270\n",
            "Epoch 224/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4436 - accuracy: 0.8275\n",
            "Epoch 225/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4462 - accuracy: 0.8226\n",
            "Epoch 226/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4453 - accuracy: 0.8267\n",
            "Epoch 227/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4372 - accuracy: 0.8311\n",
            "Epoch 228/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4422 - accuracy: 0.8278\n",
            "Epoch 229/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4367 - accuracy: 0.8283\n",
            "Epoch 230/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4472 - accuracy: 0.8249\n",
            "Epoch 231/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4369 - accuracy: 0.8307\n",
            "Epoch 232/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4386 - accuracy: 0.8288\n",
            "Epoch 233/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4413 - accuracy: 0.8287\n",
            "Epoch 234/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4386 - accuracy: 0.8288\n",
            "Epoch 235/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4391 - accuracy: 0.8300\n",
            "Epoch 236/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4348 - accuracy: 0.8308\n",
            "Epoch 237/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4372 - accuracy: 0.8310\n",
            "Epoch 238/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4358 - accuracy: 0.8314\n",
            "Epoch 239/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4323 - accuracy: 0.8315\n",
            "Epoch 240/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4265 - accuracy: 0.8297\n",
            "Epoch 241/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4290 - accuracy: 0.8320\n",
            "Epoch 242/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4410 - accuracy: 0.8292\n",
            "Epoch 243/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4272 - accuracy: 0.8364\n",
            "Epoch 244/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4251 - accuracy: 0.8343\n",
            "Epoch 245/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4290 - accuracy: 0.8339\n",
            "Epoch 246/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4172 - accuracy: 0.8372\n",
            "Epoch 247/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4262 - accuracy: 0.8347\n",
            "Epoch 248/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4254 - accuracy: 0.8360\n",
            "Epoch 249/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4173 - accuracy: 0.8360\n",
            "Epoch 250/300\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4235 - accuracy: 0.8350\n",
            "Epoch 251/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4183 - accuracy: 0.8377\n",
            "Epoch 252/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4221 - accuracy: 0.8403\n",
            "Epoch 253/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4218 - accuracy: 0.8334\n",
            "Epoch 254/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4261 - accuracy: 0.8333\n",
            "Epoch 255/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4166 - accuracy: 0.8387\n",
            "Epoch 256/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4230 - accuracy: 0.8369\n",
            "Epoch 257/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4173 - accuracy: 0.8384\n",
            "Epoch 258/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4182 - accuracy: 0.8371\n",
            "Epoch 259/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4215 - accuracy: 0.8354\n",
            "Epoch 260/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4140 - accuracy: 0.8414\n",
            "Epoch 261/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4164 - accuracy: 0.8372\n",
            "Epoch 262/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4094 - accuracy: 0.8424\n",
            "Epoch 263/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4080 - accuracy: 0.8394\n",
            "Epoch 264/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4100 - accuracy: 0.8404\n",
            "Epoch 265/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4102 - accuracy: 0.8373\n",
            "Epoch 266/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4077 - accuracy: 0.8442\n",
            "Epoch 267/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4024 - accuracy: 0.8443\n",
            "Epoch 268/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4109 - accuracy: 0.8388\n",
            "Epoch 269/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4127 - accuracy: 0.8385\n",
            "Epoch 270/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4130 - accuracy: 0.8404\n",
            "Epoch 271/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4004 - accuracy: 0.8458\n",
            "Epoch 272/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4082 - accuracy: 0.8422\n",
            "Epoch 273/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4051 - accuracy: 0.8423\n",
            "Epoch 274/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4039 - accuracy: 0.8434\n",
            "Epoch 275/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4056 - accuracy: 0.8418\n",
            "Epoch 276/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4059 - accuracy: 0.8429\n",
            "Epoch 277/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4098 - accuracy: 0.8396\n",
            "Epoch 278/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3993 - accuracy: 0.8445\n",
            "Epoch 279/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3987 - accuracy: 0.8443\n",
            "Epoch 280/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3978 - accuracy: 0.8460\n",
            "Epoch 281/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3993 - accuracy: 0.8465\n",
            "Epoch 282/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3932 - accuracy: 0.8485\n",
            "Epoch 283/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3971 - accuracy: 0.8480\n",
            "Epoch 284/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3886 - accuracy: 0.8515\n",
            "Epoch 285/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3901 - accuracy: 0.8489\n",
            "Epoch 286/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4022 - accuracy: 0.8419\n",
            "Epoch 287/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3916 - accuracy: 0.8491\n",
            "Epoch 288/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4000 - accuracy: 0.8455\n",
            "Epoch 289/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3942 - accuracy: 0.8459\n",
            "Epoch 290/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3914 - accuracy: 0.8458\n",
            "Epoch 291/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3961 - accuracy: 0.8445\n",
            "Epoch 292/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3876 - accuracy: 0.8510\n",
            "Epoch 293/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3799 - accuracy: 0.8551\n",
            "Epoch 294/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3917 - accuracy: 0.8468\n",
            "Epoch 295/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3920 - accuracy: 0.8476\n",
            "Epoch 296/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3895 - accuracy: 0.8499\n",
            "Epoch 297/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3924 - accuracy: 0.8481\n",
            "Epoch 298/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3856 - accuracy: 0.8510\n",
            "Epoch 299/300\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3846 - accuracy: 0.8485\n",
            "Epoch 300/300\n",
            "432/433 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8474\n",
            "Epoch 00300: saving model to /content/gdrive/My Drive/ensemble/s828/student/student_300_epochs/weights-300-0.847.ckpt\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3893 - accuracy: 0.8474\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7b86e9ff90>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latest_student_300_epochs=tensorflow.train.latest_checkpoint(checkpoint_student_model_300_epochs_dir)"
      ],
      "metadata": {
        "id": "AN766yqWJZIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(latest_student_300_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbgIPD-_MQr2",
        "outputId": "63c03057-4542-48df-e8ce-a3980d195359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/ensemble/s828/student/student_300_epochs/weights-300-0.847.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_300_epochs.load_weights(latest_student_300_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td96MRnDMQv6",
        "outputId": "d1a0bf46-593e-4c14-c824-e32fd7012f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7b87752d10>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_300_epochs.compile(optimizer=optimizer_student, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rA2HIo40Mb5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_student_model_300_epochs = student_300_epochs.evaluate(trans_x_train_s828_cp, y_train_s828_ar_ohe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWcdEGJJMb-i",
        "outputId": "f9ee3a78-9b64-4f1c-a28d-dab8d5fc95cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9051 - accuracy: 0.6442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "400 epochs"
      ],
      "metadata": {
        "id": "rAIOEzApPisS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "with open(\"/content/gdrive/My Drive/ensemble/s828/json_config_best_model_student_s828.json\",\"r\") as file:\n",
        "  read_model=file.read()\n",
        "\n",
        "\n",
        "student_400_epochs=model_from_json(read_model)"
      ],
      "metadata": {
        "id": "L-pLD-GsMcDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_400_epochs.compile(optimizer=optimizer_student, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yrkcuuJDPnN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_student_model_400_epochs = \"/content/gdrive/My Drive/ensemble/s828/student/student_400_epochs/weights-{epoch:02d}-{accuracy:.3f}.ckpt\""
      ],
      "metadata": {
        "id": "E52L4m_XPnTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_student_model_400_epochs_dir = os.path.dirname(checkpoint_student_model_400_epochs)"
      ],
      "metadata": {
        "id": "1bEgxqpkPnWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp_callback_student_model_400_epochs = tensorflow.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_student_model_400_epochs,\n",
        "    monitor='accuracy', \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    mode = 'max',\n",
        "    period=400)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPXvDhf6MQ09",
        "outputId": "ea420d21-3d76-47ba-8227-a3e2d3796ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_400_epochs.fit(x_transfer_set_cp_ar, y_transfer_ar_cp_ohe, epochs=400, callbacks=[cp_callback_student_model_400_epochs])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3w3tnFdQBlj",
        "outputId": "59219931-ed8c-4cab-e529-573ec4951482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 1.0191 - accuracy: 0.5879\n",
            "Epoch 2/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.9466 - accuracy: 0.6043\n",
            "Epoch 3/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.9135 - accuracy: 0.6316\n",
            "Epoch 4/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8923 - accuracy: 0.6429\n",
            "Epoch 5/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.8780 - accuracy: 0.6556\n",
            "Epoch 6/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8654 - accuracy: 0.6586\n",
            "Epoch 7/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8524 - accuracy: 0.6672\n",
            "Epoch 8/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8459 - accuracy: 0.6701\n",
            "Epoch 9/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.8349 - accuracy: 0.6781\n",
            "Epoch 10/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.8272 - accuracy: 0.6824\n",
            "Epoch 11/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8230 - accuracy: 0.6823\n",
            "Epoch 12/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8164 - accuracy: 0.6824\n",
            "Epoch 13/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.8102 - accuracy: 0.6873\n",
            "Epoch 14/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.8039 - accuracy: 0.6907\n",
            "Epoch 15/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7979 - accuracy: 0.6917\n",
            "Epoch 16/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7964 - accuracy: 0.6936\n",
            "Epoch 17/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7897 - accuracy: 0.6923\n",
            "Epoch 18/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7887 - accuracy: 0.6957\n",
            "Epoch 19/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7813 - accuracy: 0.6980\n",
            "Epoch 20/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7822 - accuracy: 0.6986\n",
            "Epoch 21/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7757 - accuracy: 0.7003\n",
            "Epoch 22/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7728 - accuracy: 0.7024\n",
            "Epoch 23/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7704 - accuracy: 0.7031\n",
            "Epoch 24/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7638 - accuracy: 0.7057\n",
            "Epoch 25/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7668 - accuracy: 0.7047\n",
            "Epoch 26/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7600 - accuracy: 0.7066\n",
            "Epoch 27/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7578 - accuracy: 0.7056\n",
            "Epoch 28/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7494 - accuracy: 0.7123\n",
            "Epoch 29/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7454 - accuracy: 0.7115\n",
            "Epoch 30/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7445 - accuracy: 0.7131\n",
            "Epoch 31/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7423 - accuracy: 0.7143\n",
            "Epoch 32/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7424 - accuracy: 0.7126\n",
            "Epoch 33/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7354 - accuracy: 0.7149\n",
            "Epoch 34/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7300 - accuracy: 0.7183\n",
            "Epoch 35/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7313 - accuracy: 0.7187\n",
            "Epoch 36/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7295 - accuracy: 0.7183\n",
            "Epoch 37/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7235 - accuracy: 0.7217\n",
            "Epoch 38/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7237 - accuracy: 0.7220\n",
            "Epoch 39/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7192 - accuracy: 0.7223\n",
            "Epoch 40/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7191 - accuracy: 0.7228\n",
            "Epoch 41/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7160 - accuracy: 0.7220\n",
            "Epoch 42/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7109 - accuracy: 0.7253\n",
            "Epoch 43/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7097 - accuracy: 0.7256\n",
            "Epoch 44/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.7095 - accuracy: 0.7253\n",
            "Epoch 45/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7014 - accuracy: 0.7262\n",
            "Epoch 46/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.7021 - accuracy: 0.7251\n",
            "Epoch 47/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6947 - accuracy: 0.7308\n",
            "Epoch 48/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6963 - accuracy: 0.7316\n",
            "Epoch 49/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6951 - accuracy: 0.7313\n",
            "Epoch 50/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6900 - accuracy: 0.7327\n",
            "Epoch 51/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6902 - accuracy: 0.7335\n",
            "Epoch 52/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6842 - accuracy: 0.7363\n",
            "Epoch 53/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6868 - accuracy: 0.7371\n",
            "Epoch 54/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6845 - accuracy: 0.7321\n",
            "Epoch 55/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6767 - accuracy: 0.7363\n",
            "Epoch 56/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6763 - accuracy: 0.7373\n",
            "Epoch 57/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6817 - accuracy: 0.7385\n",
            "Epoch 58/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6696 - accuracy: 0.7419\n",
            "Epoch 59/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6724 - accuracy: 0.7376\n",
            "Epoch 60/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6715 - accuracy: 0.7380\n",
            "Epoch 61/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6724 - accuracy: 0.7409\n",
            "Epoch 62/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6622 - accuracy: 0.7426\n",
            "Epoch 63/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6645 - accuracy: 0.7433\n",
            "Epoch 64/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6619 - accuracy: 0.7421\n",
            "Epoch 65/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6615 - accuracy: 0.7426\n",
            "Epoch 66/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6570 - accuracy: 0.7454\n",
            "Epoch 67/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6595 - accuracy: 0.7418\n",
            "Epoch 68/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6508 - accuracy: 0.7475\n",
            "Epoch 69/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6546 - accuracy: 0.7436\n",
            "Epoch 70/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6526 - accuracy: 0.7449\n",
            "Epoch 71/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6479 - accuracy: 0.7503\n",
            "Epoch 72/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6463 - accuracy: 0.7497\n",
            "Epoch 73/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6454 - accuracy: 0.7452\n",
            "Epoch 74/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6461 - accuracy: 0.7470\n",
            "Epoch 75/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6393 - accuracy: 0.7533\n",
            "Epoch 76/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6355 - accuracy: 0.7555\n",
            "Epoch 77/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6412 - accuracy: 0.7504\n",
            "Epoch 78/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6363 - accuracy: 0.7526\n",
            "Epoch 79/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6392 - accuracy: 0.7525\n",
            "Epoch 80/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6333 - accuracy: 0.7502\n",
            "Epoch 81/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6290 - accuracy: 0.7551\n",
            "Epoch 82/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6287 - accuracy: 0.7561\n",
            "Epoch 83/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6308 - accuracy: 0.7527\n",
            "Epoch 84/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6357 - accuracy: 0.7515\n",
            "Epoch 85/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6174 - accuracy: 0.7587\n",
            "Epoch 86/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6179 - accuracy: 0.7594\n",
            "Epoch 87/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6223 - accuracy: 0.7558\n",
            "Epoch 88/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6202 - accuracy: 0.7564\n",
            "Epoch 89/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6165 - accuracy: 0.7603\n",
            "Epoch 90/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6158 - accuracy: 0.7618\n",
            "Epoch 91/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6125 - accuracy: 0.7630\n",
            "Epoch 92/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6130 - accuracy: 0.7633\n",
            "Epoch 93/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6096 - accuracy: 0.7635\n",
            "Epoch 94/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6069 - accuracy: 0.7633\n",
            "Epoch 95/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6073 - accuracy: 0.7602\n",
            "Epoch 96/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6041 - accuracy: 0.7658\n",
            "Epoch 97/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.6066 - accuracy: 0.7639\n",
            "Epoch 98/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6058 - accuracy: 0.7644\n",
            "Epoch 99/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6009 - accuracy: 0.7646\n",
            "Epoch 100/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.6016 - accuracy: 0.7694\n",
            "Epoch 101/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5997 - accuracy: 0.7655\n",
            "Epoch 102/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5938 - accuracy: 0.7702\n",
            "Epoch 103/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5958 - accuracy: 0.7666\n",
            "Epoch 104/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5895 - accuracy: 0.7714\n",
            "Epoch 105/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5896 - accuracy: 0.7725\n",
            "Epoch 106/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5917 - accuracy: 0.7745\n",
            "Epoch 107/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5884 - accuracy: 0.7705\n",
            "Epoch 108/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5853 - accuracy: 0.7725\n",
            "Epoch 109/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5834 - accuracy: 0.7744\n",
            "Epoch 110/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5831 - accuracy: 0.7737\n",
            "Epoch 111/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5818 - accuracy: 0.7748\n",
            "Epoch 112/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5854 - accuracy: 0.7738\n",
            "Epoch 113/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5762 - accuracy: 0.7783\n",
            "Epoch 114/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5809 - accuracy: 0.7722\n",
            "Epoch 115/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5767 - accuracy: 0.7765\n",
            "Epoch 116/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5759 - accuracy: 0.7758\n",
            "Epoch 117/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5737 - accuracy: 0.7819\n",
            "Epoch 118/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5749 - accuracy: 0.7774\n",
            "Epoch 119/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5735 - accuracy: 0.7804\n",
            "Epoch 120/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5703 - accuracy: 0.7766\n",
            "Epoch 121/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5644 - accuracy: 0.7827\n",
            "Epoch 122/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5642 - accuracy: 0.7822\n",
            "Epoch 123/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5638 - accuracy: 0.7818\n",
            "Epoch 124/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5597 - accuracy: 0.7844\n",
            "Epoch 125/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5585 - accuracy: 0.7845\n",
            "Epoch 126/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5617 - accuracy: 0.7817\n",
            "Epoch 127/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5571 - accuracy: 0.7858\n",
            "Epoch 128/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5508 - accuracy: 0.7869\n",
            "Epoch 129/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5570 - accuracy: 0.7853\n",
            "Epoch 130/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5564 - accuracy: 0.7841\n",
            "Epoch 131/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5520 - accuracy: 0.7822\n",
            "Epoch 132/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5537 - accuracy: 0.7835\n",
            "Epoch 133/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5501 - accuracy: 0.7846\n",
            "Epoch 134/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5421 - accuracy: 0.7911\n",
            "Epoch 135/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5495 - accuracy: 0.7871\n",
            "Epoch 136/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5475 - accuracy: 0.7901\n",
            "Epoch 137/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5409 - accuracy: 0.7895\n",
            "Epoch 138/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5417 - accuracy: 0.7890\n",
            "Epoch 139/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5402 - accuracy: 0.7921\n",
            "Epoch 140/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5374 - accuracy: 0.7916\n",
            "Epoch 141/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5412 - accuracy: 0.7895\n",
            "Epoch 142/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5343 - accuracy: 0.7903\n",
            "Epoch 143/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5383 - accuracy: 0.7916\n",
            "Epoch 144/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5341 - accuracy: 0.7934\n",
            "Epoch 145/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5351 - accuracy: 0.7916\n",
            "Epoch 146/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5366 - accuracy: 0.7935\n",
            "Epoch 147/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5310 - accuracy: 0.7951\n",
            "Epoch 148/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5327 - accuracy: 0.7948\n",
            "Epoch 149/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5264 - accuracy: 0.7957\n",
            "Epoch 150/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5268 - accuracy: 0.7984\n",
            "Epoch 151/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5259 - accuracy: 0.7931\n",
            "Epoch 152/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5257 - accuracy: 0.7958\n",
            "Epoch 153/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5247 - accuracy: 0.7955\n",
            "Epoch 154/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5169 - accuracy: 0.7998\n",
            "Epoch 155/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5250 - accuracy: 0.7991\n",
            "Epoch 156/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5174 - accuracy: 0.7986\n",
            "Epoch 157/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5259 - accuracy: 0.7971\n",
            "Epoch 158/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5143 - accuracy: 0.8018\n",
            "Epoch 159/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5090 - accuracy: 0.8009\n",
            "Epoch 160/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5147 - accuracy: 0.8007\n",
            "Epoch 161/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5150 - accuracy: 0.8010\n",
            "Epoch 162/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5149 - accuracy: 0.7980\n",
            "Epoch 163/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5150 - accuracy: 0.7993\n",
            "Epoch 164/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5195 - accuracy: 0.7983\n",
            "Epoch 165/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5126 - accuracy: 0.7997\n",
            "Epoch 166/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5034 - accuracy: 0.8033\n",
            "Epoch 167/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5108 - accuracy: 0.8012\n",
            "Epoch 168/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5058 - accuracy: 0.8045\n",
            "Epoch 169/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5131 - accuracy: 0.8014\n",
            "Epoch 170/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4996 - accuracy: 0.8041\n",
            "Epoch 171/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5041 - accuracy: 0.8057\n",
            "Epoch 172/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5053 - accuracy: 0.8049\n",
            "Epoch 173/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5003 - accuracy: 0.8038\n",
            "Epoch 174/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5051 - accuracy: 0.8054\n",
            "Epoch 175/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5049 - accuracy: 0.8007\n",
            "Epoch 176/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.5012 - accuracy: 0.8048\n",
            "Epoch 177/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.5025 - accuracy: 0.8049\n",
            "Epoch 178/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4982 - accuracy: 0.8055\n",
            "Epoch 179/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4986 - accuracy: 0.8070\n",
            "Epoch 180/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4940 - accuracy: 0.8082\n",
            "Epoch 181/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4902 - accuracy: 0.8113\n",
            "Epoch 182/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4892 - accuracy: 0.8098\n",
            "Epoch 183/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4871 - accuracy: 0.8130\n",
            "Epoch 184/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4899 - accuracy: 0.8105\n",
            "Epoch 185/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4884 - accuracy: 0.8077\n",
            "Epoch 186/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4828 - accuracy: 0.8142\n",
            "Epoch 187/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4863 - accuracy: 0.8136\n",
            "Epoch 188/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4832 - accuracy: 0.8125\n",
            "Epoch 189/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4862 - accuracy: 0.8125\n",
            "Epoch 190/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4814 - accuracy: 0.8141\n",
            "Epoch 191/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4767 - accuracy: 0.8152\n",
            "Epoch 192/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4891 - accuracy: 0.8132\n",
            "Epoch 193/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4796 - accuracy: 0.8149\n",
            "Epoch 194/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4780 - accuracy: 0.8130\n",
            "Epoch 195/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4756 - accuracy: 0.8162\n",
            "Epoch 196/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4737 - accuracy: 0.8164\n",
            "Epoch 197/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4730 - accuracy: 0.8177\n",
            "Epoch 198/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4767 - accuracy: 0.8143\n",
            "Epoch 199/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4716 - accuracy: 0.8188\n",
            "Epoch 200/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4716 - accuracy: 0.8167\n",
            "Epoch 201/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4744 - accuracy: 0.8149\n",
            "Epoch 202/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4677 - accuracy: 0.8187\n",
            "Epoch 203/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4687 - accuracy: 0.8200\n",
            "Epoch 204/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4699 - accuracy: 0.8165\n",
            "Epoch 205/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4659 - accuracy: 0.8211\n",
            "Epoch 206/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4668 - accuracy: 0.8218\n",
            "Epoch 207/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4672 - accuracy: 0.8191\n",
            "Epoch 208/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4636 - accuracy: 0.8210\n",
            "Epoch 209/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4671 - accuracy: 0.8195\n",
            "Epoch 210/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4632 - accuracy: 0.8198\n",
            "Epoch 211/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4586 - accuracy: 0.8219\n",
            "Epoch 212/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4545 - accuracy: 0.8226\n",
            "Epoch 213/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4639 - accuracy: 0.8204\n",
            "Epoch 214/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4598 - accuracy: 0.8210\n",
            "Epoch 215/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4608 - accuracy: 0.8215\n",
            "Epoch 216/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4542 - accuracy: 0.8249\n",
            "Epoch 217/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4513 - accuracy: 0.8257\n",
            "Epoch 218/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4605 - accuracy: 0.8203\n",
            "Epoch 219/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4609 - accuracy: 0.8221\n",
            "Epoch 220/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4563 - accuracy: 0.8213\n",
            "Epoch 221/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4530 - accuracy: 0.8251\n",
            "Epoch 222/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4560 - accuracy: 0.8229\n",
            "Epoch 223/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4522 - accuracy: 0.8253\n",
            "Epoch 224/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4579 - accuracy: 0.8242\n",
            "Epoch 225/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4501 - accuracy: 0.8263\n",
            "Epoch 226/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4487 - accuracy: 0.8276\n",
            "Epoch 227/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4436 - accuracy: 0.8271\n",
            "Epoch 228/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4427 - accuracy: 0.8293\n",
            "Epoch 229/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4503 - accuracy: 0.8253\n",
            "Epoch 230/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4457 - accuracy: 0.8286\n",
            "Epoch 231/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4406 - accuracy: 0.8281\n",
            "Epoch 232/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4434 - accuracy: 0.8280\n",
            "Epoch 233/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4393 - accuracy: 0.8304\n",
            "Epoch 234/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4446 - accuracy: 0.8287\n",
            "Epoch 235/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4335 - accuracy: 0.8351\n",
            "Epoch 236/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4466 - accuracy: 0.8288\n",
            "Epoch 237/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4403 - accuracy: 0.8296\n",
            "Epoch 238/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4333 - accuracy: 0.8320\n",
            "Epoch 239/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4443 - accuracy: 0.8268\n",
            "Epoch 240/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4318 - accuracy: 0.8332\n",
            "Epoch 241/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4257 - accuracy: 0.8323\n",
            "Epoch 242/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4381 - accuracy: 0.8309\n",
            "Epoch 243/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4370 - accuracy: 0.8280\n",
            "Epoch 244/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4253 - accuracy: 0.8348\n",
            "Epoch 245/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4324 - accuracy: 0.8320\n",
            "Epoch 246/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4275 - accuracy: 0.8357\n",
            "Epoch 247/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4296 - accuracy: 0.8352\n",
            "Epoch 248/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4292 - accuracy: 0.8362\n",
            "Epoch 249/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4363 - accuracy: 0.8278\n",
            "Epoch 250/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4266 - accuracy: 0.8337\n",
            "Epoch 251/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4246 - accuracy: 0.8358\n",
            "Epoch 252/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4274 - accuracy: 0.8348\n",
            "Epoch 253/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4242 - accuracy: 0.8333\n",
            "Epoch 254/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4223 - accuracy: 0.8349\n",
            "Epoch 255/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4206 - accuracy: 0.8360\n",
            "Epoch 256/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4288 - accuracy: 0.8304\n",
            "Epoch 257/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4349 - accuracy: 0.8304\n",
            "Epoch 258/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4246 - accuracy: 0.8362\n",
            "Epoch 259/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4093 - accuracy: 0.8427\n",
            "Epoch 260/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4174 - accuracy: 0.8372\n",
            "Epoch 261/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4197 - accuracy: 0.8398\n",
            "Epoch 262/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4174 - accuracy: 0.8359\n",
            "Epoch 263/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4165 - accuracy: 0.8369\n",
            "Epoch 264/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4107 - accuracy: 0.8420\n",
            "Epoch 265/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4108 - accuracy: 0.8395\n",
            "Epoch 266/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4196 - accuracy: 0.8364\n",
            "Epoch 267/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4112 - accuracy: 0.8380\n",
            "Epoch 268/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4096 - accuracy: 0.8432\n",
            "Epoch 269/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4108 - accuracy: 0.8428\n",
            "Epoch 270/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4220 - accuracy: 0.8346\n",
            "Epoch 271/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4081 - accuracy: 0.8410\n",
            "Epoch 272/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4102 - accuracy: 0.8415\n",
            "Epoch 273/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4127 - accuracy: 0.8395\n",
            "Epoch 274/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4117 - accuracy: 0.8410\n",
            "Epoch 275/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4060 - accuracy: 0.8415\n",
            "Epoch 276/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4100 - accuracy: 0.8416\n",
            "Epoch 277/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4089 - accuracy: 0.8446\n",
            "Epoch 278/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4005 - accuracy: 0.8435\n",
            "Epoch 279/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4081 - accuracy: 0.8421\n",
            "Epoch 280/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4113 - accuracy: 0.8425\n",
            "Epoch 281/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4087 - accuracy: 0.8445\n",
            "Epoch 282/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4023 - accuracy: 0.8446\n",
            "Epoch 283/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4003 - accuracy: 0.8453\n",
            "Epoch 284/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3988 - accuracy: 0.8442\n",
            "Epoch 285/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4112 - accuracy: 0.8414\n",
            "Epoch 286/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3989 - accuracy: 0.8460\n",
            "Epoch 287/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4017 - accuracy: 0.8437\n",
            "Epoch 288/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3901 - accuracy: 0.8523\n",
            "Epoch 289/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4023 - accuracy: 0.8437\n",
            "Epoch 290/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4060 - accuracy: 0.8433\n",
            "Epoch 291/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3961 - accuracy: 0.8481\n",
            "Epoch 292/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.4037 - accuracy: 0.8448\n",
            "Epoch 293/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4003 - accuracy: 0.8451\n",
            "Epoch 294/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3912 - accuracy: 0.8489\n",
            "Epoch 295/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3959 - accuracy: 0.8464\n",
            "Epoch 296/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3926 - accuracy: 0.8502\n",
            "Epoch 297/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3836 - accuracy: 0.8556\n",
            "Epoch 298/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.4036 - accuracy: 0.8415\n",
            "Epoch 299/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3850 - accuracy: 0.8530\n",
            "Epoch 300/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3883 - accuracy: 0.8492\n",
            "Epoch 301/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3868 - accuracy: 0.8482\n",
            "Epoch 302/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3876 - accuracy: 0.8513\n",
            "Epoch 303/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3845 - accuracy: 0.8509\n",
            "Epoch 304/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3895 - accuracy: 0.8502\n",
            "Epoch 305/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3913 - accuracy: 0.8471\n",
            "Epoch 306/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3856 - accuracy: 0.8495\n",
            "Epoch 307/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3977 - accuracy: 0.8446\n",
            "Epoch 308/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3929 - accuracy: 0.8491\n",
            "Epoch 309/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3834 - accuracy: 0.8520\n",
            "Epoch 310/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3907 - accuracy: 0.8471\n",
            "Epoch 311/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3828 - accuracy: 0.8495\n",
            "Epoch 312/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3921 - accuracy: 0.8467\n",
            "Epoch 313/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3819 - accuracy: 0.8544\n",
            "Epoch 314/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3817 - accuracy: 0.8517\n",
            "Epoch 315/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3813 - accuracy: 0.8531\n",
            "Epoch 316/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3764 - accuracy: 0.8562\n",
            "Epoch 317/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3795 - accuracy: 0.8507\n",
            "Epoch 318/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3872 - accuracy: 0.8493\n",
            "Epoch 319/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3813 - accuracy: 0.8516\n",
            "Epoch 320/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3758 - accuracy: 0.8559\n",
            "Epoch 321/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3795 - accuracy: 0.8511\n",
            "Epoch 322/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3814 - accuracy: 0.8501\n",
            "Epoch 323/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3706 - accuracy: 0.8553\n",
            "Epoch 324/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3731 - accuracy: 0.8552\n",
            "Epoch 325/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3767 - accuracy: 0.8548\n",
            "Epoch 326/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3860 - accuracy: 0.8497\n",
            "Epoch 327/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3745 - accuracy: 0.8544\n",
            "Epoch 328/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3673 - accuracy: 0.8591\n",
            "Epoch 329/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3687 - accuracy: 0.8578\n",
            "Epoch 330/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3717 - accuracy: 0.8539\n",
            "Epoch 331/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3671 - accuracy: 0.8568\n",
            "Epoch 332/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3720 - accuracy: 0.8566\n",
            "Epoch 333/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3691 - accuracy: 0.8596\n",
            "Epoch 334/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3704 - accuracy: 0.8557\n",
            "Epoch 335/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3803 - accuracy: 0.8524\n",
            "Epoch 336/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3745 - accuracy: 0.8575\n",
            "Epoch 337/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3621 - accuracy: 0.8609\n",
            "Epoch 338/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3582 - accuracy: 0.8636\n",
            "Epoch 339/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3619 - accuracy: 0.8638\n",
            "Epoch 340/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3686 - accuracy: 0.8581\n",
            "Epoch 341/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3663 - accuracy: 0.8579\n",
            "Epoch 342/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3631 - accuracy: 0.8592\n",
            "Epoch 343/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3683 - accuracy: 0.8580\n",
            "Epoch 344/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3660 - accuracy: 0.8609\n",
            "Epoch 345/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3771 - accuracy: 0.8544\n",
            "Epoch 346/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3585 - accuracy: 0.8614\n",
            "Epoch 347/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3662 - accuracy: 0.8565\n",
            "Epoch 348/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3543 - accuracy: 0.8614\n",
            "Epoch 349/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3561 - accuracy: 0.8603\n",
            "Epoch 350/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3536 - accuracy: 0.8630\n",
            "Epoch 351/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3575 - accuracy: 0.8626\n",
            "Epoch 352/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3554 - accuracy: 0.8658\n",
            "Epoch 353/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3599 - accuracy: 0.8594\n",
            "Epoch 354/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3577 - accuracy: 0.8639\n",
            "Epoch 355/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3657 - accuracy: 0.8573\n",
            "Epoch 356/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3569 - accuracy: 0.8627\n",
            "Epoch 357/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3552 - accuracy: 0.8645\n",
            "Epoch 358/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3679 - accuracy: 0.8593\n",
            "Epoch 359/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3657 - accuracy: 0.8600\n",
            "Epoch 360/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3593 - accuracy: 0.8640\n",
            "Epoch 361/400\n",
            "433/433 [==============================] - 2s 4ms/step - loss: 0.3654 - accuracy: 0.8591\n",
            "Epoch 362/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3522 - accuracy: 0.8643\n",
            "Epoch 363/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3581 - accuracy: 0.8601\n",
            "Epoch 364/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3561 - accuracy: 0.8637\n",
            "Epoch 365/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3497 - accuracy: 0.8661\n",
            "Epoch 366/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3511 - accuracy: 0.8643\n",
            "Epoch 367/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3604 - accuracy: 0.8620\n",
            "Epoch 368/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3530 - accuracy: 0.8642\n",
            "Epoch 369/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3567 - accuracy: 0.8643\n",
            "Epoch 370/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3482 - accuracy: 0.8664\n",
            "Epoch 371/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3497 - accuracy: 0.8670\n",
            "Epoch 372/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3448 - accuracy: 0.8678\n",
            "Epoch 373/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3490 - accuracy: 0.8657\n",
            "Epoch 374/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3496 - accuracy: 0.8632\n",
            "Epoch 375/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3580 - accuracy: 0.8592\n",
            "Epoch 376/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3547 - accuracy: 0.8640\n",
            "Epoch 377/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3492 - accuracy: 0.8661\n",
            "Epoch 378/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3327 - accuracy: 0.8716\n",
            "Epoch 379/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3603 - accuracy: 0.8631\n",
            "Epoch 380/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3479 - accuracy: 0.8679\n",
            "Epoch 381/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3505 - accuracy: 0.8666\n",
            "Epoch 382/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3483 - accuracy: 0.8666\n",
            "Epoch 383/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3512 - accuracy: 0.8617\n",
            "Epoch 384/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3441 - accuracy: 0.8668\n",
            "Epoch 385/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3369 - accuracy: 0.8708\n",
            "Epoch 386/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3419 - accuracy: 0.8677\n",
            "Epoch 387/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3457 - accuracy: 0.8667\n",
            "Epoch 388/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3465 - accuracy: 0.8659\n",
            "Epoch 389/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3418 - accuracy: 0.8686\n",
            "Epoch 390/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3348 - accuracy: 0.8699\n",
            "Epoch 391/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3427 - accuracy: 0.8686\n",
            "Epoch 392/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3385 - accuracy: 0.8705\n",
            "Epoch 393/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3455 - accuracy: 0.8693\n",
            "Epoch 394/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3574 - accuracy: 0.8654\n",
            "Epoch 395/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3355 - accuracy: 0.8686\n",
            "Epoch 396/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3393 - accuracy: 0.8679\n",
            "Epoch 397/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3338 - accuracy: 0.8715\n",
            "Epoch 398/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3317 - accuracy: 0.8718\n",
            "Epoch 399/400\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3456 - accuracy: 0.8654\n",
            "Epoch 400/400\n",
            "423/433 [============================>.] - ETA: 0s - loss: 0.3492 - accuracy: 0.8628\n",
            "Epoch 00400: saving model to /content/gdrive/My Drive/ensemble/s828/student/student_400_epochs/weights-400-0.863.ckpt\n",
            "433/433 [==============================] - 2s 5ms/step - loss: 0.3501 - accuracy: 0.8625\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7b86567d90>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latest_student_400_epochs=tensorflow.train.latest_checkpoint(checkpoint_student_model_400_epochs_dir)"
      ],
      "metadata": {
        "id": "jVn_5up2QLgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(latest_student_400_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCCgRcNzQYoU",
        "outputId": "e7366a73-b8a7-437a-8b9f-30960f77237a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/ensemble/s828/student/student_400_epochs/weights-400-0.863.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_400_epochs.load_weights(latest_student_400_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vCUeHDAQYtk",
        "outputId": "efa729d5-2a72-4e7e-cacf-e045f73dd511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7b85b3bfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_400_epochs.compile(optimizer=optimizer_student, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "i_4ZgSfYQYyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_student_model_400_epochs = student_400_epochs.evaluate(trans_x_train_s828_cp, y_train_s828_ar_ohe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRZMELieQY3i",
        "outputId": "8351bc10-e8c5-4e2d-92fb-d4d43ee59245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 4ms/step - loss: 7.4530 - accuracy: 0.6090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KD with best heavy wt lstm model"
      ],
      "metadata": {
        "id": "93xiVjQ_Uhao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "A56jArwxU_8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "with open(\"/content/gdrive/My Drive/ensemble/s828/json_config_best_model_student_s828.json\",\"r\") as file:\n",
        "  read_model=file.read()\n",
        "\n",
        "\n",
        "student_model=model_from_json(read_model)"
      ],
      "metadata": {
        "id": "0xqXzW82T9a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model=model_b(verbose=VBS)"
      ],
      "metadata": {
        "id": "RFfzShUxVzli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#best_learning_rate_teacher=0.001\n",
        "#optimizer_teacher = Adam(learning_rate=best_learning_rate_teacher)"
      ],
      "metadata": {
        "id": "lv6nCD9OVzv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_teacher = \"/content/gdrive/My Drive/physionet/ensemble/teacher_wts_30_epochs_50_subs.ckpt\""
      ],
      "metadata": {
        "id": "MGG0_WLDWVZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_teacher_dir = os.path.dirname(checkpoint_teacher)"
      ],
      "metadata": {
        "id": "kdndRdbQWvEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#latest_teacher=tensorflow.train.latest_checkpoint(checkpoint_teacher_dir)"
      ],
      "metadata": {
        "id": "Qrtrf17sW7uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(checkpoint_teacher)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHd5_t1RXN_N",
        "outputId": "55f37333-0d88-4f41-d160-0ae8f27e5cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/ensemble/s828/teacher_300_epochs/weights-300-0.971.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model.load_weights(checkpoint_teacher)"
      ],
      "metadata": {
        "id": "wN-67mZLXYg5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7270dcc-2455-4641-aaf6-0e3c42c077f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7ae25eef90>"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model.compile(optimizer=optimizer_teacher, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "s4ImGlf84jex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfUYwLfo43kK",
        "outputId": "d7d1adf4-2a2d-4ff4-81f5-bafcac8c2306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inLayer (InputLayer)           [(None, 18, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " fConv1 (Conv1D)                (None, 18, 32)       3232        ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " cConv1 (Conv1D)                (None, 18, 32)       25632       ['inLayer[0][0]']                \n",
            "                                                                                                  \n",
            " fMaxP1 (MaxPooling1D)          (None, 9, 32)        0           ['fConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP1 (MaxPooling1D)          (None, 9, 32)        0           ['cConv1[0][0]']                 \n",
            "                                                                                                  \n",
            " fDrop1 (Dropout)               (None, 9, 32)        0           ['fMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " cDrop1 (Dropout)               (None, 9, 32)        0           ['cMaxP1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv2 (Conv1D)                (None, 9, 32)        2080        ['fDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv2 (Conv1D)                (None, 9, 32)        2080        ['cDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv3 (Conv1D)                (None, 9, 32)        2080        ['fConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv3 (Conv1D)                (None, 9, 32)        2080        ['cConv2[0][0]']                 \n",
            "                                                                                                  \n",
            " fConv4 (Conv1D)                (None, 9, 32)        2080        ['fConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " cConv4 (Conv1D)                (None, 9, 32)        2080        ['cConv3[0][0]']                 \n",
            "                                                                                                  \n",
            " fMaxP2 (MaxPooling1D)          (None, 4, 32)        0           ['fConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " cMaxP2 (MaxPooling1D)          (None, 4, 32)        0           ['cConv4[0][0]']                 \n",
            "                                                                                                  \n",
            " fFlat1 (Flatten)               (None, 128)          0           ['fMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " cFlat1 (Flatten)               (None, 128)          0           ['cMaxP2[0][0]']                 \n",
            "                                                                                                  \n",
            " merge_1 (Concatenate)          (None, 256)          0           ['fFlat1[0][0]',                 \n",
            "                                                                  'cFlat1[0][0]']                 \n",
            "                                                                                                  \n",
            " mDrop1 (Dropout)               (None, 256)          0           ['merge_1[0][0]']                \n",
            "                                                                                                  \n",
            " reshape1 (Reshape)             (None, 1, 256)       0           ['mDrop1[0][0]']                 \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 1, 256)       525312      ['reshape1[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 256)          525312      ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " outLayer (Dense)               (None, 5)            1285        ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,093,253\n",
            "Trainable params: 1,093,253\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_best_teacher = teacher_model.evaluate(pp_X_sub_482, y_sub_482_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcGbklNj46-w",
        "outputId": "244e8fae-b5bd-4b7e-eaa3-87425a575673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 2s 7ms/step - loss: 4.8575 - accuracy: 0.6231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Distiller(keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super(Distiller, self).__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "    ):\n",
        "        \"\"\" Configure the distiller.\n",
        "\n",
        "        Args:\n",
        "            optimizer: Keras optimizer for the student weights\n",
        "            metrics: Keras metrics for evaluation\n",
        "            student_loss_fn: Loss function of difference between student\n",
        "                predictions and ground-truth\n",
        "            distillation_loss_fn: Loss function of difference between soft\n",
        "                student predictions and soft teacher predictions\n",
        "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
        "            temperature: Temperature for softening probability distributions.\n",
        "                Larger temperature gives softer distributions.\n",
        "        \"\"\"\n",
        "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of teacher\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of student\n",
        "            student_predictions = self.student(x, training=True)\n",
        "\n",
        "            # Compute losses\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "            distillation_loss = self.distillation_loss_fn(\n",
        "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
        "            )\n",
        "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
        "        )\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_prediction = self.student(x, training=False)\n",
        "\n",
        "        # Calculate the loss\n",
        "        student_loss = self.student_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"student_loss\": student_loss})\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "NmBofK4H5CS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "M4FXorl45zcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_distiller_30_epochs = \"/content/gdrive/My Drive/physionet/ensemble/distilled_model/50_subs/distilled_model_30_epochs/weights-30_epochs.ckpt\""
      ],
      "metadata": {
        "id": "kJmfsxPn9-d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_distiller_30_epochs_dir = os.path.dirname(checkpoint_distiller_30_epochs)"
      ],
      "metadata": {
        "id": "yP5soriO-dwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp_callback_distiller_30_epochs = tensorflow.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_distiller_30_epochs,\n",
        "    monitor='accuracy', \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    mode = 'max',\n",
        "    period=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaY5C-wg-nC4",
        "outputId": "afe00d7c-b5c7-4fbc-c6e4-a503d7800ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and compile distiller\n",
        "distiller = Distiller(student=student_model, teacher=teacher_model)\n",
        "distiller.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.9,\n",
        "    temperature=4,\n",
        ")\n",
        "\n",
        "# Distill teacher to student\n",
        "distiller.fit(x_transfer_set_rshp, y_transfer_set_, epochs=30)\n",
        "\n",
        "# Evaluate student on test dataset\n",
        "#distiller.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0UOM4Sc51-T",
        "outputId": "f5f0eaa5-82ea-4194-d010-ed1902470188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "433/433 [==============================] - 7s 10ms/step - categorical_accuracy: 0.5859 - student_loss: 1.0411 - distillation_loss: 0.0017\n",
            "Epoch 2/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.6156 - student_loss: 0.9411 - distillation_loss: 0.0020\n",
            "Epoch 3/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.6382 - student_loss: 0.9050 - distillation_loss: 0.0021\n",
            "Epoch 4/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.6474 - student_loss: 0.8881 - distillation_loss: 0.0022\n",
            "Epoch 5/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.6609 - student_loss: 0.8673 - distillation_loss: 0.0022\n",
            "Epoch 6/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.6628 - student_loss: 0.8582 - distillation_loss: 0.0023\n",
            "Epoch 7/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.6723 - student_loss: 0.8416 - distillation_loss: 0.0023\n",
            "Epoch 8/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.6697 - student_loss: 0.8378 - distillation_loss: 0.0023\n",
            "Epoch 9/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.6784 - student_loss: 0.8283 - distillation_loss: 0.0023\n",
            "Epoch 10/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.6829 - student_loss: 0.8219 - distillation_loss: 0.0024\n",
            "Epoch 11/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.6878 - student_loss: 0.8078 - distillation_loss: 0.0024\n",
            "Epoch 12/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.6902 - student_loss: 0.8040 - distillation_loss: 0.0024\n",
            "Epoch 13/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.6886 - student_loss: 0.7978 - distillation_loss: 0.0025\n",
            "Epoch 14/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.6949 - student_loss: 0.7925 - distillation_loss: 0.0025\n",
            "Epoch 15/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.6978 - student_loss: 0.7857 - distillation_loss: 0.0025\n",
            "Epoch 16/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.6990 - student_loss: 0.7796 - distillation_loss: 0.0025\n",
            "Epoch 17/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.6990 - student_loss: 0.7714 - distillation_loss: 0.0025\n",
            "Epoch 18/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7021 - student_loss: 0.7694 - distillation_loss: 0.0026\n",
            "Epoch 19/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7022 - student_loss: 0.7649 - distillation_loss: 0.0026\n",
            "Epoch 20/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7047 - student_loss: 0.7599 - distillation_loss: 0.0026\n",
            "Epoch 21/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7079 - student_loss: 0.7557 - distillation_loss: 0.0026\n",
            "Epoch 22/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7097 - student_loss: 0.7474 - distillation_loss: 0.0026\n",
            "Epoch 23/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7095 - student_loss: 0.7498 - distillation_loss: 0.0026\n",
            "Epoch 24/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7106 - student_loss: 0.7445 - distillation_loss: 0.0026\n",
            "Epoch 25/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7118 - student_loss: 0.7360 - distillation_loss: 0.0026\n",
            "Epoch 26/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7212 - student_loss: 0.7295 - distillation_loss: 0.0027\n",
            "Epoch 27/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7165 - student_loss: 0.7298 - distillation_loss: 0.0027\n",
            "Epoch 28/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7193 - student_loss: 0.7256 - distillation_loss: 0.0027\n",
            "Epoch 29/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7246 - student_loss: 0.7160 - distillation_loss: 0.0027\n",
            "Epoch 30/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7207 - student_loss: 0.7189 - distillation_loss: 0.0027\n",
            "Epoch 31/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7234 - student_loss: 0.7150 - distillation_loss: 0.0027\n",
            "Epoch 32/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7238 - student_loss: 0.7073 - distillation_loss: 0.0027\n",
            "Epoch 33/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7246 - student_loss: 0.7076 - distillation_loss: 0.0027\n",
            "Epoch 34/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7245 - student_loss: 0.7040 - distillation_loss: 0.0028\n",
            "Epoch 35/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7252 - student_loss: 0.7019 - distillation_loss: 0.0028\n",
            "Epoch 36/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7265 - student_loss: 0.6968 - distillation_loss: 0.0028\n",
            "Epoch 37/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7308 - student_loss: 0.6944 - distillation_loss: 0.0028\n",
            "Epoch 38/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7292 - student_loss: 0.6943 - distillation_loss: 0.0028\n",
            "Epoch 39/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7316 - student_loss: 0.6875 - distillation_loss: 0.0028\n",
            "Epoch 40/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7339 - student_loss: 0.6841 - distillation_loss: 0.0028\n",
            "Epoch 41/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7354 - student_loss: 0.6792 - distillation_loss: 0.0028\n",
            "Epoch 42/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7361 - student_loss: 0.6794 - distillation_loss: 0.0028\n",
            "Epoch 43/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7366 - student_loss: 0.6734 - distillation_loss: 0.0028\n",
            "Epoch 44/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7382 - student_loss: 0.6681 - distillation_loss: 0.0029\n",
            "Epoch 45/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7374 - student_loss: 0.6734 - distillation_loss: 0.0029\n",
            "Epoch 46/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7402 - student_loss: 0.6652 - distillation_loss: 0.0029\n",
            "Epoch 47/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7423 - student_loss: 0.6584 - distillation_loss: 0.0029\n",
            "Epoch 48/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7408 - student_loss: 0.6569 - distillation_loss: 0.0029\n",
            "Epoch 49/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7458 - student_loss: 0.6533 - distillation_loss: 0.0029\n",
            "Epoch 50/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7486 - student_loss: 0.6500 - distillation_loss: 0.0029\n",
            "Epoch 51/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7438 - student_loss: 0.6487 - distillation_loss: 0.0029\n",
            "Epoch 52/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7490 - student_loss: 0.6404 - distillation_loss: 0.0029\n",
            "Epoch 53/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7463 - student_loss: 0.6494 - distillation_loss: 0.0029\n",
            "Epoch 54/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7501 - student_loss: 0.6382 - distillation_loss: 0.0030\n",
            "Epoch 55/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7532 - student_loss: 0.6332 - distillation_loss: 0.0030\n",
            "Epoch 56/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7556 - student_loss: 0.6301 - distillation_loss: 0.0030\n",
            "Epoch 57/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7512 - student_loss: 0.6334 - distillation_loss: 0.0030\n",
            "Epoch 58/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7523 - student_loss: 0.6295 - distillation_loss: 0.0030\n",
            "Epoch 59/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7574 - student_loss: 0.6241 - distillation_loss: 0.0030\n",
            "Epoch 60/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7546 - student_loss: 0.6237 - distillation_loss: 0.0030\n",
            "Epoch 61/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7598 - student_loss: 0.6222 - distillation_loss: 0.0030\n",
            "Epoch 62/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7606 - student_loss: 0.6170 - distillation_loss: 0.0030\n",
            "Epoch 63/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7576 - student_loss: 0.6145 - distillation_loss: 0.0030\n",
            "Epoch 64/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7613 - student_loss: 0.6149 - distillation_loss: 0.0030\n",
            "Epoch 65/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7609 - student_loss: 0.6091 - distillation_loss: 0.0030\n",
            "Epoch 66/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7619 - student_loss: 0.6090 - distillation_loss: 0.0031\n",
            "Epoch 67/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7624 - student_loss: 0.6113 - distillation_loss: 0.0031\n",
            "Epoch 68/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7642 - student_loss: 0.6091 - distillation_loss: 0.0031\n",
            "Epoch 69/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7658 - student_loss: 0.6053 - distillation_loss: 0.0031\n",
            "Epoch 70/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7710 - student_loss: 0.5908 - distillation_loss: 0.0031\n",
            "Epoch 71/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7679 - student_loss: 0.5898 - distillation_loss: 0.0031\n",
            "Epoch 72/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.7703 - student_loss: 0.5905 - distillation_loss: 0.0031\n",
            "Epoch 73/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7707 - student_loss: 0.5897 - distillation_loss: 0.0031\n",
            "Epoch 74/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.7709 - student_loss: 0.5859 - distillation_loss: 0.0031\n",
            "Epoch 75/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7740 - student_loss: 0.5842 - distillation_loss: 0.0031\n",
            "Epoch 76/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.7738 - student_loss: 0.5817 - distillation_loss: 0.0031\n",
            "Epoch 77/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.7728 - student_loss: 0.5758 - distillation_loss: 0.0032\n",
            "Epoch 78/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7711 - student_loss: 0.5872 - distillation_loss: 0.0031\n",
            "Epoch 79/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7762 - student_loss: 0.5803 - distillation_loss: 0.0032\n",
            "Epoch 80/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7740 - student_loss: 0.5765 - distillation_loss: 0.0031\n",
            "Epoch 81/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7776 - student_loss: 0.5691 - distillation_loss: 0.0032\n",
            "Epoch 82/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7774 - student_loss: 0.5679 - distillation_loss: 0.0032\n",
            "Epoch 83/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7785 - student_loss: 0.5683 - distillation_loss: 0.0032\n",
            "Epoch 84/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7817 - student_loss: 0.5625 - distillation_loss: 0.0032\n",
            "Epoch 85/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7832 - student_loss: 0.5585 - distillation_loss: 0.0032\n",
            "Epoch 86/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7830 - student_loss: 0.5615 - distillation_loss: 0.0032\n",
            "Epoch 87/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7832 - student_loss: 0.5561 - distillation_loss: 0.0032\n",
            "Epoch 88/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7827 - student_loss: 0.5566 - distillation_loss: 0.0032\n",
            "Epoch 89/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7837 - student_loss: 0.5511 - distillation_loss: 0.0032\n",
            "Epoch 90/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7876 - student_loss: 0.5465 - distillation_loss: 0.0032\n",
            "Epoch 91/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7845 - student_loss: 0.5460 - distillation_loss: 0.0032\n",
            "Epoch 92/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7864 - student_loss: 0.5485 - distillation_loss: 0.0033\n",
            "Epoch 93/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7838 - student_loss: 0.5429 - distillation_loss: 0.0033\n",
            "Epoch 94/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7876 - student_loss: 0.5414 - distillation_loss: 0.0033\n",
            "Epoch 95/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7881 - student_loss: 0.5396 - distillation_loss: 0.0033\n",
            "Epoch 96/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7919 - student_loss: 0.5342 - distillation_loss: 0.0033\n",
            "Epoch 97/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7904 - student_loss: 0.5365 - distillation_loss: 0.0033\n",
            "Epoch 98/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7929 - student_loss: 0.5326 - distillation_loss: 0.0033\n",
            "Epoch 99/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7967 - student_loss: 0.5223 - distillation_loss: 0.0033\n",
            "Epoch 100/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7950 - student_loss: 0.5298 - distillation_loss: 0.0033\n",
            "Epoch 101/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7917 - student_loss: 0.5282 - distillation_loss: 0.0033\n",
            "Epoch 102/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7924 - student_loss: 0.5218 - distillation_loss: 0.0033\n",
            "Epoch 103/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7955 - student_loss: 0.5248 - distillation_loss: 0.0033\n",
            "Epoch 104/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7992 - student_loss: 0.5182 - distillation_loss: 0.0033\n",
            "Epoch 105/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7994 - student_loss: 0.5145 - distillation_loss: 0.0034\n",
            "Epoch 106/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7981 - student_loss: 0.5188 - distillation_loss: 0.0034\n",
            "Epoch 107/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8010 - student_loss: 0.5128 - distillation_loss: 0.0034\n",
            "Epoch 108/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8004 - student_loss: 0.5100 - distillation_loss: 0.0034\n",
            "Epoch 109/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7994 - student_loss: 0.5097 - distillation_loss: 0.0034\n",
            "Epoch 110/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.7997 - student_loss: 0.5102 - distillation_loss: 0.0034\n",
            "Epoch 111/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8017 - student_loss: 0.5082 - distillation_loss: 0.0034\n",
            "Epoch 112/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8085 - student_loss: 0.5033 - distillation_loss: 0.0034\n",
            "Epoch 113/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8047 - student_loss: 0.5039 - distillation_loss: 0.0034\n",
            "Epoch 114/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8078 - student_loss: 0.4938 - distillation_loss: 0.0034\n",
            "Epoch 115/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8046 - student_loss: 0.5019 - distillation_loss: 0.0034\n",
            "Epoch 116/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8075 - student_loss: 0.4946 - distillation_loss: 0.0034\n",
            "Epoch 117/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8101 - student_loss: 0.4937 - distillation_loss: 0.0034\n",
            "Epoch 118/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8071 - student_loss: 0.4969 - distillation_loss: 0.0034\n",
            "Epoch 119/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8096 - student_loss: 0.4883 - distillation_loss: 0.0034\n",
            "Epoch 120/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8082 - student_loss: 0.4888 - distillation_loss: 0.0034\n",
            "Epoch 121/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8087 - student_loss: 0.4894 - distillation_loss: 0.0034\n",
            "Epoch 122/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8137 - student_loss: 0.4836 - distillation_loss: 0.0035\n",
            "Epoch 123/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8101 - student_loss: 0.4893 - distillation_loss: 0.0035\n",
            "Epoch 124/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8142 - student_loss: 0.4809 - distillation_loss: 0.0035\n",
            "Epoch 125/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8141 - student_loss: 0.4775 - distillation_loss: 0.0035\n",
            "Epoch 126/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8133 - student_loss: 0.4804 - distillation_loss: 0.0035\n",
            "Epoch 127/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8143 - student_loss: 0.4793 - distillation_loss: 0.0035\n",
            "Epoch 128/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8152 - student_loss: 0.4736 - distillation_loss: 0.0035\n",
            "Epoch 129/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8149 - student_loss: 0.4765 - distillation_loss: 0.0035\n",
            "Epoch 130/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8182 - student_loss: 0.4692 - distillation_loss: 0.0035\n",
            "Epoch 131/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8221 - student_loss: 0.4669 - distillation_loss: 0.0035\n",
            "Epoch 132/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8161 - student_loss: 0.4701 - distillation_loss: 0.0035\n",
            "Epoch 133/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8190 - student_loss: 0.4661 - distillation_loss: 0.0035\n",
            "Epoch 134/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8183 - student_loss: 0.4684 - distillation_loss: 0.0035\n",
            "Epoch 135/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8192 - student_loss: 0.4598 - distillation_loss: 0.0035\n",
            "Epoch 136/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8214 - student_loss: 0.4622 - distillation_loss: 0.0035\n",
            "Epoch 137/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8222 - student_loss: 0.4545 - distillation_loss: 0.0035\n",
            "Epoch 138/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8180 - student_loss: 0.4661 - distillation_loss: 0.0035\n",
            "Epoch 139/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8231 - student_loss: 0.4556 - distillation_loss: 0.0035\n",
            "Epoch 140/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8239 - student_loss: 0.4533 - distillation_loss: 0.0036\n",
            "Epoch 141/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8221 - student_loss: 0.4558 - distillation_loss: 0.0036\n",
            "Epoch 142/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8215 - student_loss: 0.4573 - distillation_loss: 0.0036\n",
            "Epoch 143/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8213 - student_loss: 0.4544 - distillation_loss: 0.0036\n",
            "Epoch 144/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8271 - student_loss: 0.4470 - distillation_loss: 0.0036\n",
            "Epoch 145/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8252 - student_loss: 0.4490 - distillation_loss: 0.0036\n",
            "Epoch 146/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8333 - student_loss: 0.4385 - distillation_loss: 0.0036\n",
            "Epoch 147/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8272 - student_loss: 0.4470 - distillation_loss: 0.0036\n",
            "Epoch 148/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8293 - student_loss: 0.4415 - distillation_loss: 0.0036\n",
            "Epoch 149/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8268 - student_loss: 0.4434 - distillation_loss: 0.0036\n",
            "Epoch 150/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8294 - student_loss: 0.4393 - distillation_loss: 0.0036\n",
            "Epoch 151/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8310 - student_loss: 0.4365 - distillation_loss: 0.0036\n",
            "Epoch 152/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8304 - student_loss: 0.4330 - distillation_loss: 0.0036\n",
            "Epoch 153/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8382 - student_loss: 0.4298 - distillation_loss: 0.0036\n",
            "Epoch 154/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8324 - student_loss: 0.4322 - distillation_loss: 0.0036\n",
            "Epoch 155/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8361 - student_loss: 0.4260 - distillation_loss: 0.0036\n",
            "Epoch 156/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8336 - student_loss: 0.4256 - distillation_loss: 0.0036\n",
            "Epoch 157/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8312 - student_loss: 0.4295 - distillation_loss: 0.0036\n",
            "Epoch 158/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8335 - student_loss: 0.4307 - distillation_loss: 0.0037\n",
            "Epoch 159/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8364 - student_loss: 0.4247 - distillation_loss: 0.0037\n",
            "Epoch 160/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8357 - student_loss: 0.4186 - distillation_loss: 0.0037\n",
            "Epoch 161/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8363 - student_loss: 0.4219 - distillation_loss: 0.0037\n",
            "Epoch 162/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8369 - student_loss: 0.4189 - distillation_loss: 0.0037\n",
            "Epoch 163/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8388 - student_loss: 0.4143 - distillation_loss: 0.0037\n",
            "Epoch 164/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8393 - student_loss: 0.4180 - distillation_loss: 0.0037\n",
            "Epoch 165/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8304 - student_loss: 0.4292 - distillation_loss: 0.0037\n",
            "Epoch 166/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8401 - student_loss: 0.4103 - distillation_loss: 0.0037\n",
            "Epoch 167/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8403 - student_loss: 0.4177 - distillation_loss: 0.0037\n",
            "Epoch 168/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8442 - student_loss: 0.4073 - distillation_loss: 0.0037\n",
            "Epoch 169/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8375 - student_loss: 0.4146 - distillation_loss: 0.0037\n",
            "Epoch 170/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8439 - student_loss: 0.3991 - distillation_loss: 0.0037\n",
            "Epoch 171/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8467 - student_loss: 0.4047 - distillation_loss: 0.0037\n",
            "Epoch 172/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8426 - student_loss: 0.4027 - distillation_loss: 0.0037\n",
            "Epoch 173/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8401 - student_loss: 0.4087 - distillation_loss: 0.0037\n",
            "Epoch 174/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8468 - student_loss: 0.3988 - distillation_loss: 0.0037\n",
            "Epoch 175/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8462 - student_loss: 0.3995 - distillation_loss: 0.0038\n",
            "Epoch 176/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8466 - student_loss: 0.3994 - distillation_loss: 0.0037\n",
            "Epoch 177/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8405 - student_loss: 0.4140 - distillation_loss: 0.0037\n",
            "Epoch 178/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8394 - student_loss: 0.4108 - distillation_loss: 0.0037\n",
            "Epoch 179/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8473 - student_loss: 0.3967 - distillation_loss: 0.0038\n",
            "Epoch 180/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8464 - student_loss: 0.3971 - distillation_loss: 0.0038\n",
            "Epoch 181/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8496 - student_loss: 0.3944 - distillation_loss: 0.0038\n",
            "Epoch 182/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8506 - student_loss: 0.3911 - distillation_loss: 0.0038\n",
            "Epoch 183/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8467 - student_loss: 0.3935 - distillation_loss: 0.0038\n",
            "Epoch 184/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8484 - student_loss: 0.3851 - distillation_loss: 0.0038\n",
            "Epoch 185/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8524 - student_loss: 0.3816 - distillation_loss: 0.0038\n",
            "Epoch 186/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8492 - student_loss: 0.3860 - distillation_loss: 0.0038\n",
            "Epoch 187/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8437 - student_loss: 0.3983 - distillation_loss: 0.0038\n",
            "Epoch 188/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8507 - student_loss: 0.3922 - distillation_loss: 0.0038\n",
            "Epoch 189/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8489 - student_loss: 0.3871 - distillation_loss: 0.0038\n",
            "Epoch 190/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8463 - student_loss: 0.3929 - distillation_loss: 0.0038\n",
            "Epoch 191/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8523 - student_loss: 0.3801 - distillation_loss: 0.0038\n",
            "Epoch 192/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8601 - student_loss: 0.3749 - distillation_loss: 0.0038\n",
            "Epoch 193/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8516 - student_loss: 0.3837 - distillation_loss: 0.0038\n",
            "Epoch 194/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8527 - student_loss: 0.3807 - distillation_loss: 0.0038\n",
            "Epoch 195/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8544 - student_loss: 0.3735 - distillation_loss: 0.0038\n",
            "Epoch 196/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8573 - student_loss: 0.3708 - distillation_loss: 0.0038\n",
            "Epoch 197/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8524 - student_loss: 0.3789 - distillation_loss: 0.0038\n",
            "Epoch 198/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8541 - student_loss: 0.3759 - distillation_loss: 0.0038\n",
            "Epoch 199/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8506 - student_loss: 0.3806 - distillation_loss: 0.0038\n",
            "Epoch 200/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8561 - student_loss: 0.3745 - distillation_loss: 0.0039\n",
            "Epoch 201/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8552 - student_loss: 0.3740 - distillation_loss: 0.0039\n",
            "Epoch 202/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8582 - student_loss: 0.3707 - distillation_loss: 0.0039\n",
            "Epoch 203/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8573 - student_loss: 0.3683 - distillation_loss: 0.0039\n",
            "Epoch 204/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8551 - student_loss: 0.3727 - distillation_loss: 0.0039\n",
            "Epoch 205/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8579 - student_loss: 0.3660 - distillation_loss: 0.0039\n",
            "Epoch 206/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8565 - student_loss: 0.3672 - distillation_loss: 0.0039\n",
            "Epoch 207/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8581 - student_loss: 0.3625 - distillation_loss: 0.0039\n",
            "Epoch 208/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8635 - student_loss: 0.3550 - distillation_loss: 0.0039\n",
            "Epoch 209/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8605 - student_loss: 0.3613 - distillation_loss: 0.0039\n",
            "Epoch 210/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8534 - student_loss: 0.3800 - distillation_loss: 0.0039\n",
            "Epoch 211/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8619 - student_loss: 0.3596 - distillation_loss: 0.0039\n",
            "Epoch 212/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8625 - student_loss: 0.3555 - distillation_loss: 0.0039\n",
            "Epoch 213/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8583 - student_loss: 0.3663 - distillation_loss: 0.0039\n",
            "Epoch 214/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8608 - student_loss: 0.3595 - distillation_loss: 0.0039\n",
            "Epoch 215/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8644 - student_loss: 0.3515 - distillation_loss: 0.0039\n",
            "Epoch 216/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8596 - student_loss: 0.3571 - distillation_loss: 0.0039\n",
            "Epoch 217/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8617 - student_loss: 0.3527 - distillation_loss: 0.0039\n",
            "Epoch 218/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8637 - student_loss: 0.3529 - distillation_loss: 0.0039\n",
            "Epoch 219/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8663 - student_loss: 0.3453 - distillation_loss: 0.0039\n",
            "Epoch 220/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8633 - student_loss: 0.3538 - distillation_loss: 0.0039\n",
            "Epoch 221/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8618 - student_loss: 0.3570 - distillation_loss: 0.0039\n",
            "Epoch 222/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8652 - student_loss: 0.3498 - distillation_loss: 0.0039\n",
            "Epoch 223/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8646 - student_loss: 0.3492 - distillation_loss: 0.0039\n",
            "Epoch 224/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8606 - student_loss: 0.3587 - distillation_loss: 0.0039\n",
            "Epoch 225/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8688 - student_loss: 0.3409 - distillation_loss: 0.0040\n",
            "Epoch 226/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8630 - student_loss: 0.3481 - distillation_loss: 0.0039\n",
            "Epoch 227/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8706 - student_loss: 0.3403 - distillation_loss: 0.0040\n",
            "Epoch 228/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8607 - student_loss: 0.3473 - distillation_loss: 0.0039\n",
            "Epoch 229/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8638 - student_loss: 0.3495 - distillation_loss: 0.0039\n",
            "Epoch 230/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8709 - student_loss: 0.3414 - distillation_loss: 0.0040\n",
            "Epoch 231/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8625 - student_loss: 0.3464 - distillation_loss: 0.0040\n",
            "Epoch 232/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8732 - student_loss: 0.3346 - distillation_loss: 0.0040\n",
            "Epoch 233/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8641 - student_loss: 0.3413 - distillation_loss: 0.0040\n",
            "Epoch 234/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8655 - student_loss: 0.3422 - distillation_loss: 0.0040\n",
            "Epoch 235/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8656 - student_loss: 0.3460 - distillation_loss: 0.0040\n",
            "Epoch 236/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8661 - student_loss: 0.3449 - distillation_loss: 0.0040\n",
            "Epoch 237/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8703 - student_loss: 0.3325 - distillation_loss: 0.0040\n",
            "Epoch 238/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8706 - student_loss: 0.3356 - distillation_loss: 0.0040\n",
            "Epoch 239/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8721 - student_loss: 0.3310 - distillation_loss: 0.0040\n",
            "Epoch 240/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8708 - student_loss: 0.3321 - distillation_loss: 0.0040\n",
            "Epoch 241/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8666 - student_loss: 0.3380 - distillation_loss: 0.0040\n",
            "Epoch 242/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8703 - student_loss: 0.3394 - distillation_loss: 0.0040\n",
            "Epoch 243/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8753 - student_loss: 0.3278 - distillation_loss: 0.0040\n",
            "Epoch 244/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8723 - student_loss: 0.3309 - distillation_loss: 0.0040\n",
            "Epoch 245/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8709 - student_loss: 0.3329 - distillation_loss: 0.0040\n",
            "Epoch 246/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8696 - student_loss: 0.3368 - distillation_loss: 0.0040\n",
            "Epoch 247/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8755 - student_loss: 0.3221 - distillation_loss: 0.0040\n",
            "Epoch 248/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8721 - student_loss: 0.3308 - distillation_loss: 0.0040\n",
            "Epoch 249/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8784 - student_loss: 0.3154 - distillation_loss: 0.0040\n",
            "Epoch 250/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8704 - student_loss: 0.3330 - distillation_loss: 0.0040\n",
            "Epoch 251/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8702 - student_loss: 0.3317 - distillation_loss: 0.0040\n",
            "Epoch 252/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8737 - student_loss: 0.3289 - distillation_loss: 0.0040\n",
            "Epoch 253/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8747 - student_loss: 0.3201 - distillation_loss: 0.0040\n",
            "Epoch 254/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8786 - student_loss: 0.3161 - distillation_loss: 0.0040\n",
            "Epoch 255/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8708 - student_loss: 0.3313 - distillation_loss: 0.0040\n",
            "Epoch 256/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8729 - student_loss: 0.3258 - distillation_loss: 0.0040\n",
            "Epoch 257/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8814 - student_loss: 0.3120 - distillation_loss: 0.0041\n",
            "Epoch 258/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8737 - student_loss: 0.3269 - distillation_loss: 0.0040\n",
            "Epoch 259/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8739 - student_loss: 0.3216 - distillation_loss: 0.0040\n",
            "Epoch 260/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8794 - student_loss: 0.3130 - distillation_loss: 0.0041\n",
            "Epoch 261/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8747 - student_loss: 0.3211 - distillation_loss: 0.0041\n",
            "Epoch 262/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8829 - student_loss: 0.3072 - distillation_loss: 0.0041\n",
            "Epoch 263/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8821 - student_loss: 0.3035 - distillation_loss: 0.0041\n",
            "Epoch 264/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8839 - student_loss: 0.3061 - distillation_loss: 0.0041\n",
            "Epoch 265/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8865 - student_loss: 0.3044 - distillation_loss: 0.0041\n",
            "Epoch 266/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8786 - student_loss: 0.3090 - distillation_loss: 0.0041\n",
            "Epoch 267/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8812 - student_loss: 0.3067 - distillation_loss: 0.0041\n",
            "Epoch 268/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8790 - student_loss: 0.3136 - distillation_loss: 0.0041\n",
            "Epoch 269/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8839 - student_loss: 0.3037 - distillation_loss: 0.0041\n",
            "Epoch 270/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8747 - student_loss: 0.3236 - distillation_loss: 0.0041\n",
            "Epoch 271/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8763 - student_loss: 0.3154 - distillation_loss: 0.0041\n",
            "Epoch 272/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8826 - student_loss: 0.3014 - distillation_loss: 0.0041\n",
            "Epoch 273/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8843 - student_loss: 0.3006 - distillation_loss: 0.0041\n",
            "Epoch 274/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8841 - student_loss: 0.3024 - distillation_loss: 0.0041\n",
            "Epoch 275/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8822 - student_loss: 0.3064 - distillation_loss: 0.0041\n",
            "Epoch 276/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8818 - student_loss: 0.3015 - distillation_loss: 0.0041\n",
            "Epoch 277/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8783 - student_loss: 0.3097 - distillation_loss: 0.0041\n",
            "Epoch 278/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8843 - student_loss: 0.3056 - distillation_loss: 0.0041\n",
            "Epoch 279/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8812 - student_loss: 0.3039 - distillation_loss: 0.0041\n",
            "Epoch 280/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8817 - student_loss: 0.3062 - distillation_loss: 0.0041\n",
            "Epoch 281/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8850 - student_loss: 0.2902 - distillation_loss: 0.0041\n",
            "Epoch 282/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8823 - student_loss: 0.3013 - distillation_loss: 0.0041\n",
            "Epoch 283/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8783 - student_loss: 0.3121 - distillation_loss: 0.0041\n",
            "Epoch 284/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8878 - student_loss: 0.2925 - distillation_loss: 0.0041\n",
            "Epoch 285/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8830 - student_loss: 0.3010 - distillation_loss: 0.0041\n",
            "Epoch 286/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8812 - student_loss: 0.3048 - distillation_loss: 0.0041\n",
            "Epoch 287/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8857 - student_loss: 0.2946 - distillation_loss: 0.0041\n",
            "Epoch 288/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8874 - student_loss: 0.2872 - distillation_loss: 0.0042\n",
            "Epoch 289/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8806 - student_loss: 0.3107 - distillation_loss: 0.0041\n",
            "Epoch 290/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8893 - student_loss: 0.2914 - distillation_loss: 0.0041\n",
            "Epoch 291/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8879 - student_loss: 0.2929 - distillation_loss: 0.0041\n",
            "Epoch 292/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8824 - student_loss: 0.2995 - distillation_loss: 0.0041\n",
            "Epoch 293/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8869 - student_loss: 0.2877 - distillation_loss: 0.0042\n",
            "Epoch 294/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8909 - student_loss: 0.2832 - distillation_loss: 0.0042\n",
            "Epoch 295/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8884 - student_loss: 0.2905 - distillation_loss: 0.0042\n",
            "Epoch 296/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8932 - student_loss: 0.2841 - distillation_loss: 0.0042\n",
            "Epoch 297/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8886 - student_loss: 0.2946 - distillation_loss: 0.0041\n",
            "Epoch 298/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8844 - student_loss: 0.2958 - distillation_loss: 0.0042\n",
            "Epoch 299/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8837 - student_loss: 0.3004 - distillation_loss: 0.0042\n",
            "Epoch 300/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8847 - student_loss: 0.2998 - distillation_loss: 0.0042\n",
            "Epoch 301/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8908 - student_loss: 0.2893 - distillation_loss: 0.0042\n",
            "Epoch 302/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8844 - student_loss: 0.2968 - distillation_loss: 0.0042\n",
            "Epoch 303/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8844 - student_loss: 0.2974 - distillation_loss: 0.0042\n",
            "Epoch 304/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8921 - student_loss: 0.2817 - distillation_loss: 0.0042\n",
            "Epoch 305/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8917 - student_loss: 0.2810 - distillation_loss: 0.0042\n",
            "Epoch 306/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8928 - student_loss: 0.2791 - distillation_loss: 0.0042\n",
            "Epoch 307/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8815 - student_loss: 0.3047 - distillation_loss: 0.0042\n",
            "Epoch 308/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8945 - student_loss: 0.2710 - distillation_loss: 0.0042\n",
            "Epoch 309/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8942 - student_loss: 0.2868 - distillation_loss: 0.0042\n",
            "Epoch 310/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8913 - student_loss: 0.2846 - distillation_loss: 0.0042\n",
            "Epoch 311/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8859 - student_loss: 0.2932 - distillation_loss: 0.0042\n",
            "Epoch 312/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8952 - student_loss: 0.2720 - distillation_loss: 0.0042\n",
            "Epoch 313/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8960 - student_loss: 0.2733 - distillation_loss: 0.0042\n",
            "Epoch 314/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8909 - student_loss: 0.2825 - distillation_loss: 0.0042\n",
            "Epoch 315/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8904 - student_loss: 0.2823 - distillation_loss: 0.0042\n",
            "Epoch 316/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8920 - student_loss: 0.2837 - distillation_loss: 0.0042\n",
            "Epoch 317/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8893 - student_loss: 0.2840 - distillation_loss: 0.0042\n",
            "Epoch 318/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8947 - student_loss: 0.2721 - distillation_loss: 0.0042\n",
            "Epoch 319/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8846 - student_loss: 0.2892 - distillation_loss: 0.0042\n",
            "Epoch 320/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8946 - student_loss: 0.2709 - distillation_loss: 0.0042\n",
            "Epoch 321/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8953 - student_loss: 0.2730 - distillation_loss: 0.0042\n",
            "Epoch 322/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8917 - student_loss: 0.2788 - distillation_loss: 0.0042\n",
            "Epoch 323/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8891 - student_loss: 0.2845 - distillation_loss: 0.0042\n",
            "Epoch 324/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8905 - student_loss: 0.2804 - distillation_loss: 0.0042\n",
            "Epoch 325/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8974 - student_loss: 0.2642 - distillation_loss: 0.0042\n",
            "Epoch 326/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8981 - student_loss: 0.2668 - distillation_loss: 0.0042\n",
            "Epoch 327/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8969 - student_loss: 0.2669 - distillation_loss: 0.0042\n",
            "Epoch 328/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8960 - student_loss: 0.2709 - distillation_loss: 0.0042\n",
            "Epoch 329/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8989 - student_loss: 0.2618 - distillation_loss: 0.0042\n",
            "Epoch 330/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8927 - student_loss: 0.2758 - distillation_loss: 0.0042\n",
            "Epoch 331/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8917 - student_loss: 0.2769 - distillation_loss: 0.0042\n",
            "Epoch 332/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8959 - student_loss: 0.2682 - distillation_loss: 0.0042\n",
            "Epoch 333/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8908 - student_loss: 0.2797 - distillation_loss: 0.0042\n",
            "Epoch 334/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8985 - student_loss: 0.2623 - distillation_loss: 0.0042\n",
            "Epoch 335/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8951 - student_loss: 0.2687 - distillation_loss: 0.0042\n",
            "Epoch 336/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8984 - student_loss: 0.2639 - distillation_loss: 0.0043\n",
            "Epoch 337/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8915 - student_loss: 0.2798 - distillation_loss: 0.0042\n",
            "Epoch 338/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8987 - student_loss: 0.2578 - distillation_loss: 0.0043\n",
            "Epoch 339/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8948 - student_loss: 0.2709 - distillation_loss: 0.0042\n",
            "Epoch 340/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8974 - student_loss: 0.2705 - distillation_loss: 0.0043\n",
            "Epoch 341/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8940 - student_loss: 0.2701 - distillation_loss: 0.0043\n",
            "Epoch 342/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8985 - student_loss: 0.2690 - distillation_loss: 0.0043\n",
            "Epoch 343/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8935 - student_loss: 0.2699 - distillation_loss: 0.0043\n",
            "Epoch 344/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9026 - student_loss: 0.2581 - distillation_loss: 0.0043\n",
            "Epoch 345/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.9005 - student_loss: 0.2601 - distillation_loss: 0.0043\n",
            "Epoch 346/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8946 - student_loss: 0.2674 - distillation_loss: 0.0043\n",
            "Epoch 347/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8985 - student_loss: 0.2636 - distillation_loss: 0.0043\n",
            "Epoch 348/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8938 - student_loss: 0.2722 - distillation_loss: 0.0043\n",
            "Epoch 349/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9006 - student_loss: 0.2587 - distillation_loss: 0.0043\n",
            "Epoch 350/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8952 - student_loss: 0.2724 - distillation_loss: 0.0043\n",
            "Epoch 351/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8945 - student_loss: 0.2674 - distillation_loss: 0.0043\n",
            "Epoch 352/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8979 - student_loss: 0.2686 - distillation_loss: 0.0043\n",
            "Epoch 353/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8966 - student_loss: 0.2661 - distillation_loss: 0.0043\n",
            "Epoch 354/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8998 - student_loss: 0.2629 - distillation_loss: 0.0043\n",
            "Epoch 355/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9037 - student_loss: 0.2526 - distillation_loss: 0.0043\n",
            "Epoch 356/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9009 - student_loss: 0.2570 - distillation_loss: 0.0043\n",
            "Epoch 357/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.9018 - student_loss: 0.2569 - distillation_loss: 0.0043\n",
            "Epoch 358/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9005 - student_loss: 0.2594 - distillation_loss: 0.0043\n",
            "Epoch 359/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8953 - student_loss: 0.2687 - distillation_loss: 0.0043\n",
            "Epoch 360/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8967 - student_loss: 0.2626 - distillation_loss: 0.0043\n",
            "Epoch 361/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9070 - student_loss: 0.2449 - distillation_loss: 0.0043\n",
            "Epoch 362/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8994 - student_loss: 0.2621 - distillation_loss: 0.0043\n",
            "Epoch 363/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8987 - student_loss: 0.2611 - distillation_loss: 0.0043\n",
            "Epoch 364/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9003 - student_loss: 0.2570 - distillation_loss: 0.0043\n",
            "Epoch 365/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9058 - student_loss: 0.2440 - distillation_loss: 0.0043\n",
            "Epoch 366/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8980 - student_loss: 0.2623 - distillation_loss: 0.0043\n",
            "Epoch 367/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9045 - student_loss: 0.2507 - distillation_loss: 0.0043\n",
            "Epoch 368/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9065 - student_loss: 0.2510 - distillation_loss: 0.0043\n",
            "Epoch 369/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9025 - student_loss: 0.2537 - distillation_loss: 0.0043\n",
            "Epoch 370/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9022 - student_loss: 0.2532 - distillation_loss: 0.0043\n",
            "Epoch 371/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8998 - student_loss: 0.2566 - distillation_loss: 0.0043\n",
            "Epoch 372/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.9040 - student_loss: 0.2474 - distillation_loss: 0.0043\n",
            "Epoch 373/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9069 - student_loss: 0.2456 - distillation_loss: 0.0043\n",
            "Epoch 374/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9040 - student_loss: 0.2529 - distillation_loss: 0.0043\n",
            "Epoch 375/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8961 - student_loss: 0.2665 - distillation_loss: 0.0043\n",
            "Epoch 376/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9047 - student_loss: 0.2494 - distillation_loss: 0.0043\n",
            "Epoch 377/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8998 - student_loss: 0.2607 - distillation_loss: 0.0043\n",
            "Epoch 378/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9070 - student_loss: 0.2401 - distillation_loss: 0.0043\n",
            "Epoch 379/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9010 - student_loss: 0.2554 - distillation_loss: 0.0043\n",
            "Epoch 380/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9034 - student_loss: 0.2533 - distillation_loss: 0.0043\n",
            "Epoch 381/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9021 - student_loss: 0.2539 - distillation_loss: 0.0043\n",
            "Epoch 382/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9019 - student_loss: 0.2511 - distillation_loss: 0.0043\n",
            "Epoch 383/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.8987 - student_loss: 0.2592 - distillation_loss: 0.0043\n",
            "Epoch 384/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9031 - student_loss: 0.2451 - distillation_loss: 0.0043\n",
            "Epoch 385/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9087 - student_loss: 0.2345 - distillation_loss: 0.0044\n",
            "Epoch 386/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9075 - student_loss: 0.2403 - distillation_loss: 0.0043\n",
            "Epoch 387/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9061 - student_loss: 0.2457 - distillation_loss: 0.0043\n",
            "Epoch 388/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8978 - student_loss: 0.2635 - distillation_loss: 0.0043\n",
            "Epoch 389/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9101 - student_loss: 0.2348 - distillation_loss: 0.0043\n",
            "Epoch 390/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.8970 - student_loss: 0.2665 - distillation_loss: 0.0043\n",
            "Epoch 391/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9006 - student_loss: 0.2525 - distillation_loss: 0.0043\n",
            "Epoch 392/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9053 - student_loss: 0.2450 - distillation_loss: 0.0043\n",
            "Epoch 393/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9041 - student_loss: 0.2472 - distillation_loss: 0.0043\n",
            "Epoch 394/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9049 - student_loss: 0.2441 - distillation_loss: 0.0043\n",
            "Epoch 395/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9052 - student_loss: 0.2448 - distillation_loss: 0.0043\n",
            "Epoch 396/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9090 - student_loss: 0.2365 - distillation_loss: 0.0044\n",
            "Epoch 397/400\n",
            "433/433 [==============================] - 3s 8ms/step - categorical_accuracy: 0.9026 - student_loss: 0.2471 - distillation_loss: 0.0043\n",
            "Epoch 398/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9032 - student_loss: 0.2471 - distillation_loss: 0.0043\n",
            "Epoch 399/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9078 - student_loss: 0.2417 - distillation_loss: 0.0044\n",
            "Epoch 400/400\n",
            "433/433 [==============================] - 4s 8ms/step - categorical_accuracy: 0.9068 - student_loss: 0.2407 - distillation_loss: 0.0044\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7ae0235bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_distiller = distiller.evaluate(pp_X_sub_482, y_sub_482_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXYDUAQ063ce",
        "outputId": "65fd1fd9-2abc-4eb5-f754-e430b4fee3f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 4ms/step - categorical_accuracy: 0.6048 - student_loss: 6.3767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "used the best performing teacher with accuracy of 62.32 on subject data;\n",
        "\n",
        "alpha=0.1\n",
        "\n",
        "temp=10\n",
        "\n",
        "100 epochs: ~ 55\n",
        "\n",
        "200 epochs: 60.48\n",
        "\n",
        "300 epochs: 57.24\n",
        "\n",
        "400 epochs: 59.07\n",
        "\n",
        "500 epochs: 55.56\n",
        "\n",
        "alpha=0.9\n",
        "\n",
        "temp=4\n",
        "\n",
        "100 epochs: 60.90\n",
        "\n",
        "200 epochs: 62.17\n",
        "\n",
        "300 epochs: 62.45\n",
        "\n",
        "400 epochs: 60.48\n",
        "\n",
        "500 epochs: \n",
        "\n"
      ],
      "metadata": {
        "id": "OlkwcKpNCrFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ebmlHLHD95hM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}